{80}  -*- text -*-
[0:

Sat Jan 19 12:29:28 2019 OK, so we've been struggling trying to pick a
userspace interaction/communication model for intertile stuff, and we
then perhaps the current missing link is we need an explicit 'neighbor
tile' abstraction.  Something that's not about the intertile
connection, but about the tile at the far end -- whether we currently
have a such a neighbor or not.

Unsure if it belongs in /dev, /sys/class, or something more userspace,
but perhaps like /dev/tile/ET etc.  For at least some users, we'd like
connection and disconnection events to be reported as just more
packets on some channel that stays open across such things.

And this abstraction would naturally be the place to handle those
currently-unhandled locstd 'P' and 'F' packets that we are currently
dumping to syslog like lost babies.  The /dev/tile/DIR object would
change status as a result, and that would be somehow visible more
broadly in userspace.

Perhaps we should draft a standard local packet type for 'tile event
notices' right now, so that our tile model can have an OoB way to
notify consumers about such changes.

OK, currently 201812171048-packet-format-notes.txt:1: has our
'documentation' for the defined local standard packet types.  0..3 (of
31) are currently in use.  Just take 4?  What is its name?[1:

Sat Jan 19 12:57:57 2019 'Tile Event Packet'?  TEP?  None of the std
loc packet types seem to have manifest constant names yet.[2:

Sat Jan 19 12:59:31 2019 And what is the TEP syntax?  Well, we finally
will not have the direction encoded in it, because that's now implicit
in which tile we are talking to.

So:
TEP := TEP_PKT_TYPE + EVENT_TYPE + OPT_ARGS
TEP_PKT_TYPE := 0xc4
OPT_ARGS     := BYTE*

EVENT_TYPE   :=
 0x00      Illegal
 0x01      Connect
 0x02      Disconnect
 0x03-0xff Reserved

[3:

Sat Jan 19 16:04:54 2019 The tile models, I guess, should provide
services by something like port number, so packets can be
demultiplexed by the tile model.

And I guess the userspace 'server' we're thinking of is the "actual"
tile that the remote tile models are modeling.
[4:

Sat Jan 19 17:21:36 2019 Looking at some FUSE tutorials..  I know
there's plenty of people hating on FUSE but it might be at least a
transition technology for us here as we try to figure out what we
actually want our LKMs to do for us.
[5:

Sun Jan 20 01:06:31 2019 Well, fuse is about what you'd expect -- a
giant pile of callbacks with a lot of fiddly details about
unimplemented flags and fuse-versions and so forth.  We can certainly
figure it out if we really want to but I'd rather have a clearer idea
what we want out of it before we try.

[6:

Sun Jan 20 01:08:10 2019 What are our main use cases?

1. mfmt2 would like to sit on one fd -- preferably via select() but
   perhaps block on a thread -- and receive all intertile mfm packets.

2. mfmt2 would also like to select() on one fd to know when it can
   send an intertile packet?

3. some 'physics daemon' would like to announce and monitor the tile's
   current physics 'version stamp' and do background intertile
   updating of newer versions.

4. at a minimum the physics daemon would manage mfz files; as a
   step-up it could propagate like the T2 repo as well.


5. 'general intertile communications', whatever that might mean?

[7:

Sun Jan 20 04:25:04 2019 Given that it's all about 1 & 2, really, what
about if we draft the reserved bit in

    FIRST BYTE

     Standard Routed Packet Header
      STND LOCL RSV1
     +----------------------------------------+
     |  1 |  0 |  0 |OVRN||EROR|DIR2|DIR1|DIR0|
     +----------------------------------------+

(from /home/t2/T2-12/pru/itcio/notes/201812171048-packet-format-notes.txt:0 )

to be the 'mfm bit'?

      STND LOCL MFMT
     +----------------------------------------+
     |  1 |  0 | 1  |OVRN||EROR|DIR2|DIR1|DIR0|
     +----------------------------------------+

So anything with MFMT set is 'MFM traffic' that would be routed to and
from like /dev/itc/mfm or something, and mfmt2 would select or block
on that.[8:

Sun Jan 20 04:33:55 2019 So, everybody else would do what?  Go through
some single daemon that managed packet services for everybody except
mfm?  And that guy would expect packets like what, perhaps:


      BYTE 0                                   BYTE 1
      STND LOCL MFMT
     +----------------------------------------++---------------------------------------+
     |  1 |  0 | 0  |OVRN||EROR|DIR2|DIR1|DIR0||DST3|DST2|DST1|DST0|SRC3|SRC2|SRC1|SRC0|
     +----------------------------------------++---------------------------------------+

and we'd support up to sixteen random packet service ports.  Or I
suppose we could go to a three byte header, jeez.[9:

Sun Jan 20 04:54:44 2019 And how would people offer and use those
services.  Open /dev/itc/svc/ff for RDWR|NONBLOCK or something?  But
then do we even need a distinct source port, or is everything peer to
peer?  That would be flavorful.
[13:

Thu Jan 31 00:36:25 2019 So, we're back here, and we have a public
challenge to get software moving between tiles before next t2sday.

So, picking up the discussion in :8:, we need to pull the trigger on a
format for STND,!LOCL,!MFMT packets.

Do we NEED source ports?  Well, why do source ports exist?  So that
multiple 'clients' can talk to one 'server'.  Now, in basic intertile
land, we are ONLY talking to neighboring tiles and are NOT routing
beyond that.  And the source DIRECTION is already present in the BYTE0
header, so clients on different neighboring tiles are already
distinguishable.

So these multiple clients, if we had them, would have to be all on a
SINGLE neighboring tile.  Do we really need that?  Well, what if we
wanted to update a bunch of files amongst our neighbors?  We might be
newer on some files and some of our neighbors might be newer on
others.  It would be arguably convenient to just start flows for each
file that has to move in any direction and let their packets get
interleaved however, rather than having to (go to all the onerous
extra trouble to) make a user-level queue or whatever for the files
destined for each neighbor.
[14:

Thu Jan 31 02:40:10 2019 So I guess that example isn't
super-compelling to me.  To the contrary, if we had a peer-to-peer
'managed file update service', we could (more easily) get different
pieces of files from different neighbors and so on.  (Eventually.)

Are there other cases to consider for source ports?[15:

Thu Jan 31 02:46:01 2019 ..I'm just not seeing it.  Screw it, let's go
full-on peer-to-peer and deal with any fall-out as we have to.  Worst
case we can always create a source port model underneath some
peer-to-peer service.

So, we'd be saying something like

      BYTE 0                                   BYTE 1
      STND LOCL MFMT
     +----------------------------------------++---------------------------------------+
     |  1 |  0 | 0  |OVRN||EROR|DIR2|DIR1|DIR0||RSV1|RSV0|SVC5|SVC4|SVC3|SVC2|SVC1|SVC0|
     +----------------------------------------++---------------------------------------+

where we offer up to 63 services (reserving service 0 as null), and
hold a couple of bits for the future.

Aaand we can go ahead and draft a few services here, at least
provisionally?

Say service 1 is a .. what?  Version number?  Liveness ping?  Maybe we
should stick to our knitting here and just say like service 8 is
'managed file update'.  We want a service that just falls towards
having the newest version of all managed files that any neighbor knows
about.  We'll have a directory of the current king of the hill files,
each with a version number and a checksum..[16:

Thu Jan 31 03:17:26 2019 Stop stop stop.  Crawl before fly my god you
have to get something running here.  A directory of MFZ files that are
all to be considered 'legitimates physics-es'.  All have to be signed
by a known key.  We go by the timestamp in the mfz to decide if a file
is newer.  As an idle background process, we send random mfz+timestamp
info to random neighbors every so often.  If we receive word about an
MFZ that we don't have or that's newer than what we do have, we
request that file.  The source starts streaming it to us.  We assemble
it in a temporary directory.  When/if it arrives completely and we
verify it locally, we (atomically-ish) cut it over into the live
directory, and that's when it will start getting broadcast to our
neighbors.

Somehow we have a way -- perhaps a different service in fact -- of
saying it's time to change physics, which we handle by shutting down
MFM and restarting it on a new MFZ.

For now we still won't have intertile events, so there's no issue yet
of mfm needing to check that neighbors are on the same MFZ.

:16]

:15]

:14]

:13]
:9]


:8]

:7]


:6]

:5]
:4]
:3]


:2]

:1]

:0]
[10:

Sun Jan 20 08:02:15 2019 But, I need to see something anything proof
of concept minimal crap actually working here, for me to feel
comfortable.

I want a Perl script daemon that

1. Watches the modification date of some counter file, and reloads it
   whenever it changes.

2. And advertises its counter value by sending it to all active
   neighbors every minute or so.

3. And tracks the counters of all active neighbors by monitoring their
   counter value advertisements.

4. And

:10]
[11:

Wed Jan 30 22:37:52 2019 Aaand, to make the guts of that work, we need
a way to send a file.  Which is a stream of bytes, plus metadata,
which has to be packetized, sent, received, and reassembled.

Aaaaad, damn the NIH torpedoes aaand damn the RTW (Reinventing The
Wheel) nay-sayers and let's just MAKE OUR OWWWWWWWWN.

[12:

Wed Jan 30 22:40:56 2019 So.  We need packet formats for metadata and
data stream.  We have some structure for such things already set up,
so we should find that.

:12]

:11]
[17:

Sat Feb  2 23:50:04 2019 Aaaand we're back.  [18:

Sun Feb  3 01:04:12 2019 So we're making 'cdm.pl', a demo 'common data
manager' script that, as far as I can tell right now, will have
essentially no user interface at all.  It will hog all the packets on
/dev/itc/packets -- a device which should, once mfmt2 exists, NOT
include mfm traffic -- and build a model of its own and its neighbors
common data, and automatically send updates as needed so that
everybody falls towards having an equivalent view of what counts as
the latest common data.  cdm.pl will generate output along the lines
of log messages about what's going on, but that's about it.

But first, nap.[19:

Sun Feb  3 02:36:19 2019 Well, maybe not nap yet.

Structures for file/directory model:

 @content => (sha512-of-content content-length-bytes path-to-content)


:19]

:18]


:17]
[20:

Sun Feb  3 04:44:54 2019 OK, say service 3 is CDM_PKT_TYPE.  Format
is:

      BYTE 0                                   BYTE 1                                   BYTE 2
      STND LOCL MFMT
     +----------------------------------------++---------------------------------------++----------------+
     |  1 |  0 | 0  |OVRN||EROR|DIR2|DIR1|DIR0||   0|   0|   0|   0|   0|   0|   1|   1|| CDM PKT TYPE   |...
     +----------------------------------------++---------------------------------------++----------------+

 => 0x80 | dir, 0x03, code, args..  Why service 3?  Because that's ^C
for 'CDM'?  Whatever.

And our first code is 'A'live, a liveness ping.  Let's implement that
and foggen PROCESS A PACKET.[21:

Sun Feb  3 05:17:49 2019 OK, so there it is.  Mr NW sent
'\203^CA' packets and Mr SE sent '\207^CA' packets, and Mr NW received
'\203^CA' packets and Mr SE received '\207^CA' packets.

Which seems like they could just be talking to themselves.. but the
dirs get remapped from dst->src as they move intertile.  (Which I just
confirmed by adding a random number payload to distinguish the 'A'
packet.)

So.  Progress.  Now nap.  (What _is_ happening to those packets we're
sending to unconnected tiles, hmm?)

:21]

:20]
[22:

Sun Feb  3 11:47:53 2019 OK, so, let's have a primitive neighbor model
to maintain and grow:

 - Direction to ngb
 - Time we last got an Alive pkt from them
 - Time we last sent an Alive pkt to them

I guess we ought to do 'object hash' style.  This is likely to grow
hunh?

Also, maybe we shouldn't use wall-clock time, but just
count-of-background-works or something.  We really want to avoid
leaning on absolute time if we don't need it.  We'll call an entry to
doBackgroundWork a.. what?  'Ticks' is way too overloaded already.
'Tocks'?  Just makes you look around for ticks.

'Background Work' -> 'Borks'?  Probably too distracting.. 'Clicks'?
Maybe.  'Clacks'?  Ooh, better :).  Like machinery!  Big old
steam-powered machinery suitable for slow background tasks.

[23:

Sun Feb  3 12:27:00 2019 Do we actually need even clacks, in the sense
of it being an absolute count of doBackgroundWork calls?  We're facing
count-to-infinity if we want absolute clacks.  And all we really need
is 'clack intervals' anyway, right?  Couldn't we do countdowns
instead?  And we don't even need countdowns if we seriously drink our
own koolaid and do 'stats instead of state'.  Every time we pick a ngb
to consider, we have some odds of sending it an Alive..  And if we
have it flagged as alive, we have some odds of clearing that flag.
Like 1 in 25 to send our Alive, 1 in 100 to clear their alive.

Going all-stats might be get pretty raggedy, though, for something
we're thinking of as fairly low-level.  Could mix it, stats to send
our alive but a countdown to expire their Alive?  Or countdown for
both but reset them to random range.  Or countup with random
expiration. [24:

Sun Feb  3 13:07:20 2019 Now, wait a minute.  Do we even need
aliveness packets given we have the credible and much lower-level
notion of packet sync?  Well, it's not about need, it's about
robustness.  If we have PS but aren't getting alive packets, our
neighbor has got problems in middle management.

Suppose we create an apoptosis signal packet -- a pretty low-level
one, that's handled in the LKM.  One such packet doesn't mean much,
but getting them frequently from multiple neighbors should be a sign
that we should try to make a note of the situation somewhere and then
reboot.

:24]

:23]

:22]
[25:

Sun Feb  3 14:21:27 2019 Well, we have two reserved bits in byte 1 of
standard routed tile (as opposed to mfm) packets.  I'm wondering about
drafting either or both as a 'network level' indicator or something,
like:

 00 User space
 01 LKM
 10 PRU reserved
 11 Illegal reserved

where 'normal' cdm packets would be 00 but apoptosis packets would be
01.

I suppose a more 'port-like' approach would be just reserve a low
range of service numbers to be 'system' level.[26:

Sun Feb  3 14:42:03 2019 BUT IN ANY FOGGEN EVENT I SHOULDN'T BE
DESIGNING INTERTILE APOPTOSIS RIGHT THE FOG NOW.  Sheesh.

:26]

:25]
[27:

Mon Feb  4 00:38:22 2019 OK, also want a data model to describe our
view of the common/ directory.  At least, stuff about file paths,
sizes, and checksums.  We're still struggling to define our
relationship with wall-clock time: We don't think we really need it,
and we don't think it's all that scalable, but it's what the
filesystem is going to be using so what do we do?

Fundamental data model question: When should some content count as a
new version of an existing name?[28:

Mon Feb  4 00:52:59 2019 All we really have at the moment is the
internal timestamp on mfz files.  We can get at that using the
extended version of 'mfzrun verify':

    ackley@coldaynell:~/PART4/code/D$ ./MFM/bin/mfzrun ../E/MFM/res/elements/demos/ForkBombs.mfz VERIFY
    SIGNATURE_CHECK [OK]
    INNER_CHECKSUM [2aafbf-aa30-a86bc6]
    INNER_TIMESTAMP [1536398164]
    SIGNING_HANDLE [MFM-DEMOS-20180908031520-ulam-3.0.12-ackley]
    HANDLE_FINGERPRINT [e1bf-234-7029]
    HANDLE_PUBKEY [-----BEGIN RSA PUBLIC KEY-----
    MIGJAoGBALdLR5qmGltWAx7Kt5yBAiNQbElAT9UuAjVNZCdHYTuTRckeyhNNF0VS
    0mKBAKAyzLXIG4yXJVCw5s/lx2J3DCcXOv62tNDL8uPpqM3PiGlSv+R5iSvDv27m
    mNpHxXYIwfrpaHLPSngPyYa3P31r8gRCka+K8IiF9dimYMjan+N/AgMBAAE=
    -----END RSA PUBLIC KEY-----
    ]

which absolutely does depend on absolute time, but, because it's also
signed by someone we've been told to trust, we're inclined to believe
that successive INNER_TIMESTAMPs will be legitimately comparable
within a given mfz name.[29:

Mon Feb  4 01:18:56 2019 Another natural, modrun possibility is
working off a git repo and deriving version precedence from successive
commits on a given path.  But that brings an awful lot of
infrastructure with it -- not necessarily bad infrastructure, but not
necessarily infrastructure we want to fundamentally depend upon
either.

Back in IXM-land a decade ago, we had 'green boot', 'blue boot', and
'red boot'.  Green boot accepted wall-clock-newer code from anybody,
blue required wall-clock-newer plus matching the current 'program id',
and red wouldn't accept new code at all without a physical button
press during boot up.

We could say a physical button-press is required to add something to
/data/common?  But how would that work?  We accept any contents in
/data/common when cdm.pl starts up, so put new crap in then restart.

[30:

Mon Feb  4 01:34:39 2019 Well, fog it, we have to get off the dime
here.  For today let's only consider .mfz files, let's checksum them
externally and recheck the checksums from time to time, and when they
change we use mfzrun VERIFY to get the internal timestamp, and if the
internal timestamp beats what we're holding we propagate it.

One practical problem is that mfzrun VERIFY is only in the github,
it's not in the MFM-4.0.12 that the tiles are using.  Now, I guess for
the moment we could just use 'mfzrun list' and take the time of the
MFZPUBKEY.DAT file as proxy for the 'internal timestamp'.

Let's do that.  Damn the torpedoes.

[31:

Mon Feb  4 01:40:45 2019 So, one cdm background task is load/refresh
an .mfz file.

The file info we'll keep is:

  [path, length, checksum, signing-handle, timestamp]

The file info we'll send to neighbors is

  [path, timestamp]

So our data model, for now, will be:

 %dataModel =
   [path => [length, checksum, signing-handle, inner-timestamp]]
   [path => [length, checksum, signing-handle, inner-timestamp]]
[33:

Mon Feb  4 08:35:41 2019 Well, now we're wondering we should have
'available-from' and 'bytes-needed' (or something) as well, in the
file info.  Otherwise we're going to have to have that info
elsewhere, right, and somehow link it to this?

Well, finish the mfz metadata gathering first, then come back to
this. 

:33]
and that's all..[32:

Mon Feb  4 02:11:10 2019 Well, let's also keep an array of files to
check, that we can munch through one by one without hoping to keep a
directory handle open for long periods of time..

:32]

:31]

:30]
:29]

:28]

:27]
[34:

Mon Feb  4 09:54:10 2019 Well, alright, finally, here we are needing
to announce the existence of a file an alive cdm neighbor.  What's the
CDM packet type and format for that?

'B' because it's next after 'A'?  Doh.  'B' for 'Be aware'? 'C' for
content?  'F' for file?  'I' for info?  'M' for MFZ?

'F' for file I guess.
[45: SEE :44: BELOW  :45]
0x80 | dir, 0x03, 'F', len+filename, len+checksum, len+innertimestamp?
How big is that??

max    1/1   1/2   1/3 1/4 36/40     1/41 16/57    1/58 10/68

:34]
[35:

Mon Feb  4 10:33:01 2019 Well, I suspect I now know what happens once
the tx buffers fill up..  I suspect this is what happens:

    Feb  4 10:27:59 beaglebone kernel: [127827.790882] itc_pkt rpmsg0: timeout waiting for a tx buffer
    Feb  4 10:27:59 beaglebone kernel: [127827.796695] itc_pkt itc!pru0: Transmission on rpmsg bus failed -512
    Feb  4 10:29:11 beaglebone kernel: [127899.741438] itc_pkt rpmsg0: timeout waiting for a tx buffer
    Feb  4 10:29:11 beaglebone kernel: [127899.747269] itc_pkt itc!pru0: Transmission on rpmsg bus failed -512
    Feb  4 10:29:47 beaglebone kernel: [127935.828735] itc_pkt rpmsg0: timeout waiting for a tx buffer
    Feb  4 10:29:47 beaglebone kernel: [127935.834543] itc_pkt itc!pru0: Transmission on rpmsg bus failed -512
    Feb  4 10:30:45 beaglebone kernel: [127993.699574] itc_pkt rpmsg1: timeout waiting for a tx buffer
    Feb  4 10:30:45 beaglebone kernel: [127993.705409] itc_pkt itc!pru1: Transmission on rpmsg bus failed -512

And sitting here I can't think of any existing way to flush tx buffers
except reboot or possibly reload itc_pkt.ko..[36:

Mon Feb  4 10:40:01 2019 Well, in this case

    Error: Bad address at ./apps/t2/cdm/cdm.pl line 49.
    root@beaglebone:/home/t2/T2-12# modprobe -r itc_pkt
    root@beaglebone:/home/t2/T2-12# modprobe itc_pkt
    root@beaglebone:/home/t2/T2-12#

seemed to work (it shut down and rebooted the PRUs and everything), so
we'll go with that for now..
[37:

Mon Feb  4 10:51:43 2019 Maybe we shouldn't even queue a packet for
transmission unless we believe we have PS.  You shouldn't try to route
a packet toward an ITC unless you believe it has PS.  [38:

Mon Feb  4 11:23:59 2019 OK, we think we can do that pretty
reasonably..  What errno do we want to throw if you try it?[39:

Mon Feb  4 11:27:53 2019 Well, let's try -EHOSTUNREACH and see how we
like that..

:39]

:38]

:37]
:36]

:35]
[40:

Mon Feb  4 19:14:13 2019 OK, back in town getting stuff set up
again.[41:

Mon Feb  4 20:51:08 2019 Well that took longer than it should've but
we're now correctly parsing the CDM F type packet info, and we need to
decide how to store that info before we actually have the file in.

Let's start by adding a status field to finfo.  Status "Got"
means we have the whole file, it checks, and we can serve pieces of it
to anybody that asks.  Status "Need" means we are missing some or all
of the file.  ..Or more minimally, we could just have a count of the
bytes-from-the-front that we currently think we do have, and if that's
less than the length we ask somebody for the next segment.  How do we
know who to ask?  Keep a list of dirs that have offered it.  Pick at
random.  Drop dirs from the list every so often.  [42:

Mon Feb  4 21:32:54 2019 So, add 'currentLength', initially 0, and
'checkedLength', also initially 0.  When 'currentLength' is less than
'length', request a chunk starting at currentLength from anybody is
advertising the content.

When currentLength reaches length, go on to mfzrun checking, and when
that succeeds, set checkedLength to length.   Once checkedLength is
equal to length, start advertising the file.

Request a chunk with a CDM C type packet, for 'chunk' or 'content'
Format of C type is:
[59: SEE :58: BELOW  :59]
0x80 | dir, 0x03, 'C', len+filename, len+checksum, len+startingIndex

Host seeing a 'C' packet immediately checks if they have the file and
its checkedLength is greater than the requested starting index.  If
so, host replies with a CDM D type packet providing 'data'.  Format of
D type is:
[60: DITTO SEE :58:  :60]
0x80 | dir, 0x03, 'D', len+filename, len+checksum, len+startingIndex

[43:

Mon Feb  4 21:55:30 2019 OK well it's obviously a huge drag to have to
send the file name and checksum over and over in every C type
request.  We're going to add a 'tag' to the 'F' packet advertisement
-- like a stock number -- that is locally unique to the advertiser and
which can be used to refer to the content when talking to that
advertiser.  We'll take some bits from the file name, the checksum,
and the innertimestamp, and append an incrementing number.

SKU:  firstLetterOfFilename+4hexchecksumprefix+3loworderdigitsoftime+lexincr

SKU lexincr is assigned when the content is checked.  The point of the
identifying info is to help disambiguate the case where a neighbor cdm
restarts, for whatever reason, and starts handing out the same
lexincrs.

[44:

Mon Feb  4 22:13:23 2019 So F type becomes
[62: SEE :61: BELOW  :62]
0x80 | dir, 0x03, 'F', len+filename, len+checksum, len+innertimestamp, len+incr

and when we receive an F we need to store the incr with the associated
dir that we got it from.
[47:

Mon Feb  4 23:04:11 2019 Umm don't we need the content length too?
Else how do we know when we're done?

Adding length to F type.  Also fuck it let's cut the checksum in half.

:47]
And we need to refactor the F parsing to make the len+foo stripping
much more automatic..

:44]

:43]
:42]
:41]

:40]
[46:

Mon Feb  4 22:43:13 2019 And we're going to have to be veeeery careful
about making and distributing updates that affect the cdm protocol
itself.  We ultimately want to distribute cdm using cdm, which means
adjacent protocol versions must always be forward and backward
compatible. 

While at the moment we don't even have a cdm protocol version.

I think a basic rule is that we shouldn't get pissed if there's extra
crap at the end of a packet, and future versions must only add shit at
the end, or else deal with the backward compatibility.

But anyway, we're just accepting that as technical debt at the moment.
CONTENT MUST MOVE!  NOW NOW NOW. 

 :46]
[48:

Tue Feb  5 00:36:11 2019 So, we really need to keep the pending files
separate from the 'good content' files.  If cdm restarts with
incomplete files sitting in /data/common, it's going to be a huge mess
at best.  Much better to keep in-progress files separate and only cut
them into common when they are complete and checked.

So when we get an advertisement we have a few cases:

(1) We find it complete and matched in common/.  We ignore the
    advertisement.  Also ignore it if the name is in common/ but we
    can't check it yet.

(2) It's absent from common/ and pending/.  We create a record for it
    pending/, with the dir and sku of the advertiser.

(3) It's present and matched in pending/.  We add or refresh the dir
    and seqno in the record.

(4) We find it complete but mismatching in common/.  If we dominate,
    ignore the advertisement.  If they dominate, remove our complete
    from common/ (or move it to archive/ somehow) and continue at (2)

(5) We find it complete but mismatching in pending/.  If we dominate,
    ignore the advertisement.  If they dominate, remove our pending
    from pending/ and continue at (2).

Beyond that, we 'just' flush pending/ when we start up, And Then
Everything Just Works No Really.

:48][49:

Tue Feb  5 02:58:42 2019 Well, we have to get to shooting the video
and we're not 'technically' going to have INTERTILE S/W in a form I
would consider acceptable if I was grading my work.  But so be it;
tons of yada progress yada.

So current state is we have announcements getting sent and received
and processed plausibly -- leading to stubs in pending/ with metadata,
but we aren't requesting or sending the data chunks.

:49]
[50:

Wed Feb  6 03:52:20 2019 Well, t2sup#217 released an hour late, which
was a bummer, but at least it's out there.  Main extra delay was
zillions of tiny renders trying to get the webcam tile footage mostly
synced to the screengrab audio.

(Plus trying to get the damn CDM stuff working first.  Ahem.)

Now let's foggen get CDM actually MOVING some effen FILES. 

Where we we?  Last design snarl I remember was realizing we really did
want to distinguish common/ and pending/ and to build incoming files
in pending/.

In the implementation, I wasn't sure whether I wanted %dataModel to
contain both although I thought not at first.  But then in the rush I
put both common/ and pending/ stuff in there and it wasn't an instant
disaster because the keys are full paths.  It may well be an issue if
I try to iterate over %dataModel, but that will depend on why I'm
iterating over %dataModel..

[51:

Wed Feb  6 04:11:42 2019 So let's try to see how we'll get to
requesting pieces of that we need![52:

Wed Feb  6 04:13:14 2019 Right now we go to checkAnnouncedFile, where
we do (the easy part of) the logic in :48: above.  We create a
pending/ record for the file, with no seqno and currentLength and
checkedLength both 0.  So now we 'just' have to find that record at
some appropriate time -- under our own initiative, without another
packet coming in.  And that's why we could want pendingModel separate
from dataModel.  Or rename dataModel to commonModel and make
pendingModel as a sibling.

Let's try that.[53:

Wed Feb  6 04:27:11 2019 Right now we are keying on the path
(including the 'common') instead of on the filename.  But I'd think
we'd want to go with the filename instead, and have the common vs
pending distinction in the surrounding table, so we could move finfo
records between tables as we move the associated files between
directories.

Let's try to key on filenames, just that much, and get that
established to our current level of functioning.[54:

Wed Feb  6 05:53:42 2019 Well, we cleaned things up a bit.  Still
struggling with whether finfo's contain their path or not.  Seems like
they need to but then we have to update that when they move.  Let's
have them store their current subdir, remember to update that, and
then build the path when we need it.[55:

Wed Feb  6 06:37:18 2019 OK, did that.  Pushing all this mess out and
then we circle back around to pulling files.

[56:

Wed Feb  6 06:42:49 2019 OK dammit its file pulling time.  Wooly bully
file pully.  First off we'll make a background step to check into
pending for something to do.[57:

Wed Feb  6 07:21:15 2019 OK, so have we defined packets for file
transfer yet? ..yes, back in :42:, but I guess we need to redo it to
include the sku..

[58: 

Wed Feb  6 07:40:21 2019 

Request a chunk with a CDM C type packet, for 'chunk' or 'content'
Format of C type is:

0x80 | dir, 0x03, 'C', len+filename, len+sku, len+startingIndex

A CDM D type packet provides 'data'.  Format of D type is:

0x80 | dir, 0x03, 'D', len+filename, len+sku, len+startingIndex, len+data

How much data in a D?  Well, something up to the rest of the packet, I
guess.  Filename, sku, startingIndex are all variable length.  Could
we go just with the sku in type C and type D?  Review the sku!

:43: Well the problem is what happens if a remote cdm restarts and
therefore restarts its 'unique' incrementing numbers?  Well so what?
We'll probably want a 'nack' D format anyway for when people ask for a
sku that we don't have, for whatever reason.  So let's redo.

:58]

:57]

:56]
:55]

:54]

:53]

:52]

:51]

:50]
[61:

Wed Feb  6 08:09:56 2019 Redoing the doc for type F, C, and D:

F type: File announcment

0x80 | dir, 0x03, 'F', len+filename, len+contentlength, len+checksum, len+innertimestamp, len+seqno

C type: Content request

0x80 | dir, 0x03, 'C', len+sku, len+startingIndex

D type: Data reply

Format 1 (C denied): 0x80 | dir, 0x03, 'D', len+sku, 0, 

Format 2 (Has data): 0x80 | dir, 0x03, 'D', len+sku, len+startingIndex, len+data, 2+hack16

:61]
[63:

Wed Feb  6 08:41:33 2019 OK, implementing that stuff.  Just changed
otherSeqnos from an array ref to a hash ref, because scanning the
array for a random neighbor pick seems a pain.  But that raised the
question: How do we age information out of otherSeqnos?  We don't want
to be wasting time sending C types to neighbors that won't respond.

One possibility is to only keep the most-recently-announced neighbor
with the content, rather than trying to keep all of them.  We may end
up pounding a single guy for a while, even though other neighbors
might have the content, but, hey, the guy did advertise having the
content..  And if another advertisement comes in while we're pulling
content, we'll switch.

Well, let's try that.  [64:

Wed Feb  6 08:48:46 2019 But it's a (dir,seqno) pair we have to
remember, not just one item...  Arrays or hashes do that naturally..
Maybe whenever an advertisement comes in we'll randomly age out
previous occupants.

:64]

:63]
[65:

Wed Feb  6 09:56:14 2019 OK, we're sending C type requests finally:

    REQUEST(ƒC
    c9273844110)

making the neighbors say:

    UNHANDLED PKT(\207^CC
    c9273844110)

So it's time for a D type handler and then push all this again..

:65]
[66:

Wed Feb  6 10:13:14 2019 Aaaand how do we map from sku back to finfo?
You'd really think I'd see this type of thing coming by now.  I guess
we keep a seqno->filename map on top of everything else.  Add to it
whenever we burn a seqno.  Map only grows on content churn which is
expected to be low.

And we're only going to serve content from common/, so we only need to
look for finfos there.[67:

Wed Feb  6 17:44:37 2019 Buuut we receive content into pending/, so we 
also have to look for finfos by sku in there.  We can't just have the
one global seqno map and use it for inbound D types.  seqno's are only
unique on per-neighbor, we have to store and look them up on that
basis.  Now, we have this neighborModel, don't we?  ..%hoodModel.
What all's in there?[68:

Wed Feb  6 21:05:23 2019 Well it seems the top level of the two-level
%cdmModel hash is really about the same thing as the %hoodModel and
they ought to be merged together.  But do I have the strength to do
that before seeing this damn thing work even once?

What's the alternative?  What's the quick hack to try?  Add a
seqno->filename map as like $hoodModel->{$dir}->{contentOffered},
update that as announcements are seen, and look up skus in that.

Yeah well let's try that.[69:

Wed Feb  6 21:22:04 2019 Well the checkSKUIn stuff needs refactored
even for the hack, though.  Passing the subdir isn't what we really
want.

If we redid the %hoodModel to be on top, and used some special code to
represent ourselves in the hood, it would probably be significantly
cleaner in the end..  But let's get this working first, gah down boy.
So we need to redo checkSKUIn to be checkSKUInDir, and use dir==8 to
mean ourselves?  For ourselves we look in subdir common when we need
the file, for other dirs we use pending.  And we're adding
contentOffered to the hoodModel guys..

:69]

:68]

:67]


:66]
[70:

Wed Feb  6 22:05:15 2019 OK, well, at VERY long last, we have
demonstrated INTERTILE S/W movement.

"clams.mfz, come here, I need you"

and all 863 bytes of clams.mfz is now in pending/, with the same
md5sum as the machine it originated on.

[71:

Wed Feb  6 22:06:56 2019 So, final step in this first round
implementation: Discover the file is complete and move it into
common/.

At that point it should start to move another hop All By It Selfs.

[72:

Wed Feb  6 23:08:19 2019 OK, making progress releasing the arrived
.mfz.  Currently we're hanging because the 'mfzrun list' is
complaining about an unrecognized handle and asking us what we want to
do.

(1) What does 'mfzrun verify' do with an unrecognized handle?
(2) How can we detect an unrecognized handle without having to 
    supply input to a subprocess?[73:

Wed Feb  6 23:13:34 2019 We can check the exit status of 'mfzmake
canvalidate HANDLE' to know if HANDLE is usable.[75:

Thu Feb  7 00:40:02 2019 But, umm, excuse me, meester, MEESTER?  How
do we know what the handle _IS_, until we look into the .mfz file,
which we can't do without mfzrun hanging waiting for input?

:75][74:

Thu Feb  7 00:10:21 2019 Now, down the road, we'd really like for
different handles to be valid for different .mfz's, so we could let
people update their mfmt2 load, for example, without being able to
modify the CDM system itself.  So we'd like the CDM to control
HANDLES.mfz that somehow contains a mapping from .MFZ file to valid
handles for signing on it.

But for now it's fine that clams.mfz fails because we don't know its
handle.

For now let's just add a /cdm/pubkeys directory and -kd to that..


:74]

:73]

:72]
:71]

:70]
[76:

Thu Feb  7 15:44:59 2019 OK, well we now have INTERTILE S/W so that's
a thing.  But it still has a lot of problems and missing bits, and
we're going to have to push back and rethink our guts now that we have
some sense of the issues.  So maybe we'll branch off to logistics and
parts acquisition for a bit, and then circle back around here with a
redesign.  Looking for a somewhat principled way to deal with:

 1. New versions of existing files found on the filesystem
 2. New versions of existing files arriving on the wire
 3. The need to delete files somehow

and also, possibly

 4. The ability to decouple names from content and maintain a content
    cache so that giving

and also

 5. A daemon wrapper loop so that cdm can restart itself (after getting
    an update) simply by exiting.

and also

 6. Include full checksum + signing handle and fingerprint in announcements?

:76]
[77:

Sat Feb 16 03:16:06 2019 OK, we need to advance the cdm story a little
bit.  And obvious next stop is updating existing files.  We already
have an official place for that to die, no?[78:

Sat Feb 16 04:02:54 2019 Yeah, around cdm.pl:778, in
checkAnnouncedFile.  ..But actually we have code trying to handle
outdated common starting at 744.  I guess we need to see that code
blow up to see where we are.

:78]

:77]
[79:

Sat Feb 16 13:46:18 2019 OK, well one issue is that we weren't
updating the file length when we saw a modtime change.  Committing
just that to get it out to the neighbors.

Also seemed to have an issue that calling refreshProvider during a
file transfer could blow the transfer by deleting the pending record
where we were keeping our progress or something?  Saw something like
that but it's not diagnosed yet.

:79]
