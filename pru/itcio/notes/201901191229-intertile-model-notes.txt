{146}  -*- text -*-
[0:

Sat Jan 19 12:29:28 2019 OK, so we've been struggling trying to pick a
userspace interaction/communication model for intertile stuff, and we
then perhaps the current missing link is we need an explicit 'neighbor
tile' abstraction.  Something that's not about the intertile
connection, but about the tile at the far end -- whether we currently
have a such a neighbor or not.

Unsure if it belongs in /dev, /sys/class, or something more userspace,
but perhaps like /dev/tile/ET etc.  For at least some users, we'd like
connection and disconnection events to be reported as just more
packets on some channel that stays open across such things.

And this abstraction would naturally be the place to handle those
currently-unhandled locstd 'P' and 'F' packets that we are currently
dumping to syslog like lost babies.  The /dev/tile/DIR object would
change status as a result, and that would be somehow visible more
broadly in userspace.

Perhaps we should draft a standard local packet type for 'tile event
notices' right now, so that our tile model can have an OoB way to
notify consumers about such changes.

OK, currently 201812171048-packet-format-notes.txt:1: has our
'documentation' for the defined local standard packet types.  0..3 (of
31) are currently in use.  Just take 4?  What is its name?[1:

Sat Jan 19 12:57:57 2019 'Tile Event Packet'?  TEP?  None of the std
loc packet types seem to have manifest constant names yet.[2:

Sat Jan 19 12:59:31 2019 And what is the TEP syntax?  Well, we finally
will not have the direction encoded in it, because that's now implicit
in which tile we are talking to.

So:
TEP := TEP_PKT_TYPE + EVENT_TYPE + OPT_ARGS
TEP_PKT_TYPE := 0xc4
OPT_ARGS     := BYTE*

EVENT_TYPE   :=
 0x00      Illegal
 0x01      Connect
 0x02      Disconnect
 0x03-0xff Reserved

[3:

Sat Jan 19 16:04:54 2019 The tile models, I guess, should provide
services by something like port number, so packets can be
demultiplexed by the tile model.

And I guess the userspace 'server' we're thinking of is the "actual"
tile that the remote tile models are modeling.
[4:

Sat Jan 19 17:21:36 2019 Looking at some FUSE tutorials..  I know
there's plenty of people hating on FUSE but it might be at least a
transition technology for us here as we try to figure out what we
actually want our LKMs to do for us.
[5:

Sun Jan 20 01:06:31 2019 Well, fuse is about what you'd expect -- a
giant pile of callbacks with a lot of fiddly details about
unimplemented flags and fuse-versions and so forth.  We can certainly
figure it out if we really want to but I'd rather have a clearer idea
what we want out of it before we try.

[6:

Sun Jan 20 01:08:10 2019 What are our main use cases?

1. mfmt2 would like to sit on one fd -- preferably via select() but
   perhaps block on a thread -- and receive all intertile mfm packets.

2. mfmt2 would also like to select() on one fd to know when it can
   send an intertile packet?

3. some 'physics daemon' would like to announce and monitor the tile's
   current physics 'version stamp' and do background intertile
   updating of newer versions.

4. at a minimum the physics daemon would manage mfz files; as a
   step-up it could propagate like the T2 repo as well.


5. 'general intertile communications', whatever that might mean?

[7:

Sun Jan 20 04:25:04 2019 Given that it's all about 1 & 2, really, what
about if we draft the reserved bit in

    FIRST BYTE

     Standard Routed Packet Header
      STND LOCL RSV1
     +----------------------------------------+
     |  1 |  0 |  0 |OVRN||EROR|DIR2|DIR1|DIR0|
     +----------------------------------------+

(from /home/t2/T2-12/pru/itcio/notes/201812171048-packet-format-notes.txt:0 )

to be the 'mfm bit'?

      STND LOCL MFMT
     +----------------------------------------+
     |  1 |  0 | 1  |OVRN||EROR|DIR2|DIR1|DIR0|
     +----------------------------------------+

So anything with MFMT set is 'MFM traffic' that would be routed to and
from like /dev/itc/mfm or something, and mfmt2 would select or block
on that.[8:

Sun Jan 20 04:33:55 2019 So, everybody else would do what?  Go through
some single daemon that managed packet services for everybody except
mfm?  And that guy would expect packets like what, perhaps:


      BYTE 0                                   BYTE 1
      STND LOCL MFMT
     +----------------------------------------++---------------------------------------+
     |  1 |  0 | 0  |OVRN||EROR|DIR2|DIR1|DIR0||DST3|DST2|DST1|DST0|SRC3|SRC2|SRC1|SRC0|
     +----------------------------------------++---------------------------------------+

and we'd support up to sixteen random packet service ports.  Or I
suppose we could go to a three byte header, jeez.[9:

Sun Jan 20 04:54:44 2019 And how would people offer and use those
services.  Open /dev/itc/svc/ff for RDWR|NONBLOCK or something?  But
then do we even need a distinct source port, or is everything peer to
peer?  That would be flavorful.
[13:

Thu Jan 31 00:36:25 2019 So, we're back here, and we have a public
challenge to get software moving between tiles before next t2sday.

So, picking up the discussion in :8:, we need to pull the trigger on a
format for STND,!LOCL,!MFMT packets.

Do we NEED source ports?  Well, why do source ports exist?  So that
multiple 'clients' can talk to one 'server'.  Now, in basic intertile
land, we are ONLY talking to neighboring tiles and are NOT routing
beyond that.  And the source DIRECTION is already present in the BYTE0
header, so clients on different neighboring tiles are already
distinguishable.

So these multiple clients, if we had them, would have to be all on a
SINGLE neighboring tile.  Do we really need that?  Well, what if we
wanted to update a bunch of files amongst our neighbors?  We might be
newer on some files and some of our neighbors might be newer on
others.  It would be arguably convenient to just start flows for each
file that has to move in any direction and let their packets get
interleaved however, rather than having to (go to all the onerous
extra trouble to) make a user-level queue or whatever for the files
destined for each neighbor.
[14:

Thu Jan 31 02:40:10 2019 So I guess that example isn't
super-compelling to me.  To the contrary, if we had a peer-to-peer
'managed file update service', we could (more easily) get different
pieces of files from different neighbors and so on.  (Eventually.)

Are there other cases to consider for source ports?[15:

Thu Jan 31 02:46:01 2019 ..I'm just not seeing it.  Screw it, let's go
full-on peer-to-peer and deal with any fall-out as we have to.  Worst
case we can always create a source port model underneath some
peer-to-peer service.

So, we'd be saying something like

      BYTE 0                                   BYTE 1
      STND LOCL MFMT
     +----------------------------------------++---------------------------------------+
     |  1 |  0 | 0  |OVRN||EROR|DIR2|DIR1|DIR0||RSV1|RSV0|SVC5|SVC4|SVC3|SVC2|SVC1|SVC0|
     +----------------------------------------++---------------------------------------+

where we offer up to 63 services (reserving service 0 as null), and
hold a couple of bits for the future.

Aaand we can go ahead and draft a few services here, at least
provisionally?

Say service 1 is a .. what?  Version number?  Liveness ping?  Maybe we
should stick to our knitting here and just say like service 8 is
'managed file update'.  We want a service that just falls towards
having the newest version of all managed files that any neighbor knows
about.  We'll have a directory of the current king of the hill files,
each with a version number and a checksum..[16:

Thu Jan 31 03:17:26 2019 Stop stop stop.  Crawl before fly my god you
have to get something running here.  A directory of MFZ files that are
all to be considered 'legitimates physics-es'.  All have to be signed
by a known key.  We go by the timestamp in the mfz to decide if a file
is newer.  As an idle background process, we send random mfz+timestamp
info to random neighbors every so often.  If we receive word about an
MFZ that we don't have or that's newer than what we do have, we
request that file.  The source starts streaming it to us.  We assemble
it in a temporary directory.  When/if it arrives completely and we
verify it locally, we (atomically-ish) cut it over into the live
directory, and that's when it will start getting broadcast to our
neighbors.

Somehow we have a way -- perhaps a different service in fact -- of
saying it's time to change physics, which we handle by shutting down
MFM and restarting it on a new MFZ.

For now we still won't have intertile events, so there's no issue yet
of mfm needing to check that neighbors are on the same MFZ.

:16]

:15]

:14]

:13]
:9]


:8]

:7]


:6]

:5]
:4]
:3]


:2]

:1]

:0]
[10:

Sun Jan 20 08:02:15 2019 But, I need to see something anything proof
of concept minimal crap actually working here, for me to feel
comfortable.

I want a Perl script daemon that

1. Watches the modification date of some counter file, and reloads it
   whenever it changes.

2. And advertises its counter value by sending it to all active
   neighbors every minute or so.

3. And tracks the counters of all active neighbors by monitoring their
   counter value advertisements.

4. And

:10]
[11:

Wed Jan 30 22:37:52 2019 Aaand, to make the guts of that work, we need
a way to send a file.  Which is a stream of bytes, plus metadata,
which has to be packetized, sent, received, and reassembled.

Aaaaad, damn the NIH torpedoes aaand damn the RTW (Reinventing The
Wheel) nay-sayers and let's just MAKE OUR OWWWWWWWWN.

[12:

Wed Jan 30 22:40:56 2019 So.  We need packet formats for metadata and
data stream.  We have some structure for such things already set up,
so we should find that.

:12]

:11]
[17:

Sat Feb  2 23:50:04 2019 Aaaand we're back.  [18:

Sun Feb  3 01:04:12 2019 So we're making 'cdm.pl', a demo 'common data
manager' script that, as far as I can tell right now, will have
essentially no user interface at all.  It will hog all the packets on
/dev/itc/packets -- a device which should, once mfmt2 exists, NOT
include mfm traffic -- and build a model of its own and its neighbors
common data, and automatically send updates as needed so that
everybody falls towards having an equivalent view of what counts as
the latest common data.  cdm.pl will generate output along the lines
of log messages about what's going on, but that's about it.

But first, nap.[19:

Sun Feb  3 02:36:19 2019 Well, maybe not nap yet.

Structures for file/directory model:

 @content => (sha512-of-content content-length-bytes path-to-content)


:19]

:18]


:17]
[20:

Sun Feb  3 04:44:54 2019 OK, say service 3 is CDM_PKT_TYPE.  Format
is:

      BYTE 0                                   BYTE 1                                   BYTE 2
      STND LOCL MFMT
     +----------------------------------------++---------------------------------------++----------------+
     |  1 |  0 | 0  |OVRN||EROR|DIR2|DIR1|DIR0||   0|   0|   0|   0|   0|   0|   1|   1|| CDM PKT TYPE   |...
     +----------------------------------------++---------------------------------------++----------------+

 => 0x80 | dir, 0x03, code, args..  Why service 3?  Because that's ^C
for 'CDM'?  Whatever.

And our first code is 'A'live, a liveness ping.  Let's implement that
and foggen PROCESS A PACKET.[21:

Sun Feb  3 05:17:49 2019 OK, so there it is.  Mr NW sent
'\203^CA' packets and Mr SE sent '\207^CA' packets, and Mr NW received
'\203^CA' packets and Mr SE received '\207^CA' packets.

Which seems like they could just be talking to themselves.. but the
dirs get remapped from dst->src as they move intertile.  (Which I just
confirmed by adding a random number payload to distinguish the 'A'
packet.)

So.  Progress.  Now nap.  (What _is_ happening to those packets we're
sending to unconnected tiles, hmm?)

:21]

:20]
[22:

Sun Feb  3 11:47:53 2019 OK, so, let's have a primitive neighbor model
to maintain and grow:

 - Direction to ngb
 - Time we last got an Alive pkt from them
 - Time we last sent an Alive pkt to them

I guess we ought to do 'object hash' style.  This is likely to grow
hunh?

Also, maybe we shouldn't use wall-clock time, but just
count-of-background-works or something.  We really want to avoid
leaning on absolute time if we don't need it.  We'll call an entry to
doBackgroundWork a.. what?  'Ticks' is way too overloaded already.
'Tocks'?  Just makes you look around for ticks.

'Background Work' -> 'Borks'?  Probably too distracting.. 'Clicks'?
Maybe.  'Clacks'?  Ooh, better :).  Like machinery!  Big old
steam-powered machinery suitable for slow background tasks.

[23:

Sun Feb  3 12:27:00 2019 Do we actually need even clacks, in the sense
of it being an absolute count of doBackgroundWork calls?  We're facing
count-to-infinity if we want absolute clacks.  And all we really need
is 'clack intervals' anyway, right?  Couldn't we do countdowns
instead?  And we don't even need countdowns if we seriously drink our
own koolaid and do 'stats instead of state'.  Every time we pick a ngb
to consider, we have some odds of sending it an Alive..  And if we
have it flagged as alive, we have some odds of clearing that flag.
Like 1 in 25 to send our Alive, 1 in 100 to clear their alive.

Going all-stats might be get pretty raggedy, though, for something
we're thinking of as fairly low-level.  Could mix it, stats to send
our alive but a countdown to expire their Alive?  Or countdown for
both but reset them to random range.  Or countup with random
expiration. [24:

Sun Feb  3 13:07:20 2019 Now, wait a minute.  Do we even need
aliveness packets given we have the credible and much lower-level
notion of packet sync?  Well, it's not about need, it's about
robustness.  If we have PS but aren't getting alive packets, our
neighbor has got problems in middle management.

Suppose we create an apoptosis signal packet -- a pretty low-level
one, that's handled in the LKM.  One such packet doesn't mean much,
but getting them frequently from multiple neighbors should be a sign
that we should try to make a note of the situation somewhere and then
reboot.

:24]

:23]

:22]
[25:

Sun Feb  3 14:21:27 2019 Well, we have two reserved bits in byte 1 of
standard routed tile (as opposed to mfm) packets.  I'm wondering about
drafting either or both as a 'network level' indicator or something,
like:

 00 User space
 01 LKM
 10 PRU reserved
 11 Illegal reserved

where 'normal' cdm packets would be 00 but apoptosis packets would be
01.

I suppose a more 'port-like' approach would be just reserve a low
range of service numbers to be 'system' level.[26:

Sun Feb  3 14:42:03 2019 BUT IN ANY FOGGEN EVENT I SHOULDN'T BE
DESIGNING INTERTILE APOPTOSIS RIGHT THE FOG NOW.  Sheesh.

:26]

:25]
[27:

Mon Feb  4 00:38:22 2019 OK, also want a data model to describe our
view of the common/ directory.  At least, stuff about file paths,
sizes, and checksums.  We're still struggling to define our
relationship with wall-clock time: We don't think we really need it,
and we don't think it's all that scalable, but it's what the
filesystem is going to be using so what do we do?

Fundamental data model question: When should some content count as a
new version of an existing name?[28:

Mon Feb  4 00:52:59 2019 All we really have at the moment is the
internal timestamp on mfz files.  We can get at that using the
extended version of 'mfzrun verify':

    ackley@coldaynell:~/PART4/code/D$ ./MFM/bin/mfzrun ../E/MFM/res/elements/demos/ForkBombs.mfz VERIFY
    SIGNATURE_CHECK [OK]
    INNER_CHECKSUM [2aafbf-aa30-a86bc6]
    INNER_TIMESTAMP [1536398164]
    SIGNING_HANDLE [MFM-DEMOS-20180908031520-ulam-3.0.12-ackley]
    HANDLE_FINGERPRINT [e1bf-234-7029]
    HANDLE_PUBKEY [-----BEGIN RSA PUBLIC KEY-----
    MIGJAoGBALdLR5qmGltWAx7Kt5yBAiNQbElAT9UuAjVNZCdHYTuTRckeyhNNF0VS
    0mKBAKAyzLXIG4yXJVCw5s/lx2J3DCcXOv62tNDL8uPpqM3PiGlSv+R5iSvDv27m
    mNpHxXYIwfrpaHLPSngPyYa3P31r8gRCka+K8IiF9dimYMjan+N/AgMBAAE=
    -----END RSA PUBLIC KEY-----
    ]

which absolutely does depend on absolute time, but, because it's also
signed by someone we've been told to trust, we're inclined to believe
that successive INNER_TIMESTAMPs will be legitimately comparable
within a given mfz name.[29:

Mon Feb  4 01:18:56 2019 Another natural, modrun possibility is
working off a git repo and deriving version precedence from successive
commits on a given path.  But that brings an awful lot of
infrastructure with it -- not necessarily bad infrastructure, but not
necessarily infrastructure we want to fundamentally depend upon
either.

Back in IXM-land a decade ago, we had 'green boot', 'blue boot', and
'red boot'.  Green boot accepted wall-clock-newer code from anybody,
blue required wall-clock-newer plus matching the current 'program id',
and red wouldn't accept new code at all without a physical button
press during boot up.

We could say a physical button-press is required to add something to
/data/common?  But how would that work?  We accept any contents in
/data/common when cdm.pl starts up, so put new crap in then restart.

[30:

Mon Feb  4 01:34:39 2019 Well, fog it, we have to get off the dime
here.  For today let's only consider .mfz files, let's checksum them
externally and recheck the checksums from time to time, and when they
change we use mfzrun VERIFY to get the internal timestamp, and if the
internal timestamp beats what we're holding we propagate it.

One practical problem is that mfzrun VERIFY is only in the github,
it's not in the MFM-4.0.12 that the tiles are using.  Now, I guess for
the moment we could just use 'mfzrun list' and take the time of the
MFZPUBKEY.DAT file as proxy for the 'internal timestamp'.

Let's do that.  Damn the torpedoes.

[31:

Mon Feb  4 01:40:45 2019 So, one cdm background task is load/refresh
an .mfz file.

The file info we'll keep is:

  [path, length, checksum, signing-handle, timestamp]

The file info we'll send to neighbors is

  [path, timestamp]

So our data model, for now, will be:

 %dataModel =
   [path => [length, checksum, signing-handle, inner-timestamp]]
   [path => [length, checksum, signing-handle, inner-timestamp]]
[33:

Mon Feb  4 08:35:41 2019 Well, now we're wondering we should have
'available-from' and 'bytes-needed' (or something) as well, in the
file info.  Otherwise we're going to have to have that info
elsewhere, right, and somehow link it to this?

Well, finish the mfz metadata gathering first, then come back to
this.

:33]
and that's all..[32:

Mon Feb  4 02:11:10 2019 Well, let's also keep an array of files to
check, that we can munch through one by one without hoping to keep a
directory handle open for long periods of time..

:32]

:31]

:30]
:29]

:28]

:27]
[34:

Mon Feb  4 09:54:10 2019 Well, alright, finally, here we are needing
to announce the existence of a file an alive cdm neighbor.  What's the
CDM packet type and format for that?

'B' because it's next after 'A'?  Doh.  'B' for 'Be aware'? 'C' for
content?  'F' for file?  'I' for info?  'M' for MFZ?

'F' for file I guess.
[45: SEE :44: BELOW  :45]
0x80 | dir, 0x03, 'F', len+filename, len+checksum, len+innertimestamp?
How big is that??

max    1/1   1/2   1/3 1/4 36/40     1/41 16/57    1/58 10/68

:34]
[35:

Mon Feb  4 10:33:01 2019 Well, I suspect I now know what happens once
the tx buffers fill up..  I suspect this is what happens:

    Feb  4 10:27:59 beaglebone kernel: [127827.790882] itc_pkt rpmsg0: timeout waiting for a tx buffer
    Feb  4 10:27:59 beaglebone kernel: [127827.796695] itc_pkt itc!pru0: Transmission on rpmsg bus failed -512
    Feb  4 10:29:11 beaglebone kernel: [127899.741438] itc_pkt rpmsg0: timeout waiting for a tx buffer
    Feb  4 10:29:11 beaglebone kernel: [127899.747269] itc_pkt itc!pru0: Transmission on rpmsg bus failed -512
    Feb  4 10:29:47 beaglebone kernel: [127935.828735] itc_pkt rpmsg0: timeout waiting for a tx buffer
    Feb  4 10:29:47 beaglebone kernel: [127935.834543] itc_pkt itc!pru0: Transmission on rpmsg bus failed -512
    Feb  4 10:30:45 beaglebone kernel: [127993.699574] itc_pkt rpmsg1: timeout waiting for a tx buffer
    Feb  4 10:30:45 beaglebone kernel: [127993.705409] itc_pkt itc!pru1: Transmission on rpmsg bus failed -512

And sitting here I can't think of any existing way to flush tx buffers
except reboot or possibly reload itc_pkt.ko..[36:

Mon Feb  4 10:40:01 2019 Well, in this case

    Error: Bad address at ./apps/t2/cdm/cdm.pl line 49.
    root@beaglebone:/home/t2/T2-12# modprobe -r itc_pkt
    root@beaglebone:/home/t2/T2-12# modprobe itc_pkt
    root@beaglebone:/home/t2/T2-12#

seemed to work (it shut down and rebooted the PRUs and everything), so
we'll go with that for now..
[37:

Mon Feb  4 10:51:43 2019 Maybe we shouldn't even queue a packet for
transmission unless we believe we have PS.  You shouldn't try to route
a packet toward an ITC unless you believe it has PS.  [38:

Mon Feb  4 11:23:59 2019 OK, we think we can do that pretty
reasonably..  What errno do we want to throw if you try it?[39:

Mon Feb  4 11:27:53 2019 Well, let's try -EHOSTUNREACH and see how we
like that..

:39]

:38]

:37]
:36]

:35]
[40:

Mon Feb  4 19:14:13 2019 OK, back in town getting stuff set up
again.[41:

Mon Feb  4 20:51:08 2019 Well that took longer than it should've but
we're now correctly parsing the CDM F type packet info, and we need to
decide how to store that info before we actually have the file in.

Let's start by adding a status field to finfo.  Status "Got"
means we have the whole file, it checks, and we can serve pieces of it
to anybody that asks.  Status "Need" means we are missing some or all
of the file.  ..Or more minimally, we could just have a count of the
bytes-from-the-front that we currently think we do have, and if that's
less than the length we ask somebody for the next segment.  How do we
know who to ask?  Keep a list of dirs that have offered it.  Pick at
random.  Drop dirs from the list every so often.  [42:

Mon Feb  4 21:32:54 2019 So, add 'currentLength', initially 0, and
'checkedLength', also initially 0.  When 'currentLength' is less than
'length', request a chunk starting at currentLength from anybody is
advertising the content.

When currentLength reaches length, go on to mfzrun checking, and when
that succeeds, set checkedLength to length.   Once checkedLength is
equal to length, start advertising the file.

Request a chunk with a CDM C type packet, for 'chunk' or 'content'
Format of C type is:
[59: SEE :58: BELOW  :59]
0x80 | dir, 0x03, 'C', len+filename, len+checksum, len+startingIndex

Host seeing a 'C' packet immediately checks if they have the file and
its checkedLength is greater than the requested starting index.  If
so, host replies with a CDM D type packet providing 'data'.  Format of
D type is:
[60: DITTO SEE :58:  :60]
0x80 | dir, 0x03, 'D', len+filename, len+checksum, len+startingIndex

[43:

Mon Feb  4 21:55:30 2019 OK well it's obviously a huge drag to have to
send the file name and checksum over and over in every C type
request.  We're going to add a 'tag' to the 'F' packet advertisement
-- like a stock number -- that is locally unique to the advertiser and
which can be used to refer to the content when talking to that
advertiser.  We'll take some bits from the file name, the checksum,
and the innertimestamp, and append an incrementing number.

SKU:  firstLetterOfFilename+4hexchecksumprefix+3loworderdigitsoftime+lexincr

SKU lexincr is assigned when the content is checked.  The point of the
identifying info is to help disambiguate the case where a neighbor cdm
restarts, for whatever reason, and starts handing out the same
lexincrs.

[44:

Mon Feb  4 22:13:23 2019 So F type becomes
[62: SEE :61: BELOW  :62]
0x80 | dir, 0x03, 'F', len+filename, len+checksum, len+innertimestamp, len+incr

and when we receive an F we need to store the incr with the associated
dir that we got it from.
[47:

Mon Feb  4 23:04:11 2019 Umm don't we need the content length too?
Else how do we know when we're done?

Adding length to F type.  Also fuck it let's cut the checksum in half.

:47]
And we need to refactor the F parsing to make the len+foo stripping
much more automatic..

:44]

:43]
:42]
:41]

:40]
[46:

Mon Feb  4 22:43:13 2019 And we're going to have to be veeeery careful
about making and distributing updates that affect the cdm protocol
itself.  We ultimately want to distribute cdm using cdm, which means
adjacent protocol versions must always be forward and backward
compatible.

While at the moment we don't even have a cdm protocol version.

I think a basic rule is that we shouldn't get pissed if there's extra
crap at the end of a packet, and future versions must only add shit at
the end, or else deal with the backward compatibility.

But anyway, we're just accepting that as technical debt at the moment.
CONTENT MUST MOVE!  NOW NOW NOW.

 :46]
[48:

Tue Feb  5 00:36:11 2019 So, we really need to keep the pending files
separate from the 'good content' files.  If cdm restarts with
incomplete files sitting in /data/common, it's going to be a huge mess
at best.  Much better to keep in-progress files separate and only cut
them into common when they are complete and checked.

So when we get an advertisement we have a few cases:

(1) We find it complete and matched in common/.  We ignore the
    advertisement.  Also ignore it if the name is in common/ but we
    can't check it yet.

(2) It's absent from common/ and pending/.  We create a record for it
    pending/, with the dir and sku of the advertiser.

(3) It's present and matched in pending/.  We add or refresh the dir
    and seqno in the record.

(4) We find it complete but mismatching in common/.  If we dominate,
    ignore the advertisement.  If they dominate, remove our complete
    from common/ (or move it to archive/ somehow) and continue at (2)

(5) We find it complete but mismatching in pending/.  If we dominate,
    ignore the advertisement.  If they dominate, remove our pending
    from pending/ and continue at (2).

Beyond that, we 'just' flush pending/ when we start up, And Then
Everything Just Works No Really.

:48][49:

Tue Feb  5 02:58:42 2019 Well, we have to get to shooting the video
and we're not 'technically' going to have INTERTILE S/W in a form I
would consider acceptable if I was grading my work.  But so be it;
tons of yada progress yada.

So current state is we have announcements getting sent and received
and processed plausibly -- leading to stubs in pending/ with metadata,
but we aren't requesting or sending the data chunks.

:49]
[50:

Wed Feb  6 03:52:20 2019 Well, t2sup#217 released an hour late, which
was a bummer, but at least it's out there.  Main extra delay was
zillions of tiny renders trying to get the webcam tile footage mostly
synced to the screengrab audio.

(Plus trying to get the damn CDM stuff working first.  Ahem.)

Now let's foggen get CDM actually MOVING some effen FILES.

Where we we?  Last design snarl I remember was realizing we really did
want to distinguish common/ and pending/ and to build incoming files
in pending/.

In the implementation, I wasn't sure whether I wanted %dataModel to
contain both although I thought not at first.  But then in the rush I
put both common/ and pending/ stuff in there and it wasn't an instant
disaster because the keys are full paths.  It may well be an issue if
I try to iterate over %dataModel, but that will depend on why I'm
iterating over %dataModel..

[51:

Wed Feb  6 04:11:42 2019 So let's try to see how we'll get to
requesting pieces of that we need![52:

Wed Feb  6 04:13:14 2019 Right now we go to checkAnnouncedFile, where
we do (the easy part of) the logic in :48: above.  We create a
pending/ record for the file, with no seqno and currentLength and
checkedLength both 0.  So now we 'just' have to find that record at
some appropriate time -- under our own initiative, without another
packet coming in.  And that's why we could want pendingModel separate
from dataModel.  Or rename dataModel to commonModel and make
pendingModel as a sibling.

Let's try that.[53:

Wed Feb  6 04:27:11 2019 Right now we are keying on the path
(including the 'common') instead of on the filename.  But I'd think
we'd want to go with the filename instead, and have the common vs
pending distinction in the surrounding table, so we could move finfo
records between tables as we move the associated files between
directories.

Let's try to key on filenames, just that much, and get that
established to our current level of functioning.[54:

Wed Feb  6 05:53:42 2019 Well, we cleaned things up a bit.  Still
struggling with whether finfo's contain their path or not.  Seems like
they need to but then we have to update that when they move.  Let's
have them store their current subdir, remember to update that, and
then build the path when we need it.[55:

Wed Feb  6 06:37:18 2019 OK, did that.  Pushing all this mess out and
then we circle back around to pulling files.

[56:

Wed Feb  6 06:42:49 2019 OK dammit its file pulling time.  Wooly bully
file pully.  First off we'll make a background step to check into
pending for something to do.[57:

Wed Feb  6 07:21:15 2019 OK, so have we defined packets for file
transfer yet? ..yes, back in :42:, but I guess we need to redo it to
include the sku..

[58:

Wed Feb  6 07:40:21 2019

Request a chunk with a CDM C type packet, for 'chunk' or 'content'
Format of C type is:

0x80 | dir, 0x03, 'C', len+filename, len+sku, len+startingIndex

A CDM D type packet provides 'data'.  Format of D type is:

0x80 | dir, 0x03, 'D', len+filename, len+sku, len+startingIndex, len+data

How much data in a D?  Well, something up to the rest of the packet, I
guess.  Filename, sku, startingIndex are all variable length.  Could
we go just with the sku in type C and type D?  Review the sku!

:43: Well the problem is what happens if a remote cdm restarts and
therefore restarts its 'unique' incrementing numbers?  Well so what?
We'll probably want a 'nack' D format anyway for when people ask for a
sku that we don't have, for whatever reason.  So let's redo.

:58]

:57]

:56]
:55]

:54]

:53]

:52]

:51]

:50]
[61:

Wed Feb  6 08:09:56 2019 Redoing the doc for type F, C, and D:

F type: File announcment

0x80 | dir, 0x03, 'F', len+filename, len+contentlength, len+checksum, len+innertimestamp, len+seqno

C type: Content request

0x80 | dir, 0x03, 'C', len+sku, len+startingIndex

D type: Data reply

Format 1 (C denied): 0x80 | dir, 0x03, 'D', len+sku, 0,

Format 2 (Has data): 0x80 | dir, 0x03, 'D', len+sku, len+startingIndex, len+data, 2+hack16

:61]
[63:

Wed Feb  6 08:41:33 2019 OK, implementing that stuff.  Just changed
otherSeqnos from an array ref to a hash ref, because scanning the
array for a random neighbor pick seems a pain.  But that raised the
question: How do we age information out of otherSeqnos?  We don't want
to be wasting time sending C types to neighbors that won't respond.

One possibility is to only keep the most-recently-announced neighbor
with the content, rather than trying to keep all of them.  We may end
up pounding a single guy for a while, even though other neighbors
might have the content, but, hey, the guy did advertise having the
content..  And if another advertisement comes in while we're pulling
content, we'll switch.

Well, let's try that.  [64:

Wed Feb  6 08:48:46 2019 But it's a (dir,seqno) pair we have to
remember, not just one item...  Arrays or hashes do that naturally..
Maybe whenever an advertisement comes in we'll randomly age out
previous occupants.

:64]

:63]
[65:

Wed Feb  6 09:56:14 2019 OK, we're sending C type requests finally:

    REQUEST(ƒC
    c9273844110)

making the neighbors say:

    UNHANDLED PKT(\207^CC
    c9273844110)

So it's time for a D type handler and then push all this again..

:65]
[66:

Wed Feb  6 10:13:14 2019 Aaaand how do we map from sku back to finfo?
You'd really think I'd see this type of thing coming by now.  I guess
we keep a seqno->filename map on top of everything else.  Add to it
whenever we burn a seqno.  Map only grows on content churn which is
expected to be low.

And we're only going to serve content from common/, so we only need to
look for finfos there.[67:

Wed Feb  6 17:44:37 2019 Buuut we receive content into pending/, so we
also have to look for finfos by sku in there.  We can't just have the
one global seqno map and use it for inbound D types.  seqno's are only
unique on per-neighbor, we have to store and look them up on that
basis.  Now, we have this neighborModel, don't we?  ..%hoodModel.
What all's in there?[68:

Wed Feb  6 21:05:23 2019 Well it seems the top level of the two-level
%cdmModel hash is really about the same thing as the %hoodModel and
they ought to be merged together.  But do I have the strength to do
that before seeing this damn thing work even once?

What's the alternative?  What's the quick hack to try?  Add a
seqno->filename map as like $hoodModel->{$dir}->{contentOffered},
update that as announcements are seen, and look up skus in that.

Yeah well let's try that.[69:

Wed Feb  6 21:22:04 2019 Well the checkSKUIn stuff needs refactored
even for the hack, though.  Passing the subdir isn't what we really
want.

If we redid the %hoodModel to be on top, and used some special code to
represent ourselves in the hood, it would probably be significantly
cleaner in the end..  But let's get this working first, gah down boy.
So we need to redo checkSKUIn to be checkSKUInDir, and use dir==8 to
mean ourselves?  For ourselves we look in subdir common when we need
the file, for other dirs we use pending.  And we're adding
contentOffered to the hoodModel guys..

:69]

:68]

:67]


:66]
[70:

Wed Feb  6 22:05:15 2019 OK, well, at VERY long last, we have
demonstrated INTERTILE S/W movement.

"clams.mfz, come here, I need you"

and all 863 bytes of clams.mfz is now in pending/, with the same
md5sum as the machine it originated on.

[71:

Wed Feb  6 22:06:56 2019 So, final step in this first round
implementation: Discover the file is complete and move it into
common/.

At that point it should start to move another hop All By It Selfs.

[72:

Wed Feb  6 23:08:19 2019 OK, making progress releasing the arrived
.mfz.  Currently we're hanging because the 'mfzrun list' is
complaining about an unrecognized handle and asking us what we want to
do.

(1) What does 'mfzrun verify' do with an unrecognized handle?
(2) How can we detect an unrecognized handle without having to
    supply input to a subprocess?[73:

Wed Feb  6 23:13:34 2019 We can check the exit status of 'mfzmake
canvalidate HANDLE' to know if HANDLE is usable.[75:

Thu Feb  7 00:40:02 2019 But, umm, excuse me, meester, MEESTER?  How
do we know what the handle _IS_, until we look into the .mfz file,
which we can't do without mfzrun hanging waiting for input?

:75][74:

Thu Feb  7 00:10:21 2019 Now, down the road, we'd really like for
different handles to be valid for different .mfz's, so we could let
people update their mfmt2 load, for example, without being able to
modify the CDM system itself.  So we'd like the CDM to control
HANDLES.mfz that somehow contains a mapping from .MFZ file to valid
handles for signing on it.

But for now it's fine that clams.mfz fails because we don't know its
handle.

For now let's just add a /cdm/pubkeys directory and -kd to that..


:74]

:73]

:72]
:71]

:70]
[76:

Thu Feb  7 15:44:59 2019 OK, well we now have INTERTILE S/W so that's
a thing.  But it still has a lot of problems and missing bits, and
we're going to have to push back and rethink our guts now that we have
some sense of the issues.  So maybe we'll branch off to logistics and
parts acquisition for a bit, and then circle back around here with a
redesign.  Looking for a somewhat principled way to deal with:

 1. New versions of existing files found on the filesystem
 2. New versions of existing files arriving on the wire
 3. The need to delete files somehow

and also, possibly

 4. The ability to decouple names from content and maintain a content
    cache so that giving

and also

 5. A daemon wrapper loop so that cdm can restart itself (after getting
    an update) simply by exiting.

and also

 6. Include full checksum + signing handle and fingerprint in announcements?

:76]
[77:

Sat Feb 16 03:16:06 2019 OK, we need to advance the cdm story a little
bit.  And obvious next stop is updating existing files.  We already
have an official place for that to die, no?[78:

Sat Feb 16 04:02:54 2019 Yeah, around cdm.pl:778, in
checkAnnouncedFile.  ..But actually we have code trying to handle
outdated common starting at 744.  I guess we need to see that code
blow up to see where we are.

:78]

:77]
[79:

Sat Feb 16 13:46:18 2019 OK, well one issue is that we weren't
updating the file length when we saw a modtime change.  Committing
just that to get it out to the neighbors.

Also seemed to have an issue that calling refreshProvider during a
file transfer could blow the transfer by deleting the pending record
where we were keeping our progress or something?  Saw something like
that but it's not diagnosed yet.[80:

Sat Feb 16 14:20:12 2019 OK, we seem to be propagating updated
versions of a given name.  So that's nice, though the code is gross.

A remaining issue is we're saying 'COMMON CHECKSUM MISMATCH
UNIMPLEMENTED, IGNORED' in response to an -- I think -- out-of-date
announcement.. [81:

Sat Feb 16 14:38:33 2019 OK, shut that up, I think.  Committing this,
though I believe detecting new common/ content in a running cdm is
still untested.

:81]

:80]

:79]
[82:

Sat Feb 16 15:20:53 2019 OK, well, one test of updating a common/ file
while cdm is running appeared to work, so I think maybe we're
galloping on to the next level up.

I think we should start a quick sort of 'command-line content manager'
script that will implement deletion by updating and releasing a
CDM-STATE.mfz file.  There would eventually be a CDM-CODE.mfz as well,
and perhaps a CDM-CONFIG.mfz.  They probably ought to correspond to
distinct subdirs of /cdm, and contain complete copies of same..[83:

Sat Feb 16 17:14:29 2019 So let's move here on this.  What is/are the
dir names? /cdm/{state|code|config}? /cdm/CDM/{state|code|config}?
/cdm/CDM-{STATE|CODE|CONFIG}?

Well, we're going to be special-casing the handling of these things
somehow, so how is that going to be done?  If it works directly off
the .mfz file name, then..

Let's say.. what's the difference between 'state' and 'config'?  Not
really sure yet I guess.  But where do the deleteds go?  In state,
that seems clear.  Where do the rules about what's handled specially
go?  In config?

/cdm/cdm/config/triggers.map

  -> A file mapping common/.mfz filenames to special actions, where
     special actions are like 'unpack to dir X', and 'restart service
     X'.  We don't put these triggers within the .mfz itself,
     apparently, because we want a pretense of separating code and
     data?

/cdm/cdm/state/deleteds.map

  -> A file containing a list of common/.mfz filenames + checksums.
     Every file on the list is (currently) 'deleted': It should be
     removed from common/ if it found, and it should not be announced
     or accepted.

  .. And we'll have a finfo for this?  Separate from the cmd-state.mfz
  that contains it?  Or no, just as part of triggering on cdm-state
  we'll reload this thing.  And at boot time?  That does seem like a
  finfo.  But this file, itself, is not shared.  When a new version of
  it appears, we don't pick it up and announce it.

What if there's no explicit 'unpacked' directory at all?  We'll have a
current CDM-STATE.mfz file in common/, and we'll have a special rule
so that on loading that (right after checksum success time, I guess),
we'll unpack it into /tmp or memory and process the info immediately.

Could it be a common/MFMT2-STATE.mfz that starts up mfmt2 (aka mfms at
the moment)?  So there wouldn't even be a systemd service to start up
mfm, just cdm?  And then cdm would start up mfm, etc?  That makes a
certain amount of sense.  Not sure how we make it robust though.

I guess mfmt2 needs a layer or two of robustness on its own.  A driver
script that just restarts it if it dies.  We'll see.[84:

Sun Feb 17 00:40:26 2019 So I realized the fact that we can just
wily-nily rename files and have them look new is evidence of the fact
that we can't or shouldn't rely just on file names for 'magic
triggering' purposes, or we open ourselves to DoS attacks at least.
Even filename + handle won't do it, since it's easy to copy signed
files to a new filename.

The signature applies only to the content, not to the filename.

So when we want to trigger on a special file, we want the manifest
inside the file to have the form we are expecting.  It should contain
the file(s) we expect, and we would know that because we go looking
for them as part of triggering.

So overall we'd say, for a rule to trigger, all this must hold:

(1) File name must match MFZ NAME
(2) Handle/pubkey must be in AUTHORIZED SET
(3) Manifest must contain FILE PATHS

at which point whatever are the TRIGGER ACTIONS are to be performed.

Now: This triggering is supposed to establish constraints between the
(latest recognized) trigger file and the files it updates.  In
particular, meaning that if a trigger-controlled file is modified
locally, those modifications are liable to be overwritten by the
trigger file being re-run at some point.  Like a 'git checkout foo'
overwriting local modifications to 'foo'.

The question is: When should a 'git checkout foo' be run
automatically?  Never?  Boot time only?  cdm.pl startup?  At random
intervals whenever cdm.pl is running?

Let's say cdm.pl startup for now.  But let's write the code so it
could be called at other times, yes.

[85:

Sun Feb 17 02:06:32 2019 All this discussion was also making me think
that maybe triggered .mfzs should only contain one path?  Expecting
cdm to be iterating through some random .mfz file... sniff, cdm has
much bigger and more important things to be doing.

But that circles back around to the synchronized updates issue.  If we
can only have one file per trigger mfz how do we update both cdm.pl
and stat13.pl in a synchronized way?  We'd have to add another level
of zipping, and then what have we accomplished except hide the paths
that will actually be ordered?

[86:

Sun Feb 17 02:49:21 2019 So we need to relax a little bit, here, I
think.  If the file name is right and the pubkey is right and some
single, top-level 'MFZ-NAME.txt' file exists and matches, then that's
it, we're good to go.  We position all the other contained files
anywhere in the fricken file system, and restart some services or
whatever.

We could generate MFZ-NAME.txt automatically in mfzmake, couldn't we?
It needs to be down in the inner zip, like MFZPUBKEY.DAT but unlike
MFZSIG.DAT.  So we'd call it MFZNAME.DAT I guess.

What happens if you try to pack a file names MFZPUBKEY.DAT?[87:

Sun Feb 17 03:08:01 2019 Ah, good boy:

    root@beaglebone:/# mfzmake make t2-cdm-debug-10 norg2.mfz MFZPUBKEY.DAT last-clams-before-deletion-is-possible.txt

    Error: 'MFZPUBKEY.DAT' is handled automatically, cannot pack it explicitly
    Type '/usr/bin/mfzmake help' for help
    root@beaglebone:/#

[88:

Sun Feb 17 03:13:25 2019 Aaaaahhummm, except, bad boy:

    root@beaglebone:/# mfzmake make t2-cdm-debug-10 norg2.mfz ./MFZPUBKEY.DAT last-clams-before-deletion-is-possible.txt
    Wrote 'norg2.mfz'
    root@beaglebone:/#

and then:

    norg2.mfz

    M Filemode      Length  Date         Time      File
    - ----------  --------  -----------  --------  ----------
      -rw-r--r--       172  17-Feb-2019  03:11:04  MFZSIG.DAT
      -rw-rw-rw-       689  17-Feb-2019  03:11:04  MFZ.ZIP
    - ----------  --------  -----------  --------  ----------
                           861                         2 files

and
    MFZ.ZIP

    M Filemode      Length  Date         Time      File
    - ----------  --------  -----------  --------  ------------------------------------------
      -rw-r--r--       280  17-Feb-2019  03:11:04  MFZPUBKEY.DAT
      -rw-rw-rw-         7  17-Feb-2019  03:07:08  MFZPUBKEY.DAT
      -rw-rw-rw-        10  16-Feb-2019  15:15:06  last-clams-before-deletion-is-possible.txt
    - ----------  --------  -----------  --------  ------------------------------------------
                         297                         3 files

So really we ought to ban MFZPUBKEY.DAT and MFZNAME.DAT from _any_
path in the mfz, not just the top-level?  Would it be safe to
normalize the path first using some perl whizzerd, and then check the
canonicalized form?[89:

Sun Feb 17 03:23:41 2019 Looks like maybe:

    root@beaglebone:/# mfzmake make t2-cdm-debug-10 norg2.mfz /root/../MFZPUBKEY.DAT last-clams-before-deletion-is-possible.txt
    ZONGABS(/MFZPUBKEY.DAT)
    ZONGABS(/last-clams-before-deletion-is-possible.txt)
    Wrote 'norg2.mfz'
    root@beaglebone:/#

And mfzmake is already 'abs_path'ing the files.. we 'just' need to
check for special-at-top-level files after rather than before doing
that.. [90:

Sun Feb 17 06:59:49 2019 OK we've been hacking in MFM to get the
original mfz filename into the inner zip, and that's starting to
work.  It really kind of feels like we should bump the .mfz format
version but I really don't want to do that considering we don't have
any code ready to handle backward compatibility there at all.

So even though it's lame, I'm much more inclined to just say the
existence of MFZFILE.DAT is not guaranteed in general, although we'll
require it for any 'triggering' mfz.[91:

Sun Feb 17 07:38:28 2019 Committing that stuff.

:91]

:90]

:89]

:88]

:87]

:86]

:85]

:84]

:83]

:82]
[92:

Sun Feb 17 12:56:33 2019 So pop pop how do we get to some visible
behavior quickly here?  Let's do deletion.  Let's start the
command-line cdm tool.  Called...  'cdmctl' I guess.

I also think we should now commit to using repo versions of the mfm
tools instead of the installed ones.  We can still fuss about the GFB
stuff, but we should commit to the tree for mfm, ulam, and SPLAT, and
figure out how to get updates for them moved without having to rebuild
them on each tile.  What happens if you try to diff a non-compressed
tar file?  [93:

Sun Feb 17 13:41:39 2019 Screw it let's just package everything for
now.  It's the only way to be robust, and updates at the
mfm/ulam/splat level are supposed to be asymptotically rare anyway.

But first let's get naming and syntax for the deleteds file, and then
something for the triggers file.

CDM-DELETEDS.mfz containing

  cdm/config/deleteds.map

in turn containing rows of the form..  announcement packets?  Could we
do that?  Put down a length byte first for packet framing, then put
down an announce packet?  Or maybe have a difference code for
reporting a deleted file -- cdm "D" type or something -- and use
that.  What info do we really need?  Just filename+checksum?
Or filename/length/checksum/innertimestamp, like cdm F type?  Why not
the handle too, then?

We either trust the checksum til the cows come home or we don't.  If
we do, then handle and inner timestamp are irrelevant since they're
covered by the checksum.  If we don't...?

I guess the point is that a 'deleteds map' should be smaller than
actually retaining all the deleted files.  After all, another way to
solve the deletions problem is just move the file to a 'deleted/'
directory like a Trash folder.  But we never reclaim the space that
way.  The deleteds map, the tombstone set, is to provide a more
compact representation of that-which-no-longer-exists than actually
keeping the stuff hidden somewhere.

Now, if we're constantly issuing new versions of some mfz, we don't
want to keep the checksums of all its older versions in the deleteds
map.  We want to (and already do) rely on the inner timestamp to
determine precedence.  So really, a deleteds entry should include the
timestamp, and it should be telling us that all versions of this
filename that are at least this old should be considered deleted.

And if a newer version of the same name is confirmed, I guess we
should remove that record from deleteds.

[94:

Sun Feb 17 14:40:46 2019 So, what's the easiest way to get some
version of this going?

Implement 'cdmctl delete FILE'.  Have it look in /cdm/common to find
FILE or die.  Get the filename/length/checksum/innerTimestamp from it.
(And handle?)  Load /cdm/config/deleted.map.  See if the filename is
already in there.  If not, add the current information to the map.  If
so, check if the inner timestamp of the deleted is newer than ours.
If so, then the file we are being asked to delete is 'already
deleted', so report that and do nothing.  Otherwise, update the
deleted record to our information, and rewrite the deleteds file.
Then (re)generate cdm-deleteds.mfz and place that in common/.  (User
must have t2-cdm-debug-10 private key to do this.)

"Done."[95:

Sun Feb 17 14:59:23 2019 Now, actually, don't we really need cdm.pl to
do most of that itself?  Because when a new version of the file is
asserted in common/, the older version should be removed from
deleteds, and we don't want cdm.pl and cdmctl to be racing to write
deleted.map.  How do we signal intention-to-delete?[96:

Sun Feb 17 16:22:11 2019 Maybe cdm.pl can't create a cdm-deleteds.mfz
on its own?  So if a new version of FILE comes along when it's
currently listed in deleteds.map, it stays in deleteds.map even though
it is no longer deleted since there's a newer version.

So really we want only cdm.pl to be writing deleteds.map, and to be
doing it only as part of unpacking a cdm-deleteds.mfz.  And cdmctl is
the only thing that should be writing cdm-deleteds.mfz, and if there's
a race between to cdmctl's writing two different cdm-deleteds.mfz on
two different tiles, both versions will circulate until the newer one
dominates the older one, and if they have exactly the same timestamp,
then.. the system will be broken?  Perhaps we should break the tie
with the lexicographically greater checksum at that point.

And it any case the system can still be broken, or at least DOSed, by
releasing a cdm-deleteds.mfz file with the maximum possible timestamp.
If we hold to our intention to only compare timestamps within a given
.mfz name 'lineage', we can't use our local clock to claim that some
given timestamp is in the future and reject it.  [97:

Sun Feb 17 16:38:11 2019 Anyway so do we have a plan here?  'cdmctl
delete FILE' is going to get the info from common/FILE, load
deleted.map, update it, then generate a new cdm-deleted.mfz -- without
actually updating the existing deleted.map.  The new cdm-deleted.mfz
gets dumped in common, replacing what's there, and that's it.

Then cdm.pl sees the modtime change on cdm-deleted.mfz, loads and
verifies it, discovers it's triggerable and triggers it, and the
triggering deletes FILE.  And..

You know, why the hell do we even have /cdm/config/deleted.map as a
separate file at all?  Why not just 'leave it' in
/cdm/common/cdm-deleted.mfz?  The cdm-deleted triggering can just load
the file into cdm.pl memory.  It seems like having the external 'bare'
file would be just an unnecessary special case to have to handle.
We'll get robustness by people announcing their cdm-deleted.mfz files
to us.[98:

Sun Feb 17 17:03:22 2019 Again. 'cdmctl delete FILE' gets info from
common/FILE, 'loads' common/cdm-deleted.mfz, updates it if necessary,
and generates a new common/cdm-deleted.mfz.  That's it.  Let's do it.
[99:

Sun Feb 17 17:11:53 2019 And hmm, what if we implemented 'deleted.map'
by encoding deleted filenames, plus their checksums and their
timestamps, as the names of 0-length files directly in the zip?  Is
there a limit on zip file filename length?  Then we could just do an
'mfzrun cdm-deleted.mfz LIST' command and get all the information we
need..   Too tricky for my shirt?[100:

Sun Feb 17 17:24:51 2019 Seems like might be a 255 or 250 byte limit
for filenames.  And 4096 (from unix) for full paths..  We could put
the checksum and timestamp as path elements..gah.
[101:

Mon Feb 18 00:04:30 2019 Problem isn't the trickiness so much as we'd
need to hook into mfzmake/mfzrun processing below its existing command
line level, and we don't really want to do _that_, for just a little
trickiness.

So back to the single deleted.map file inside cdm-deleted.mfz.

:101]
:100]

:99]
:98]

:97]
:96]

:95]

:94]

:93]

:92]
[102:

Mon Feb 18 04:26:04 2019 OK, well it's a total crock, but we have
cdmctl generating new and updated /cdm/common/cdm-deleteds.mfz files.
At the moment cdm.pl is not 'triggering' on them -- so in fact no actual
deletions are happening, still, doh -- but the updated
cdm-deleteds.mfz files are getting propagated around the grid
successfully.

:102]
[103:

Wed Jun 12 05:16:12 2019 OK so only four months later we are back here
again.  So we'd already mentioned /dev/itc/mfm as early as :7: above,
and that's what we're thinking we want to implement now.
[104:

Wed Jun 12 06:12:04 2019 Back from walk.  And note we'd pretty much
totally forgotten that '/home/t2/T2-12/apps/cdm/cdmctl' actually
exists. [105:

Wed Jun 12 07:07:06 2019 Which we've now punched up a little bit, and
refreshed for our current keymaster key and structure.  And note re
the 'DOS' discussion in :96: above, without the keymaster private key
one can't release a functional cmd-deleted.mfz anyway, so that's just
another thing hanging off the same private key, rather than a separate
distributed programming issue..

:105]

:104]
:103]
[106:

Wed Jun 12 07:11:04 2019 So, anyway, anyway.  Back to LKM land.[107:

Wed Jun 12 07:21:45 2019 In /home/t2/T2-12/pru/itcio/module/itc_pkt.h,
we see:

    #define MAX_PRU_DEVICES 2       /* PRU0, PRU1*/
    #define MINOR_DEVICES (MAX_PRU_DEVICES+1)  /* +1 for the ITC packet interface */

and couldn't we add another one in there for an MFM packet interface?
[111: Wed Jun 12 09:02:07 2019

DONE (or, messed with that anyway.)

:111]
[108:

Wed Jun 12 07:31:25 2019

[114: Wed Jun 12 09:13:17 2019
DONE :114] - We'd add another kfifo, mfmPacketKfifo.[112: Wed Jun 12 09:03:14
  2019 and?

[115: Wed Jun 12 09:13:39 2019
DONE :115] - We'd add another wait_queue mfmPacketWaitQ?[113: Yes I think so.
   And also

[116: Wed Jun 12 09:13:54 2019
DONE :116] - We'd add another mutex, mfmLock.

:113]

:112]

 - We'd make another const struct file_operations, mfm_pkt_fops. [109:
     Wed Jun 12 07:59:30 2019 Would we?  Maybe not.

[117: Wed Jun 12 09:16:54 2019
DONE :117] - We'd extend make_itc_minor, for example around itc_pkt.c:876, with
   stuff like

      if (minor_obtained == 3)
        snprintf(devname,BUFSZ,"itc!mfm");


:109]

[118: Wed Jun 12 09:20:11 2019
DONE :118] - We'd add a new case to itc_pkt_read for our new mfm case 3, that
   would look much like case 2 but on a different kfifo.

[119: Wed Jun 12 09:22:12 2019
DONE :119] - We'd change itc_pkt_write around itc_pkt.c:475 to include minor
   3 as well as minor 2, so mfm packets would go through standard
   packet routing.

[120: Wed Jun 12 09:22:48 2019
DONE :120] - We'd change itc_pkt_cb around itc_pkt.c:703 to check the 'mfm' bit
   in the type byte, and divert to using S.mfmPacketKfifo and
   S.mfmPacketWaitQ if it's set.

[121: Wed Jun 12 09:23:09 2019 Made it a loop
DONE :121] - We'd check what's going on in itc_pkt_probe with all that minor==2
   stuff to see if it needs to be generalized or duplicated for minor
   3.
[110:

Wed Jun 12 08:57:36 2019 Well, is this more or less try-able?

:110]
:108]

:107]

:106]
[122:

Wed Jun 12 09:23:22 2019 OK well I did all the implicit TODO I'd made
up. [123:

Wed Jun 12 09:24:47 2019 And it compiles.  But nap time before I try
running this s'cah.

:123]

:122]
[124:

Wed Jun 12 13:10:00 2019 OK trying it..[125:

Wed Jun 12 13:10:45 2019 Well would you look at that:

    root@beaglebone:/home/t2/T2-12/pru/itcio/module# ls -l /dev/itc/
    total 0
    crw------- 1 root root 247, 0 Jun 10 12:21 locks
    crw------- 1 root root 246, 3 Jun 12 13:10 mfm
    crw------- 1 root root 246, 2 Jun 12 13:10 packets
    crw------- 1 root root 246, 0 Jun 12 13:10 pru0
    crw------- 1 root root 246, 1 Jun 12 13:10 pru1
    root@beaglebone:/home/t2/T2-12/pru/itcio/module#

and /dev/itc/packets is minor 3 and everything.  [126:

Wed Jun 12 13:12:24 2019 Looks like /dev/itc/packets might still be
working:

    root@beaglebone:/home/t2/T2-12/pru/itcio/module# cat /dev/itc/packets
    …A…Fcdmd-T2-12.mfz987765õ¡MÒyNsŸ¥”0bÏ
    156017469010‡FBONGERS.mfz7509*áäÈS=hï«¹eYcŠš
    15494995928‡Fcdmd-t2.mfz314460f´J§ÖnŸ/e#A¦wÝ
    156023444815…F	CDM11.mfz12066¯Wë_ {/¶ós–üo#Ý
    154986702213…FPONGERS.mfz7509*áäÈS=hï«¹eYcŠš
    154949959211‚Fcdmd-T2-12.mfz987765õ¡MÒyNsŸ¥”0bÏ
    15601746908‡Fcdm-distrib-T2-GFB.mfz7780FtÁø7vûiaaÄ»ý
    15597802765‚Fcdm-distrib-T2-GFB.mfz7780FtÁø7vûiaaÄ»ý
    155978027613…Fcdmd-devbins.mfz682276eÚƒìzxAæ>ùC3ó>ÌÚ
    15601239402‚Fcdm-distrib-T2-GFB.mfz7780FtÁø7vûiaaÄ»ý
    155978027613‡Fcdm-distrib-MFM.mf16903483ˆÕvzƒ¾`%’¯Ú»
    15600916064…Fcdmd-MFM.mf10417990ËÝˆ9=Ìˆn™Xh|X
    156021665012Fcdm-distrib-MFM.mf16903483ˆÕvzƒ¾`%’¯Ú»
    156009160610‡Fcdmd-T2-12.mfz987765õ¡MÒyNsŸ¥”0bÏ
    15601746902…Fcdmd-T2-12.mfz987765õ¡MÒyNsŸ¥”0bÏ
    156017469010‚Fcdmd-T2-12.mfz987765õ¡MÒyNsŸ¥”0bÏ
    15601746908…Fcdm-distrib-MFM.mf16903483ˆÕvzƒ¾`%’¯Ú»
    15600916065ƒA‡Fcdmd-MFM.mf10417990ËÝˆ9=Ìˆn™Xh|X
    156021665010…FPONGERS.mfz7509*áäÈS=hï«¹eYcŠš
    154949959211‚FBONGERS.mfz7509*áäÈS=hï«¹eYcŠš
    15494995925…A‚F	CDM11.mfz12066¯Wë_ {/¶ós–üo#Ý
    154986702211‡Fcdm-distrib-T2-GFB.mfz7780FtÁø7vûiaaÄ»ý
    CDM11COPY.mfz12066¯Wë_ {/¶ós–üo#Ý
    15498670223  C-c C-c
    root@beaglebone:/home/t2/T2-12/pru/itcio/module#

Which sure look like advertisements inbound from the neighbors.  Now
why it that there's a newline just before the tag in all those
packets?


:126]

:125]

:124]
[127:

Wed Jun 12 17:31:47 2019 OK well we're starting up apparently cleanly
again, after I wasted an hour or so by not rebooting and therefore
having an major:minor in use that shouldn't have existed.  Doh and doh.

So now I guess we need a legal-looking mfm packet to trying echoing
into /dev/itc/mfm..  And I guess the current status of packet format
development is something like:

      BYTE 0                                   BYTE 1                                   BYTE 2
      STND LOCL MFMT
     +----------------------------------------++---------------------------------------++----------------+
     |  1 |  0 | 1  |OVRN||EROR|DIR2|DIR1|DIR0||    MFM PKT FORMAT...                  ||
     +----------------------------------------++---------------------------------------++----------------+

Do we get to screw around imagining all-sancing MFM packet formats here now?[128:

Wed Jun 12 21:23:31 2019 Well, now after evening break, maybe we get
to think about it a little.  But really, we already have a cache
protocol, right?  How well does or doesn't it just drop in, here?[129:

Wed Jun 12 21:28:48 2019 Well, in src/core/include/CacheProcessor.tcc,
we see

        u8 byte = (u8) plen;  // plen<128 since OString128..
        m_channelEnd.Write(&byte, 1);  // Packet length, then data
        m_channelEnd.Write((const u8 *) pb.GetBuffer(), plen);

with no direction info since m_channelEnd is point-to-point so it
already knows.  But since we have OoB packet framing, we wouldn't need
the plen -- and we might prefer having a checksum instead.[130:

Wed Jun 12 22:07:46 2019 Also looks like we'd want to replace the
ChannelEnd abstraction since it expects to accumulate the bytes of a
packet but on the T2 packets will be handled atomically.[131:

Wed Jun 12 22:16:31 2019 So the MFM packet payloads are way small --
like a type byte plus one atom, or a type byte plus two shorts.  If
we're adding a routing byte plus a packet terminator to each of those
that could be pretty signficant overhead.[132:

Wed Jun 12 22:24:23 2019 So, the CacheProcessor already buffers up a
whole bunch of 'packets', in the form of CachePacketInfo structs,
inside its m_toSend array.  But when it gets to AdvanceShipping, it
breaks that back down to individual PacketIO::SendAtom chunks.

On the receiving side, the small individual packets are handled as
they are seen from ChannelEnd::ReceivePacket(); there's no inbound
buffering.  In principle, with smaller packets, the whole update
process would be pipelined between the two tiles -- the receiver could
be applying changes before the send has finished sending them
all.[133:

Wed Jun 12 23:21:06 2019 But in any event it seems we should leave the
cache protocol semantics alone until we have things working that way.
So we'll have little packets with a lot of overhead.

But we could still have other types of mfm packets beyond cache
packets -- like here's my simulation id, request to clear the world,
restart mfm, reboot t2, whatever.  Potentially in both p2p and flood
versions.

Now, if these cache packets really are so tiny, we could carve off
byte 7 at least and put the length right in byte 1:

      BYTE 0                                   BYTE 1                       BYTE 2            BYTE 3
      STND LOCL MFMT                            SPEC
     +----------------------------------------++---------------------------++----------------++--
     |  1 |  0 | 1  |OVRN||EROR|DIR2|DIR1|DIR0||  0 | MFM CACHE PKT LENGTH || CACHE PKT TYPE ||
     +----------------------------------------++---------------------------++----------------++--
     +----------------------------------------++---------------------------++----------------++--
     |  1 |  0 | 1  |OVRN||EROR|DIR2|DIR1|DIR0||  1 | MFM SPECIAL TYPE     || MFM SPEC TYPE ARGS..
     +----------------------------------------++---------------------------++----------------++--

with the understanding that if the t2 packet length was bigger than
the mfm cache pkt len, that means there's another mfm cache pkt in the
same t2 pkt?  Blows the ignore-excess-packet-for-forward-compatibility
theory mentioned around here somewhere -- but if we say a 0 byte in
the length position means end we could have it back sort of.  Or if we
just say ignore and skip unknown packet types like MOV file chunks etc.

[134:

Thu Jun 13 00:20:49 2019 How actually are we going to identify the
simulation we are running?  Do we need an mfmt2 argument so mfzrun can
pass info in?[135:

Thu Jun 13 00:22:46 2019 We also need to remember we want to
prioritize mfm packets outbound.  Where does that happen?  We want the
mfm kfifo to be flat empty before we consider /dev/itc/packets
traffic.[136:

Thu Jun 13 00:28:50 2019 Umm we don't have any outbound kfifos, we
just blast packets directly to rpmsg_send and tough noogies if there's
no rpmsg bufs available.  So /dev/itc/packets and /dev/itc/mfm are
first-come-first-serve serialized by rpmsg -- and umm where is the
lock controlling access to that?  itc_pkt_write(..) doesn't appear to
ever lock anything, but at least the following are shared data:

  static unsigned char driver_buf[RPMSG_BUF_SIZE];
    - where we buffer the message in kernel space

  devstate = S.dev_packet_state[newMinor];
    - the state for pru0 or pru1, including

  devstate->rpmsg_dev
    - the thing we actually send the messages on.

[137:

Thu Jun 13 00:56:00 2019 Maybe we should make an outbound kernel
thread that pumps out the rpmsg bufs.  We'll make two outbound kfifos
-- a priority lane for mfm, and a background process for itc -- and
have them share one waitqueue.  minor 2 writes to the itc fifo and
wakes the shared queue, minor 3 writes to the mfm fifo and does the
same.  The kernel thread makes rpmsg bufs as fast as it can.  Now
when rpmsg bufs are exhausted and the thread has to sleep, who wakes
it up again?  It's got to be the rpmsg interrupt that we didn't really
believe in so much, ugh.  Well we could have it be a short sleep.

It's a lot more complexity, and another layer of buffering.  Vs just
putting a lock around much of itc_pkt_write.

(Are we even safe on the read side?  I bet not either.  But sleep now.)
[138:

Thu Jun 13 07:29:10 2019 Well, looks like the read side has the
potential to be already okay, because of the existing kfifos.  People
trying to read /dev/itc/pru0 fight to acquire pru0's specialLock
mutex, and ditto for /dev/itc/pru1.  Once they have it, they block on
pru0's or pru1's private specialWaitQ until the the appropriate kfifo
(global S.special0Kfifo or S.special1Kfifo) is non-empty.

The same happens for /dev/itc/packets -- fight for S.standardLock,
wait on S.itcPacketWaitQ, until S.itcPacketKfifo is non-empty.  Ditto
/dev/itc/mfm, fight for S.mfmLock, wait on S.mfmPacketWaitQ, until
S.mfmPacketWaitQ is non-empty.

So read side might be okay.  And the only reason we've gotten away
with the existing write side is that we actually had only one
user-space writer.  Which is precisely what we are changing now.

What other alternatives are there?  Put a single lock around all write
activity, so only one process can get to rpmsg_send at a time.[139:

Thu Jun 13 09:09:40 2019 So I'm pretty conflicted about what to do
here.  A 'priority lane' for mfm seems like the right thing to do, but
just putting a lock around all writing seems like the easier thing to
try.

Fuck it, it's only Thursday.  Let's try to code up the priority lane.

[140:

Thu Jun 13 10:21:05 2019 Well here's another thing.  If we're tearing
up itc_pkt much at all, there's a variety of crap that seems like it
needs rewriting/cleaning.  Such as the comment in itc_pkt.h:

    /* per maj,min device -- so in our case, per PRU */
    typedef struct itc_dev_state {
     ..
    } ITCDeviceState;


which just isn't true given that we have two PRUs but four minors --
and in fact we do make four of them, via

    typedef struct itc_pkt_driver_state {
  ..
      ITCDeviceState    * (dev_packet_state[MINOR_DEVICES]); /* ptrs to all our device states */
    } ITCPacketDriverState;

and

    static int itc_pkt_probe(struct rpmsg_channel *rpmsg_dev)
    {
      int ret;
      ITCDeviceState *devstate;
      int minor_obtained;
  ..
      minor_obtained = rpmsg_dev->dst - 30;

      devstate = make_itc_minor(&rpmsg_dev->dev, minor_obtained, &ret);
  ..
      S.dev_packet_state[minor_obtained] = devstate;


and

    for (i = 2; i <= 3; ++i) {
 ..
      S.dev_packet_state[i] = make_itc_minor(&rpmsg_dev->dev, i, &ret);


It really seems like that should be rewritten to be per PRU and the
minor stuff should be handled separately sort of as an overlay.. but
that's a complete redesign of the code, which implies a complete
restabilization of a big pile of new code.

:140]

:139]

:138]
:137]

:136]

:135]

:134]


:133]

:132]

:131]

:130]

:129]

:128]


:127]
[141:

Thu Jun 13 15:39:48 2019 Let's think about the design then.  I need to
dig in.

Annotated structs:

typedef struct itc_dev_state {
  struct rpmsg_channel *rpmsg_dev;

   - channel provided to us in itc_pkt_probe when the PRUs are being
     booted and their handling module is being initted.

   - itc_pkt_probe gets called with a different rpmsg_dev for each PRU
     (I believe), but since we init /dev/itc/packets and /dev/itc/mfm
     during the first probe, their 'parent' is set to whichever
     rpmsg_dev we saw first.

     = I suspect that means that the ITCDeviceState dynamically
       allocated by devm_kzalloc for packets and mfm will both be
       released when that first-probed PRU is being 'detached', which
       is I hope harmless.


  struct device *dev;

   - Pointer to our 'parent' device in rpmsg_dev.  Used in dev_err and
     dev_info calls, at least.

  struct mutex specialLock; /*if held, a special packet roundtrip is in progress*/

   - lock hold by the low-level roundtrip packet comm between lkm and
     pru, used in these cases:

     = itc_pkt_read takes it before reading from S.special0Kfifo or 1.

     = send_msg_to_pru takes it around a call to rpmsg_send plus a
       wait for a return packet on S.special0Kfifo or 1.
       send_msg_to_pru is used for 'atomic' access to PRU resources in
       itc_pin_write_handler and itc_pin_read_handler, and to send the
       initial 'throat clearing' packet after the PRUs boot.  And, I
       think, that's it.

  wait_queue_head_t specialWaitQ;

   - A wait queue associated the above specialLock, and indirectly
     through that to the S.special[01]Kfifo

   - I really don't understand why I have the specialKfifo's as
     globals rather than just as data members in this struct.
  
  bool dev_lock;

   - A flag enforcing a single simultaneous open on the inode, used
     only in itc_pkt_open and itc_pkt_release, and seems fine for it's
     purpose -- especially as creating /dev/itc/mfm means we don't
     need multiple simultaneous opens on any single inode anyway.

  struct cdev cdev;

   - Linux' struct for a char device, with the file operations

  dev_t devt;

   - The major,minor for this device.

} ITCDeviceState;[142:

Thu Jun 13 17:07:16 2019 Well, that took forever.  And it still leaves
open the question of whether we want to use ITCDeviceState's for our
virtual devices.  What might it look like if we didn't?

#define PRU_MINORS 2   /* low-level access to PRU0, PRU1*/
#define PKT_MINORS 2   /* processed access to itc, mfm */
#define MINOR_DEVICES (PRU_MINORS + PKT_MINORS) 

in global driver state S --

..
  ITCPRUDeviceState * (dev_pru_state[PRU_MINORS]);  /* ptrs to state for /dev/itc/pru[01] */
  ITCPktDeviceState * (dev_pkt_state[PKT_MINORS]);  /* ptrs to state for /dev/itc/{packets,mfm,?}*/
..

/* per rpmsg-probed PRU device - /dev/itc/pru[01] */
typedef struct {
  struct rpmsg_channel *rpmsg_dev;
  struct device *dev;

  struct mutex specialLock;        /* if held, a special packet roundtrip is in progress*/
  wait_queue_head_t specialWaitQ;  /* where to wait if special packet roundtrip in progress*/
  SpecialPacketFIFO specialKfifo;  /* buffer for inbound special packets */

  bool dev_lock;
  struct cdev cdev;
  dev_t devt;
} ITCPRUDeviceState;

/* per 'virtual' packet device - /dev/itc/{packets,mfm} */
typedef struct {
  struct device *dev;

  ITCPacketFIFO     pktKfifo;      /* buffer for all inbound packets on this device */
  wait_queue_head_t pktWaitQ;      /* for people blocking on this device */
  struct mutex      pktReadLock;   /* lock for reading packets on this device */

  bool dev_lock;
  struct cdev cdev;
  dev_t devt;
} ITCPktDeviceState;

and for outbound virtual packets, the write fops would use
S.dev_pru_state[minorNeeded] to get to the rpmsg_channel we need.
While for inbound virtual packets, the cb fops would use
S.dev_pkt_state[pktType] to get to the kfifo to stash in.

[143:

Thu Jun 13 17:42:46 2019 Well this is a giant redo but it feels kind
of right.  But, time for cocktails.

:143]

:142]


:141]
[144:

Fri Jun 14 01:45:48 2019 OK, things are all torn up.  Stopping for
tonight on this issue: Now we have separate kfifos for mfm vs itc
packets, but don't we also need to multiply that by PRU0 and PRU1
destinations?  The packet callback is per-pru; it needs to get just
what it needs.

So that means another reorg of the structs, at least.

:144]
[145:

Fri Jun 14 15:42:57 2019 Well, it's time to pack up for the weekend.
Checkpointing all this stuff -- in its unbuildable glory, so there'll
be at least one obvious prompt to get us going again. 

:145]
