{348}  -*- text -*-
[0:

Thu Aug 20 15:54:24 2020 And here we are.
[19:

Sat Aug 22 10:27:31 2020 OK, moved this file here from the
never-committed MFM/src/drivers/cdmng directory where it was born.

Will continue here with the cdm.pl redesign.

:19][1:

Thu Aug 20 15:54:57 2020 So let's think about a proper foggen class to
represent an asset managed by CDMng.  (Which we're going to start
calling just CDM again, we think, pretty soon.)

Beliefs:

 - We represent only MFZ assets

 - We follow cdm.pl semantics, at least to get going, unless there's
   pressing reason

What are we going to call this class?  What yumbo c++ container are we
going to use for it?  MFZAsset?  ZAsset?

(Ooh, suppose we use command line arguments for things like
maintaining the deleteds file and such.)
[2:

Thu Aug 20 16:13:53 2020 Let's go with MFZAsset.  No data structure
distinction between finfo and plinfo; all just MFZAsset.

MFZAssets have a state:

 - COMMON: Complete and verified and read-only in common
 - PARTIAL

[3:

Fri Aug 21 06:14:35 2020 Maybe we want to separate representing the
'file in the abstract' from the 'data that we have'.  There's a bunch
of things that can happen even if we have no data at all:

 - Hear about an MFZ for the first time

 - Hear about a newer version of an MFZ that we have an older one of

[4:

Fri Aug 21 06:16:46 2020 And it seems like we really shouldn't ditch
an older one until we have the VERIFIED content for a newer version

And is the whole system screwed if a bit flips in a file announcement
so that some obsolete version looks to be from the year 3000?  Even
though the underlying content won't verify -- once it finally arrives
-- how do we ever kill off that circulating file announcement?

What if mfzmake on the keymaster also signed an announcement for the
MFZ?  How small could we make that?  Filename+inner
timestamp+checksum+sig

cdm-deleteds.mfzdddddddddddddddd
1562107060
990756-2483-40265a
t2-keymaster-release-10
[5:

Fri Aug 21 08:39:30 2020 So this is how long it takes to remember that
what Perl bought us was trivial interfaces to both Zip and RSA
encryption, that (1) we're going to have to do much more by hand in
C++, and yet (2) must absolutely match perl behavior down to the bit.

Urgh.

Let's find some sample code and do spikes for both..[6:

Fri Aug 21 08:45:36 2020 Hmm it seems that zip interface APIs are not
really that standardized?  One has to pick some project and go with
it?  Double urgh.[7:

Fri Aug 21 08:58:57 2020 Well, I'm thinking indeed I screwed up here,
and we should stay in perl, but just clean it up -- do real modules
and multifile and stuff.

I want to keep the t2lib refactoring though, because I can totally see
the possibility of other apps coming up that will want to share chunks
of the t2-specific infrastructure.

Just have to ditch cdmng.

Urgh.

:7]

:6]

:5]
:4]

:3]

:2]

:1]
:0]
[8:

Fri Aug 21 09:01:29 2020 The issue remains of why should we trust a
pipelined file announcement enough to repeat it, and risk creating a
flying dutchman if a timestamp error gets through.  Still think we'd
like to get a stub or a receipt or a proxy or something out of the
mfzmake process, that we could use as (most of) the pipelined file
announcement.

[9:

Fri Aug 21 09:50:47 2020 So it looks like a b64 signature is 172 bytes
long.  Pretty long, but we could probably cram it into a file
announcement, looking something like

0x80|dir + 0x83 + 'F' + announcement + sig

where the sig signs all the prior bytes, including the packet header,
taking dir as 0.

hdr: 3 bytes
announcement:
  filename: 40 bytes?
  inner timestamp in binary: 4 bytes
  inner length: 4 bytes
sig: 172

3 + 40 + 4 + 4 + 172 == 223

but still need handle?

t2-keymaster-release-10

is another 23 right there == 246

and still need some amount of inner checksum, to help deter
collisions, right?

maybe six bytes of checksum == 252

[10:

Fri Aug 21 14:28:17 2020 What does mfzrun do with future-version mfz
files?  Could we go to version 2 and pack this announcement in the
outer mfz as ANNOUNCE.PKT or something?[11:

Fri Aug 21 14:33:51 2020 Right now mfzrun horks unless the version is
exact

 ..
    sub VERSION { "1.0" }
    sub MFZRUN_HEADER { "MFZ(".VERSION.")\n" }
 ..
    die "Bad .mfz header in '$progname'"
        unless defined $firstLine and $firstLine eq MFZRUN_HEADER;

But it really kind of looks like we could just go ahead and pack
ANNOUNCE.PKT into the outer zip and the existing mfzrun code would
completely ignore it.  It does FindName for the two files it cares
about -- MFZ_ZIP_NAME and MFZ_SIG_NAME -- and doesn't care about
anything else.

We could say the 1.0 format is the file format, not all the details of
what's inside.

So I think we could do this, as long as we make having ANNOUNCE.PKT be
optional in cdm, and have some fallback (like: No pipelining) if it's
not in an MFZ.
[12:

Fri Aug 21 14:51:11 2020 Yikes though: Here's the regex for a handle:

(:?[a-zA-Z][-., a-zA-Z0-9]{0,62})

Looks like length 63 possible.  How does that square with your
post-war commie conspiracy packet budget huh?

I suppose we could addLenArg the arguments and just insist the overall
result fits in one packet?  Or else what?  Fail mfzmake?

cdm-distrib-T2-GFB.mfz is 22 bytes and currently the longest thing in
/cdm/common.  But we thought we where going to allow well more than
that.

I assume we can't trim the sig at all or it won't verify, so let's run
it down again:

255-172 == 83

If we don't b64 the signature how much do we save?  B64 is six bits
per byte, so 172*6 == 1032 and 1032/8 == 129 bytes.  That's a little
better -- basically half the packet.  Let's assume that.

  3   hdr
 40   filename
  4   timestamp
  4   len
  8   checksum
===
 59
172   sig
===
231

255-231 == 24  for handle

t2-keymaster-release-10 Just Barely Fits.  Gah.

We can ditch the packet hdr for 3 bytes

Create a new 'handle registry' of some kind, with a registered handle
number, so that we don't include the handle by name at all?  We could
go with even four bytes for a registered handle number and still save
20 bytes.

Hmmm

[13:

Fri Aug 21 15:16:50 2020 So the idea would be that as mfzmake time,
unless your private key was associated with a known registered public
key, we wouldn't include the announcement file at all.  And if it was,
we'd record the public key registration number in the announcement.

Then we'd be at something like

  3   hdr
 40   filename
  4   timestamp
  4   len
  8   checksum
  4   pubkeyregnum
===
 63
129   sig
===
192   which really isn't too bad.  For a packet.  Could even go to 48
      for the filename maybe

Which would then be:

  3   hdr
 48   filename
  4   timestamp
  4   len
  8   checksum
  4   pubkeyregnum
===
 71
129   sig
===
200

and we could just pad the filename out to 48 with nulls and say
everything goes in fixed positions.

[14:

Fri Aug 21 15:31:59 2020

Perhaps we should include an announcement version number, Mr. President?

Just to be safe.

Make it like

  3   hdr
  1   announcement version
  4   timestamp
  4   len
  8   checksum
  4   pubkeyregnum
 47   filestem (filename - '.mfz')
===
 71
129   sig
===
200

In which we actually have more room for filename by committing to .mfz
as the only possible extension.  It's not really the file stem, it's
more like the 'cdm content name' or something.

Now, before we get too close to pulling the trigger here -- do we
really want to include the packet header?

 - Locks us into the specific 'F' packet
 - Has to be modified to insert/delete the dir on the fly, and sig
   won't verify without that
 + Acts like a magic number for registered announcement files
 + Makes file length == packet length for budgetary purposes
 - Would have to be checked anyway by code before putting on the wire
 + Would have to be checked anyway by code before putting on the wire

Maybe it's okay.  If necessary, down the road, we can add our own
header and nest this whole thing inside another packet -- after all,
we still have 55 bytes to give.

Let's stick with it.

[15:

Fri Aug 21 15:41:54 2020 Now, how do we make this 'registered public
key' business work?

 - We can hard-code a mapping from int => handle inside
   mfzmake/common.pl.inc and cdm.pl.  To register a new mapping to
   have to change the code in all those places

 - We can add a new command line arg to mfzmake saying 'use this
   registration number'.  That means: Look up the handle for this
   number and use that, and hork if you don't have a private key for
   that handle.

 - And we'll only and automatically include the announcement file when
   the command line registration number is used.

 - I suppose we should include the pubkey file in the registration
   map?  How do we check that it actually matches the supplied
   privkeyfile?

:15]

:14]



:13]

:12]

:11]

:10]

:9]
:8]
[16:

Sat Aug 22 01:24:06 2020 Going with:

  3   hdr                   0x80.0x83.'F'
  1   announcement version  0x01
  4   big-endian inner timestamp
  4   big-endian inner length
  2   big-endian regnum
  8   inner checksum substr
 50   content name (filename - '.mfz')
===
 72
129   RSA sig
===
201

[17:

Sat Aug 22 01:39:10 2020 Or, as a perl pack format:

"CCA".         # hdr
"CNNnA7A50".   # announcement
"A129"         # sig

:17]

:16]
[18:

Sat Aug 22 05:16:42 2020 OK, so I think we may have successfully
introduced the 'cdmake' command to mfzmake, which causes it to
generate an ANNOUNCE.pkt in the outer zip, which is precisely 200
bytes long and represents the pipeline file announcement packet to be
sent to neighbors, unmodified except for adding the appropriate dir to
the first byte.

We need to hack cdm.pl to send and receive it, but we need to do a lot
of hacking on cdm.pl, since we're going to clean it up.

:18]
[20:

Sat Aug 22 12:09:35 2020 OK, moved the flag.  Time to take the
rethinking and apply it to cdm.pl.

First up, reorganizing for packages.  I think also we should probably
actually install cdm.pl somewhere, rather than running it out of the
T2-12 in production?  Let's do that first..[21:

Sat Aug 22 12:11:29 2020 apps/cdm/Makefile has

    DEST_DIR:=/opt/scripts/t2

but it's not using it?[22:

Sat Aug 22 12:12:19 2020 Ah, it installs cdm.sh there, but that's
all.  So maybe make /opt/scripts/t2/cdm/ and copy the code there?

[23:

Sat Aug 22 12:58:20 2020 Call coming up.  Continue after.[24:

Sat Aug 22 13:06:43 2020 Have we got anything .pm-ish in this tree yet
that we could steal?[25:

Sat Aug 22 14:22:16 2020 After call.

We do have T2-12/tests/ITC/old10/T2tils.pm, it might be something.

:25]

:24]

:23]

:22]

:21]

:20]
[26:

Sat Aug 22 14:53:26 2020 OK, we might have a plausiblish 'make
install' for cdm now.  And cdm.sh 'ought' to work from either the
source or installed dirs.

Now reorg for PMs.  Let's review the design thinking we were doing
when we were thinking C++..
[27:

Sat Aug 22 14:56:10 2020 We wanted to separate 'mfz in the abstract'
from 'data that we have'.  Call them..  MetaData and Data?  MetaMFZ
and MFZContent?  MFZMetadata vs MFZContent?  MFZMetadata vs
MFZContentManager?  MFZMetadata vs MFZManager?

And a class for the container(s)?  Maybe not yet.  Skeleton first.

:27]
:26]
[28:

Sun Aug 23 04:00:33 2020 OK so we've got plenty of module-y structure
and we've started fleshing out CDM.pm.  And we're getting worried
about just moving 90% of cdm.pl into CDM.pm without actually
reconsidering the design and addressing the mess that we made in
cdm.pl.  So we're back here to think some more.

Issues:

 - How hard do we structure for incremental state machine execution?
   In copying code we've now arrived at checkCommonFile, which is an
   incremental execution thing.  We kind of think we should pull
   common management out to its own class?

 - Really want to keep the main loop as clean as possible.  We should
   have some kind of 'task' abstraction even if the various tasks
   might not be different classes?

[29:

Sun Aug 23 05:17:52 2020 How about we do that?  Task.pm?  It wraps
another object or other state, and provides scheduling and time-based
dispatching.  Wrapped objects provide a single main callback.
[30:

Sun Aug 23 11:31:51 2020 I guess partly the point is perl will call
anything on anything..[31:

Sun Aug 23 13:50:35 2020 OK, so now we have TimeoutAble.pm and
TimeQueue.pm.   Rather than subclassing, we create instances of
TimeoutAble and supply a code ref to be called back on timeout.

We're running the TQ at one-second granularity to emphasize this is
about long-term actions not precision timing..[32:

Sun Aug 23 13:53:33 2020 So OK.  Need some more

TODO

 - Build something to load and watch over common/ like checkCommonFile
   currently does.

 - Build the main content-by-name container so the checkCommonFile
   analog has something to populate.

 - Do more design on MFZManager and/or MFZMetadata.  How independent
   to they want to be?  If we always stub out a file for MFZMetadata
   doesn't the distinction collapse?


:32]

:31]

:30]
:29]

:28]
[33:

Sun Aug 23 14:03:29 2020 So yeah, suppose we say main container is
contentName -> MFZManager and go from there for now.

:33]
[34:

Sun Aug 23 14:39:52 2020 Was trying to figure out the clean way to
initialize subclass data members after building the base class, and
ended up reading through a bunch of the stuff on Class::Struct.

And now kinda really want to redo with that and 'use fields'
throughout, before things get too complicated here..  But have to
break for meeting at the top of the hour..

:34]
[35:

Sun Aug 23 23:48:32 2020 OK use fields GO GO GO.[36:

Mon Aug 24 01:17:38 2020 OK have a first cut using 'use base' and 'use
fields'.  Hour and a half?  Urgh.  TimeoutAble is now a base class
after all, and one overrides onTimeout to do whatever one wants.

Ended up not using Class::Struct because it seemed a little narrow in
the end; we'll see.

So what next?  MFZManager vs MFZMetadata design?

Also, MFZManager might be conflating inbound and outbound tasks on a
single pipeline.  Certainly seems possible we could want separate
timeouts for reasking for an upstream chunk and reannouncing to a
downstream neighbor.

Is a reason to keep MFZManager and MFZMetadata separate that we might
want to have multiple MFZMetadata objects for a single content name?
Even if a new valid announcement on a name arrives, maybe we want to
keep the old one around (for a while) to provide errors when
downstream asks for an old tag?  Seems Not Compelling That.

What if we have a complete and verified MFZ in common/ MFZ plus also a
newer incomplete MFZ in pipeline/ under the same name?  Hah, there!

We can't be wanting to actually delete the common/ MFZ before the
pipeline version is complete.  So either we have two MFZMetadatas for
the same content name, or we have a file in common/ that has no
MFZMetadata associated with it.  Which Do You Prefer.

[37:

Mon Aug 24 01:36:42 2020 Maybe need to walk through some cases.

[38:

Mon Aug 24 02:05:11 2020 Opps.
[39:

Mon Aug 24 02:05:19 2020 Cases.

LOAD COMMON
 - Make MFZManager for each complete and verified
 - Look for ANNOUNCE.PKT inside the MFZ.  (How will we do that?)

:39]

:38]
:37]

:36]

:35]
[40:

Mon Aug 24 02:08:12 2020 Are we going to support non-cdmake MFZs at
all?  Seems like maybe now's the time to say no.  How does cdmctl deal
with cdm-deleteds?  Shell out to mfzmake?
[41:

Mon Aug 24 02:09:57 2020 Yeah, it does:

    my $cmd = "$MFZMAKE_PROGRAM make $CDM_INTERNAL_HANDLE $path $deletedsFile";

which should become something like

    my $cmd = "$MFZMAKE_PROGRAM cdmake $CDM_INTERNAL_REGNUM $path $deletedsFile";

[42:

Mon Aug 24 02:18:05 2020 Well, hacked that in the obvious way and it
appears plausible enough.

But it does totally drive home the point that we ought to take
cdm-deleteds seriously in this cdm re-redo.  Maybe we should try to do
a special MFZManager just for cdm-deleteds, since others will need to
depend on it.

How does cdmctl delete something anyway?  ..You give it a list of
.mfzs to delete.  OK.  So we could get the ANNOUNCE.PKT out of there,
and use that as the token to identify a deleted mfz.

If we had ANY WAY to extract the ANNOUNCE.PKT from an mfz without
actually writing zip-level code..  Note that 'mfzrun FOO.mfz unpack'
WON'T DO IT, because that only unpacks the inner zip.  mfzrun needs a
new command.  Let's do that.  Call it.. 'announce' I guess -- print
out the announcement packet of this .mfz, if it's got one.
[43:

Mon Aug 24 04:07:23 2020 OK, now 'mfzrun FOO.mfz announce' prints the
ANNOUNCE.PKT file to stdout, if it exists and the signature verifies.

Pop pop pop

[44:

Mon Aug 24 04:24:56 2020 As long as we're perl packaging stuff, is
there any way we could get rid of the abomination of
src/drivers/mfzmake/common.pl.inc and make it a package?  For one
thing, it would certainly be nice if cdm could import that package,
and examine the guts of MFZ directly, instead of shelling out to
mfzrun all the time.

But come on.  Stop expanding the hack.  You just added 'mfzrun
announce' so that cdm (still) doesn't _need_ to muck inside MFZs
itself.
[45:

Mon Aug 24 04:50:36 2020 So how about we get cdm.pl to load
cdm-deleteds.mfz and see how that goes.

:45]
:44]

:43]


:42]
:41]
:40]
[46:

Mon Aug 24 09:10:03 2020 OK pushing again.  Still on loading common,
but now via 'DirManager.pm'.[47:

Mon Aug 24 09:55:29 2020 Still struggling to understand the goal
here.  OK we read a bunch of filenames/paths from say common/.  Then
what?  We want to end up with MFZManager for each of them.  And we
want a MFZMetadata to describe each of them.  We want some dictionary
to hold the complete-and-verified ones, and some other dictionary to
hold the in-progress ones.  Caller will need to know whether they want
only C&V files or IP files, and go to the appropriate dictionary.

Where are these two dictionaries?  CDM.pm presumably?[48:

Mon Aug 24 10:25:47 2020 OK made

    $self->{mCompleteAndVerifiedContent} = {}; # ContentName -> MFZManager
    $self->{mInPipelineContent} = {};          # ContentName -> MFZManager

in CDM.pm.  Let's officially ditch the MFZMetadata idea -- rolling it
into MFZManager -- and try to build CnV MFZManagers for common/

:48]

:47]

:46]
[49:

Mon Aug 24 12:33:02 2020 OK, well, making some progress, but feeling
like we want to subclass DirManager for DirManagerCommon and
DirManagerPipeline instead of trying to distinguish them with flags.
The initiatives wrt file creation, for example, are opposite in the
two cases.

:49]
[50:

Mon Aug 24 15:02:27 2020 Waiting for 3pm meeting to start..

:50]
[51:

Tue Aug 25 10:55:18 2020 Hmm a bunch of time there with no notes, but
we have had some progress if subclassing 'DirManager' is supposed to
be the starting point:

 - We now have DMCommon isa DirManager and DMPipeline isa DirManager.

 - We detect modtime changes on common/ and reload.

 - We detect modtime changes on .mfz's and drop their MFZManager,
   which leads to the .mfz being reloaded.

 - We load .mfz files and use 'mfzrun ANNOUNCE' to get and check their
   metadata,

 - We have a start at PacketListener isa TimeoutAble.  We're flushing
   packets at startup, and reading them (but not yet dispatching).

 - We redid TimeQueue for high res time instead of integer seconds.

Had a half hour+ power failure this morning.  (The UPS kept the net up
for most of that, so we could how widespread the outage was, good job
buddy.)

Getting set up again here.

:51]
[52:

Tue Aug 25 11:08:29 2020 Think a good next stop could be a class to
model the neighbors.  Will that be six instances, or one, or both?[53:

Tue Aug 25 11:28:44 2020 Urgh we already have 'DirManager' for
'Dir'ectory, but now here comes 'Dir'ection for neighbors..  Maybe
blow out to DirectoryManager, before it's too late?[54:

Tue Aug 25 11:41:37 2020 OK now we're 'Directory' for pretty much
every 'dir' that meant directory.

:54]

:53]

:52]
[55:

Wed Aug 26 00:07:58 2020 Well getting to be time for more sleep.  We
have NeighborhoodManager.pm that holds NeighborManager and handles
reading /sys/class/itc_pkt/status, since that produces all neighbor
statuses at once.

We have NeighborManager with an mState.  We should have them send
"A"liversion packets every so often, and track the version they
believe is running at the far end.

We should maybe have PacketListener give the NeighborManager first
crack at any inbound packets from a given neighbor?  Then if NgbMgr
doesn't eat it, pass it to the general content dispatch?  Or maybe,
since it's called PacketListener and all, it should have enough smarts
to know which packets to dispatch and which to handle.  PacketListener
might as well be the central content resolver itself, right?

:55]
[56:

Wed Aug 26 09:12:09 2020 OK, we're sending and handling A packets
saying version 3.  Thinking now we should be more explicit about which
inbound packets we are willing to consider as a function of whether
and what we know about their version.

Right now we have NM::considerInboundCDM eating "A" packets; we could
have it also eat any packets that shouldn't be examined before we have
version info.

The documented CDM packet types are:

A aliveness
F File announcement (traditional)
C Content request   (traditional)
D Data reply        (traditional)
P Pipeline operation (with subtypes)
   F File announcement
   A prefix Availability
   R content Request
   D Data reply

So for inbound packets maybe NeighborManager:

 - should always process As.

 - should consume Ps unless theirVersion >= 3 ?

 - should consume Fs, Cs ,Ds unless theirVersion >= 1

with the second point implying we can be incompatible with version 2
pipelining and just fall back to one-hop with v2s.

[57: Wed Aug 26 09:28:26 2020

And for outbound packets?  Do they all go through NM before departing?
Seems like eating outbound packets suggests some internal lack of
coordination.  Seems more like caller ought to check what's what
before even generating an inappropriate outbound packet.

But could have Rules for Callers or something in that regard?

 - Always consider sending A before anything else.  Could do that
   as a drive-by and maybe end up sending two packets.

 - Don't generate Fs or Cs unless theirVersion >= 1

 - Don't generate Ps unless theirVersion >= 3

 - Don't generate Ds unless the targeted content is the current CnV
   for that name.  Reply with an F, if possible, if not.  (Note the
   'current CnV' might in fact be obsolete relative to an in-progress
   pipeline version of the same name, but we're not going to ditch the
   current CnV unless and until we have a new CnV.)

 - Don't generate Cs unless theirVersion >= 1

 - Don't generate Cs if we have a newer PiP ('Pipeline in Progress')
   on the same name.  (Note that PiPs shall have 'progress
   constraints' on them -- if the inbound prefix doesn't actually grow
   for some amount of time, it gets aborted.  Unclear how that plays
   out.  Maybe we don't abort the pipelined content, but we mark it as
   'non-progressive', so it won't be a considered a PiP anymore,
   unless and until we get a PF retargeting the same content?.)

[58:

Wed Aug 26 09:56:39 2020 Have to break for a meeting.

:58]

:57]

:56]
[59:

Wed Aug 26 12:14:00 2020 OK, did the filtering rules in :56: above.
Now need to think about routing FCDs to the appropriate places.

Which are..

 - F, traditional file announcement: To DirectoryManager?  But that's
   just a base class; we have DMCommon and DMPipeline?[60:

Wed Aug 26 13:04:41 2020 Well, I guess I'm not sure that we have
enough abstractions yet.  An F could involve both DMCommon and
DMPending, for example.  Do we want to have like a
TraditionalTransferManager vs a PipelineTransferManager?  They would
do things like manage the SKUs and tags for content names, as well as
link to where the content can (currently) be found.

Maybe probably so.

But nap time I think.  Long run last night; if not a lot of notes.

:60]

:59]
[61:

Thu Aug 27 00:07:18 2020 OK let's get a half-decent run in now.  Give
me TransferManager and TMTraditional and TMPipeline GO GO GO.

Currently we have

 - MFZManager models a single MFZ file, in some directory, that might
    or might not be complete and verified.  Created either during
    directory loading (common/) or in response to a file announcement
    (pending/ or pipeline/).  Destroyed during MFZManager::update when
    underlying file vanishes or is unexpectedly modified.

 - DirectoryManager models a directory of MFZs.  Is the 'official'
   container of MFZs via {mMFZManagers}->{ contentName => MFZManager }

But we don't have any direct analog to the 'SKU' in the old $finfos
and the outbound tag in the (less) old $plinfos.

(1) Traditional file announcement arrives.  How do we process it?
    (1.1) Look in DMCommon to see if we already have that version or
          newer.  Drop uninteresting, else pass to DMPending if
          possibly interesting.
    (1.2) Look in DMPending (which doesn't exist yet?) to see if we
          have already started an MFZ for it or newer.  Drop if
          uninteresting, else pass to NeighborhoodManager to record as
          a source
    (1.3) Look in NeighborManager to see if we already have a
          SourceRecord (? which doesn't exist yet) for it.  Drop if
          uninteresting, else create a SourceRecord



:61]
[62:

Thu Aug 27 00:38:44 2020 What if we made an explicit Packet class,
with subclasses for each type of packet?  Idea is a traditional file
announcement, say, would get automatically expanded into a PacketTFA
(or whatever) when it's read, and then we could KEEP that object in
some natural place to refer to the content that it has.  So there
need be no such thing as a 'SourceRecord', say, instead we'd keep the
'actual' received PacketTFA in the NeighborManager and access its
fields that way.

In the reverse direction, of course, we'd create these packet objects
as objects, then have a serialization method that would do the
appropriate packing to send it out.

It's clean but a little scary, potentially confusing, to be dual-using
the packets for static data structures as well as in-flight data.

The nice thing is it's so transparent.  What was NW announcing about
FOO.mfz?  Well check the packet they sent.

Screw it let's do it.  Packet.pm and subclasses.[63:

Thu Aug 27 04:32:05 2020 Well taking too long of course but holy moly
Perl 'pack' format has got everything!  I thought I was dead once I
remembered that the traditional packet formats used a lot of
one-byte-length+that-many-bytes constructs for variable width fields,
but foggen 'slash' format in the Perl packing language covers that!

So ONE pack language expression involving five '/' constructs:

            ("a1 C/a* C/a* C/a* C/a* C/a*",  # Lovely!
             \$self->{mCmd},
             \$self->{mName},
             \$self->{mLength},
             \$self->{mChecksum},
             \$self->{mInnerTimestamp},
             \$self->{mSeqno}
            );

serves to create (pack) or parse (unpack) the cdm command byte plus
five variable length fields of the CDM "F" packet.

"As They Say:" NOICE!
[64:

Thu Aug 27 04:37:29 2020  Let's do the other traditional packets![65:

Thu Aug 27 05:55:31 2020 Wow, now we have Packet subclasses
registering themselves with Packet.pm via BEGIN blocks, and we have

 my $pkt = Packet::parse($packetString);

that iterates through the registered types, finding somebody that
recognizes $packetString, and then building an instance of the
associated class, unpacking $packetString into it, and returning it.
Wow!

[66:

Thu Aug 27 05:58:54 2020 Good run.  Second sleep now.[67:

Thu Aug 27 10:17:42 2020 And about time to move the flag.
[68:

Thu Aug 27 10:52:28 2020 Packing up.

:68]
:67]

:66]

:65]

:64]
:63]

:62]
[69:

Thu Aug 27 12:17:03 2020 Flag moved.  Where are we here.
[70:

Thu Aug 27 12:46:20 2020 (Dealing with a dead car battery grr.)

:70]
:69]
[71:

Thu Aug 27 12:46:33 2020 So what's next.

 - Do the new Packet structure for the pipeline packets?

 - Try actually to implement the one-hop protocol?  This I think.

:71]
[72:

Thu Aug 27 12:55:19 2020 To implement the one-hop protocol:

 - Somebody must send a traditional file announcement.  Seems like
   that could be an interaction between a NeighborManager and
   DMCommon?  NM would have a { contentname -> offeringtime } kind of
   thing and refresh it every so often?  An 'mCommonOffers' perhaps?
   NM asks DMCommon for a random CnV, checks it mCommonOffers, and
   sends a PacketCDM_F if it's been a while.

 - Somebody must receive it.  PacketIO gets a packet, and calls the
   Packet::parse class method on it, which returns a $pkt =
   PacketCDM_F.  Then PacketIO calls $pkt->receive()?  We should have
   a virtual Packet::validate() method to represent constraints that
   un/pack can't deal with.  We ould have Packet::parse call it right
   after unpacking, I'd think, and have validate return itself if it's
   happy or undef if it's not:

            my $ret = eval {
                $pself->unpack();
                $pself = $pself->validate();
                $pself;
            };

   or have unpack() do it:

    sub unpack {
        my ($self) = @_;
        my ($fmt,@varrefs) = $self->packFormatAndVars();
        my @values = unpack($fmt,$self->{mPacketBytes});
        for (0 .. $#varrefs) {
            ${$varrefs[$_]} = $values[$_];
        }
        return $self->validate();
    }


:72]
[73:

Thu Aug 27 23:30:13 2020 OK time for another run.  We have validation
happening plausibly in the new Packet* classes.  If perhaps some of
the checks aren't as strict as they could be, I think they'll at least
deal with egregious cases like unpack failing due to a short packet.

The pack/unpack symmetry is so nice that I'm actually validating
outbound packets before I send them, too -- because why not?

[74:

Thu Aug 27 23:33:40 2020 Also, for the record, I've been doing one-off
tests at the command line with mouthfuls like this:

t2@beaglebone:~/T2-12/apps/cdm/cdm$ perl -I . -e 'use PacketCDM_F; my $s = PacketCDM_F->new(); print($s->{mCDMCmd}." wongonwg($s)\n");$s->{mCmd} = "F"; $s->{mName} = "Foo-Bar"; $s->{mLength}=1234; $s->{mInnerTimestamp} = 1989870; $s->{mChecksum} = 9999; $s->{mSeqno}=-127;my ($fmt,@vars) = $s->pack(); use Data::Dumper;$Data::Dumper::Sortkeys = 1; print Dumper(\$sb);  $s->rawByte(4,"G"); $s->unpack(); print "((".$s->{mPacketBytes}."))"; print Dumper(\$s)'

which at the moment produces output like this:

    131 wongonwg(PacketCDM_F=HASH(0x138b1a8))
    INITOFNO2P PacketCDM_F=HASH(0x138b1a8)>>131
    $VAR1 = \'C1C1 A1C/a* C/a* C/a* C/a* C/a*';
    $VAR1 = [
              \128,
              \131,
              \'F',
              \'Foo-Bar',
              \1234,
              \9999,
              \1989870,
              \-127
            ];
    $VAR1 = [
              128,
              131,
              'F',
              'Foo-Bar',
              1234,
              9999,
              1989870,
              -127
            ];
    Packed packet failed validation: Missing seqno at /home/t2/T2-12/apps/cdm/cdm/Packet.pm line 90.
    t2@beaglebone:~/T2-12/apps/cdm/cdm$

(where that validation failure at the end is the 'purpose' of the test..)

:74]
:73]
[75:

Fri Aug 28 00:03:46 2020 So, now we could use some higher level
protocol logic to start sending and receiving this new Packets.

Actually, can we redo "A" handling first?  We're already sending and
receiving them..[76:

Fri Aug 28 00:05:28 2020 OK, the flow we currently have for receiving
"A" packets looks like this:

    cdm.pl ==>
     $CDM->eventLoop ==>
      $TimeQueue->runExpired ==>
       $PacketIO->onTimeout ==>
        $PacketIO->processPackets ==>
*        $PacketIO->dispatchPacket ==>
*         $NeighborManager->considerInboundCDM ==>
*          $NeighborManager->processCmdTypeA

and for sending them looks like this:

    cdm.pl ==>
     $CDM->eventLoop ==>
      $TimeQueue->runExpired ==>
       $NeighborManager->onTimeout ==>
        $NeighborManager->update ==>
*        $NeighborManager->considerSendingVersion ==>
*         $NeighborManager->sendVersion ==>
           $PacketIO->writePacket

and I'm thinking we want to rework the starred lines.

Let's go.

[77:

Fri Aug 28 00:17:07 2020 Right now, PacketIO::dispatchPacket is
unpacking and analysing a $pkt string by hand.  Let's build a Packet
there instead.
[78:

Fri Aug 28 00:19:36 2020 We currently have Packet::parse returning
undef on failure -- wouldn't we be happier making the effort to get
back an error message?[79:

Fri Aug 28 00:23:42 2020 Well, that's a bit of a schlep, since we
absolutely might be die-ing inside parse/validate, and capturing die
output involves more hair than just 'eval { foo }';.  Let's let it go,
I think, and say:

  Packet::parse may or may not print an error message, but will
  certainly return undef, if there's a problem.  Otherwise it returns
  a (subclass of) Packet.

:79]

:78]
:77]

:76]

:75]
[80:

Fri Aug 28 00:57:39 2020 So last time we tried to make up an inbound
packet processing flow, we got (usefully) sidetracked by validation.
But now we have validation and so we're back to the inbound flow.

So far we've modified PacketIO::dispatchPacket to build a Packet --
Just Can't Remember Who To Send It To.

Let's loosely follow the previous code, and give the relevant
NeighborManager a first crack at it, and then, if the NM doesn't eat
it, ask the packet to receive itself. ?

Perhaps we always just do that?  Maybe provide support code to help
get to the NM if a receiver in a Packet subclass wants it?

Let's give it a try.  New virtual method on Packet: handle

[81:

Fri Aug 28 02:03:24 2020 OK, so now we have
$packet->handleInbound($cdm) and we're successfully handling A packets
with it, finding that ET and WT on loopback are VERSION 3 (ourselves),
while NE is VERSION 2.  Next stop, generate and send the A packet
using our mavalis new technology.

:81]

:80]
[82:

Fri Aug 28 02:39:45 2020 OK, so now we're sending A packets via
$apkt->sendVia($packetio).  Last bug getting to that was forgetting to
set the packet header dir8 based on the NM mDir8.

So.  Good run so far.  Not quite three hours in.

Let's try to convert tradition F packet processing to new-style:

 - PacketCDM_F::handleInbound,

 - and somebody to issue them.  That'll be the challenge.

:82]
[83:

Fri Aug 28 02:46:53 2020 OK, we're handling an inbound traditional F.
What do we do?  Possible tasks/flows:

 - Ask DMCommon if it's got an MFZManager for name

..[84:

Fri Aug 28 03:03:35 2020 Guess I'm starting to drift here.

But it seems like the proper person to ask is CDM itself.  CDM is the
thing that's got the

    mCompleteAndVerifiedContent
    mInPipelineContent

data members.  The former a DMCommon and the latter a DMPipeline.

But we have no DMPending.  Shouldn't we?  At some point earlier we
were talking about transfer managers, no?
[85:

Fri Aug 28 03:06:38 2020 Yes, :61: above.  (Which is way back when 27
hours ago..)

So we're thinking of TransferManager as a base class, with
TMTraditional and TMPipeline as subclasses?  TMTraditional should
own DMPending, and TMPipeline should own DMPipeline.  Who owns
DMCommon?  Both traditional and pipeline interact with DMCommon.

Maybe CDM still owns DMCommon?  Is there value then in having
TMTraditional separate from DMPending, and TMPipeline separate from
DMPipeline?  They don't want to collapse?

Well, suppose we leave all the DMs under CDM, and have the TMs get
them as needed via the CDM.  The main point is to have a clear place
for transfer-related code.

So let's try to say yes TransferManager, yes TMPipeline and yes
TMTraditional (which really should be called something else) and see
how far we get.[86:

Fri Aug 28 04:36:57 2020 Well, I've definitely lost it now.  Should
have stopped at three hours or so.  Now closing in on morning stuff so
can't sleep yet.

:86]

:85]
:84]

:83]
[87:

Fri Aug 28 11:33:18 2020 OK after second sleep.  Let's get files
moving traditionally, coordinated by TMTraditional, NOW NOW NOW.

So far, we've:

 - made a TMTraditional, and

 - installed it $CDM->{mTraditionalManager} during createTasks().

Let's get TMTraditional announcing files during its updates.

:87]
[88:

Fri Aug 28 11:40:51 2020 Noting for the record that we do have some
lack of clarity about when we conventionally expect rescheduling to
happen during onTimeout workflows.

For example, it appears TMTraditional is failing to reschedule itself,
so it just runs once, near startup, and that's it.

I think the safe thing would be to have long-lasting processes
reschedule themselves at the _start_ of onTimeout using a conservative
long delay, and then let code during the update flow reschedule
earlier if they feel a reason too.  Actually, should we have a
mechanism for only moving a timeout earlier, rather than just
resetting it to something else?

[89:

Fri Aug 28 11:49:35 2020 Well, for now, maybe just have a built-in
default period, managed by TimeoutAble, and leave reschedule as it is.
We can revisit later if we're unhappy about having multiple resched
reasons during a single update.[90:

Fri Aug 28 12:22:31 2020 So now we have $to->defaultInterval() and
$to->defaultInterval($newdefaultintveral), implemented partly in
TimeoutAble.pm and partly in TimeQueue.pm

So TMTraditional is now surviving.

Pop pop pop.  Get to announcing a file.  Expecting yet another object
or map to manage announcement timings.

[91:

Fri Aug 28 12:31:12 2020 Should we think about some kind of thing to
manage contacts at the TransferManager level?  It would be answering
what questions?

 - When's the last time we mentioned FOO.MFZ to NE?

 - What's the (MFZ, DIR) pair we've least-recently considered
   announcing?

How about we pick some number of random (MFZ, DIR) pairs and return
the least-recently considered among those random pairs?

 - How can we, or do we need to, scrub our 'contact map' when MFZs or
   neighbor status changes?

Are we talking some version of a 2D array for (MFZ, NGB) -- in
particular, where we can iterate on either dimension as well as go in
for specific cells?

Do we really even need to build and maintain a data structure here, vs
just picking a single random MFZ and a single (alive) NGB and going
with that?

Maybe make a method like $transferManager->selectPair() and we can
start out with (randomMFZ,randomLiveNGB) and expand it later if we
feel the need?

Let's take a shot at that.

:91]

:90]

:89]

:88]
[92:

Fri Aug 28 14:26:02 2020 After lunch.  Working through
MFZManager::loadCnVMFZ trying to see how we get to a traditional file
announcement packet.

Reminding ourselves that we are storing a (nearly final) announce
packet FOR PIPELINING in the MFZManager, but that's not for
traditional use.

Actually, let's just rename that field:

  mFileAnnouncePacket -> mFilePipelineAnnouncePacket

[93:

Fri Aug 28 14:29:38 2020 Done.

:93]

:92]
[94:

Fri Aug 28 14:34:01 2020 OK, we're creating a traditional announcement
inside MFZManager, and now we have to get a sequence number from
somewhere.  Where are we going to get it, so that it can be used to
re-access this MFZManager later?

Do we make it a class variable of MFZManager?  What does the
cdm.pl-old do?  [95:

Fri Aug 28 14:39:20 2020 It does

  $seqno = ++$globalCheckedFilesCount;

in 'assignSeqnoForFilename', which happens in checkCommonFile (like
our loadCnVMFZ), plus perhaps elsewhere.

But, looking in cdm.pl-old, I see a bug for us now -- I was using
using the checksum reported by 'mfzrun ANNOUNCE' as the PacketCDM_F
mChecksum, but I think that's wrong.  It needs to be like

        $finfo->{checksum} = checksumWholeFile($path);

instead.  [96:

Fri Aug 28 14:48:14 2020 OK, may have fixed that.  Put
checksumWholeFile into T2Utils.[97:

Fri Aug 28 14:49:13 2020 Pop pop: So back to the seqno issue.  So I
guess we'll assign a seqno from an MFZManager class counter in
loadCnVMFZ, and we'll see how it goes.[98:

Fri Aug 28 14:51:19 2020 And more importantly, we'll add mSeqno as
another data member alongside mOutboundTag.  But we won't initialize
either of them until we need to.[99:

Fri Aug 28 14:54:22 2020 OK, we have a possibly plausible
MFZManager::createTraditionalAnnouncement, which uses the mSeqno
assigned by loadCnVMFZ, but looking ahead we're going to need a way to
get back from a seqno to the MFZManager, but at the moment we're not
providing anything to anybody.  This would be where a hook into a
TransferManager would be nice.

[100:

Fri Aug 28 15:04:44 2020 Could we unify seqnos and outboundtags?
Well, seqnos are slowly growing small ints; outbound tags are mostly
random 32 bitters.

Wait.  Maybe we don't want mSeqno in MFMZManager.  Maybe that's the
claim that seqno is a transfer manager property, not an MFZ property.
Same thing for mOutboundTag, actually.  We should be going to a
transfer manager for both of those things.

But that means we somehow have to join DirectoryManager, MFZManager,
and TransferManager, and have them all keep up to date or resync with
each other as things change.
[104:

Sat Aug 29 02:33:52 2020 So what's a next step here?  We have
TMTraditional selecting MFZ and Ngb --

44681.46:TMtrad#11: DirectoryManager getRandomMFZMgr [common] MFZManager=HASH(0x2fe47a8), MFZManager=HASH(0x2fe49a0)
44681.46:TMtrad#11: TMTraditional selectPair(MFZMgr:cdmd-TEST.mfz#13,NgbWT#8

so we should make a packet and send it.[105:

Sat Aug 29 02:45:45 2020 Ah okay we also are midway through a rethink
of the locations of seqnos and outbound tags.  Currently dying thus:

    2.37:DirMgr:common#0: loadCnVMFZ MFZMgr:TEST.mfz#13 (1,1598262268,234945,234681,0,TEST)
     at ./cdm.pl line 16.
            main::__ANON__("Attempt to access disallowed key 'mSeqno' in a restricted has"...) called at /home/t2/T2-12/apps/cdm/cdm/MFZManager.pm line 134
            MFZManager::loadCnVMFZ(MFZManager=HASH(0x18e0cb8)) called at /home/t2/T2-12/apps/cdm/cdm/DMCommon.pm line 32

because we killed the seqno key.  So we're saying we want to generate
and save aliases or synonyms or abbreviations for content names, at
the Transfer Manager level.  Well let's just do it.
[106:

Sat Aug 29 03:23:54 2020 Here Comes Mr State's Dog.

So creating state in a TransferManager, for seqno or outbound tag,
means we have to have a mechanism for maintaining that state, because
it's surely possible for MFZs to rot out from underneath MFZManagers,
and on up.

If we'd made an MFZManager be immutable, we could use its
TimeoutAble::mNumber as a unique key.  Have we made MFZManager
immutable?  [107:

Sat Aug 29 03:32:22 2020 No we have not, because for example we have
MFZManager::mState, setters for mfzState, incrementally growing
XsumMap..  So how do we know when our seqno has gone bad?[108:

Sat Aug 29 03:49:21 2020 Urgh dammit not coding here; reading perl doc
and whatnot.  Is there some kind of 'monotonicity criterion' we could
lean on?  That MFZManager is not immutable, but it only changes to
"become more it's truer self" in some way -- such as growing towards
the complete file size or by getting verified once it is.

If that was true, or we deem it to be correct whether it's currently
true or not, then we could rely on TimeoutAble::mNumber.

Let's do it and damn the torpedoes.

So TMTraditional, our first test use-case, will use [mNumber seqno] as
the offer data.  And we'll recreate the offer data if the
$mfzngb->{mNumber} changes.

It's tempting to think: Why Not Use mNumber As the seqno?

That would be harder to do with the outboundTag structure.

But if we're saying the mNumber must change when the .mfz underlying
an MFZManager has changed..

Let's do the additional dereference for now, and let this cook in the
background for a while.[109:

Sat Aug 29 04:10:28 2020 OK, getting there.  Realized our new Packet
structure allows a nice thing: Instead of storing the seqno in the
cached TransferManager offer data, we can store the PacketCFM_F packet
instance itself.  Then just retarget its packet header and send it off
in all directions as long as the MFZManager::mNumber doesn't change.

But our packet appears incomplete so far, so we couldn't even send it!
Behold:

    19.02:TMtrad#11: sendVia failed (Packed packet failed validation: Missing length at /home/t2/T2-12/apps/cdm/cdm/Packet.pm line 122, <__ANONIO__> line 5.
    )
    19.02:TMtrad#11: TMTraditional SSSSSENTT

Now, CDM_F::mLength is set by MFZM::mFileTotalLength, which is initted
to -1 in MFZM::new.  So when does it get set properly?[110:

Sat Aug 29 04:15:32 2020 It gets set in MFZM::loadCnVMFZ (naturally).
So we should make sure mfzState() >= MFZ_STATE_CCNV before building an
announcement.  Do we want to check that in selectPair, possibly?  No,
because TMPipeline won't have that restriction.

:110]

:109]

:108]

:107]

:106]


:105]

:104]
[101:

Fri Aug 28 15:42:58 2020 Taking a Friday afternoon break.

:101]
:100]

:99]

:98]

:97]

:96]Which I guess loadCnVMFZ will have to do..  We better be
reusing this work pretty hard..

:95]

:94]
[102:

Sat Aug 29 02:22:18 2020 OK let's get a solid three hours in here GO
GO GO.  We should have traditional transfer RUNNING well before the
clock expires GO GO GO.

Have to get a glass of ice water first tho[103:

Sat Aug 29 02:28:50 2020 Well cokfee instead because the pitcher was
low but okay

GO GO GO

:103]

:102]
[111:

Sat Aug 29 04:20:32 2020 WHO RAH!  We have reached:

	main::__ANON__("XXX IMPLEMENT ME at /home/t2/T2-12/apps/cdm/cdm/PacketCDM_F.p"...) called at /home/t2/T2-12/apps/cdm/cdm/PacketCDM_F.pm line 81

which is this in PacketCDM_F.pm:

    ##VIRTUAL
    sub handleInbound {
        my ($self,$cdm) = @_;
        die "XXX IMPLEMENT ME";
    }

So.  How do we handle an inbound traditional packet announcement?

Is a TransferManager involved in inbound processing?  Somebody needs
to connect us to DMPending.  Are TransferManagers meant to be
bidirectional?  That was a pretty confusing aspect of cdm.pl-old

But since the thing has got TRANSFER right in the name, it shouldn't
be much of a stretch to think both sender and recipient would be
involved?  If we renamed it to ServerManager then having a
ClientManager wouldn't be so weird.

Well, let's try to do both sides in the TransferManager, carefully,
gingerly, and see how clear we can keep it.
[112:

Sat Aug 29 04:38:24 2020 So that means PacketCMD_F::handleInbound
needs to reach TMTraditional -- and who should know that?

Who's dispatching to handleInbound ATM?[113:

Sat Aug 29 04:39:56 2020 It's PacketIO::dispatchPacket ==>
handleInbound.  And that makes sense -- it's the packet type that
would naturally know (much of) how it should be routed.

So we should have packetCMD_F::handleInbound get TMTraditional from
CDM, and call some clienty-sounding method on it.
[114:

Sat Aug 29 04:49:13 2020 OK, we've gotten to here:

    7.22:PacketIO#3: TransferManager handleAnnouncement not overriden for WT CDM 'F' + 49

It's getting close to morning business but the next stop is
TMTraditional::handleAnnouncement.  Let's start into it anyway.

:114]

:113]

:112]
:111]
[115:

Sat Aug 29 06:06:13 2020 OK, back from morning stuff, and immediately
found my stupid typoe that had been hiding from diagnosis when I broke
off.  Now we're back to

   main::__ANON__("XXX FINISH ME at /home/t2/T2-12/apps/cdm/cdm/TMTraditional.pm"...) called at /home/t2/T2-12/apps/cdm/cdm/TMTraditional.pm line 37

:115]
[116:

Sat Aug 29 06:23:18 2020 Added and tested Packet::validateAsClass and
Packet::assertValid so we can insist that a $pkt be a specific
subclass of Packet.  First use is:

    sub handleAnnouncement {
        my $self = shift;
        my PacketCDM_F $pkt = PacketCDM_F->assertValid(shift);
  ..

(and now we need the rest of that..)
:116]
[117:

Sat Aug 29 06:25:16 2020 And how do we handle a traditional file
announcement?

Well, cdm.pl-old goes

processFileAnnouncement ==> checkAnnouncedFile ==> checkIfFileInCommon

and if not, then it manually creates stuff in pending.

What does that look like now?  Guess we want to get our mitts on
DMCommon and ask it about $pkt->{mName}.  Our grubby mitts, I mean.

:117]
[118:

Sat Aug 29 08:07:40 2020 OK, so we've made quite a bit of plain
procedural flow here, in TMTraditional::handleAnnouncement and now
TMTraditional::requestChunkFrom, and we're starting to hit
off-main-line cases like this:

     at ./cdm.pl line 16, <__ANONIO__> line 2.
            main::__ANON__("Died at /home/t2/T2-12/apps/cdm/cdm/DirectoryManager.pm line "...) called at /home/t2/T2-12/apps/cdm/cdm/DirectoryManager.pm line 63
            DirectoryManager::insertMFZMgr(DMPending=HASH(0x2b8d6c8), MFZManager=HASH(0x2bce8e0)) called at /home/t2/T2-12/apps/cdm/cdm/DMPending.pm line 32
            DMPending::newContent(DMPending=HASH(0x2b8d6c8), "cdmd-MFM.mfz") called at /home/t2/T2-12/apps/cdm/cdm/TMTraditional.pm line 71
            TMTraditional::handleAnnouncement(TMTraditional=HASH(0x1e68338), PacketCDM_F=HASH(0x2bcebb0)) called at /home/t2/T2-12/apps/cdm/cdm/PacketCDM_F.pm line 104

because we're hitting existing files in pending/ when we go to init a
new one in response to a traditional file announcement.

Are we not flushing pending/ on startup?  (Which would only avoid a
subset of such problems, but..)[119:

Sat Aug 29 08:12:46 2020 It looks like we are:

    ./cdm.pl start
    Found ./cdmDEBUG
    Flushed 2 ./cdmDEBUG/pending files
    Found ./cdmDEBUG/common
    Found ./cdmDEBUG/log
    Made ./cdmDEBUG/pending

so that's not it.  Maybe it's just a repeated 'F' acket that we aren't
detecting as repeated?


:119]

:118]
[120:

Sat Aug 29 08:30:27 2020 OK, now we've gotten to here:

    0.59:PacketIO#3: QQUNPACK(PacketCDM_F=HASH(0x1b26a08))

Recvd an F from ngb and processing it..
  ..
    0.59:PacketIO#3: DirMgr:pending#1 inserted (cdm-distrib-T2-GFB.mfz)
Leading to creating an entry in pending
  ..
    0.59:PacketIO#3: sendVia2(PacketCDM_C=HASH(0x1b27a18))
And us requesting a chunk of it from them
  ..
    0.99:PacketIO#3: No inbound handler for NE CDM 'D' + 200
But us not being able to handle it when it arrives.


:120]
[121:

Sat Aug 29 09:00:14 2020 OK, fading here; want to wise up and take a
break instead of doing crabby code.  For when we return

TODO

 - Change TransferManager so serverData and clientData support
   indexing by $contentName and indexing by some other provided
   scalar.

 - Use that in TMTraditional to look up clientData by SKU

 - Use that to complete a first cut at handleDataChunk.

:121]
[122:

Sat Aug 29 13:05:34 2020 Starting.

:122]
[123:

Sat Aug 29 13:56:03 2020 OK so I'm losing track of the symmetry that
I'd thought I'd seen between the serverData and the clientData.  I've
been trying to reuse the same accessing code, just passing
\$self->{mServerData} vs \$self->{mClientData} -- but that seems wrong
now.

In particular, there seems to be a single serverData record
for a given $cn, but there can be multiple clientData records for a
given $cn, depending on dir8.  We broadcast the same thing to all our
neighbors, but our neighbors all broadcast different things to us.

If anything, it seems more like us-as-server is just like one more
direction that can have metadata.  So maybe we could collapse
mServerData and mClientData and just have something like

  mMetadata => [ { cn -> { dir9 -> [dir9 cn key2 ..] } } { dir9 -> { key2 -> cn } } ]

where dir9 is dir8 + some special code meaning 'server'?  Too
dangerous to consider dir9 == undef means 'server'?  Probably.
Probably better to use 8.  Make it visible in the ${rec}s.

and we'd have

  getMetadata($cn,$dir9) undef or existing [$dir9 $cn key2 ..]
  storeMetadata($rec) insert/overwrite based on dir9, cn, and key2 of $rec
  eraseMetadata($rec) delete based on dir9, cn, and key2 of $rec

  getMetadataK2($k2,$dir9) undef or existing [$dir9 cn $k2 ..]

Are we saying that server and client recs are expected to have the
same structure beyond the first two elements?  We'll see.

[124:

Sat Aug 29 14:25:13 2020 Pull the trigger time's a-wasting GO GO GO

:124]

:123]
[125:

Sat Aug 29 15:02:41 2020 OK so we have that roughed out in
TransferManager.  How do we test it?

:125]
[126:

Sat Aug 29 22:03:20 2020 OK so time for another run.  We're real close
on traditional transfer.  Need to handle getting to the end, and deal
with the transfer to DMCommon..

We left off before dinner facing this bizarre bug where an
MFZManager's mDirectoryManager seems to suddenly change into an
unblessed hash, like this:

    9.20:PacketIO#3: MFZManager::appendDataTo 3371 + 177
    9.20:PacketIO#3: MFZManager::getPathToFile MFZManager=HASH(0x2336340) DMPending=HASH(0x22ff6d0)

That's output from:

    DPSTD("${\FUNCNAME} $self $self->{mDirectoryManager}");

and $self->{mDirectoryManager} is a DMPending=HASH(..), which makes
perfect sense..

    9.20:PacketIO#3: MFZManager::appendDataTo 3548 + 177
    9.20:PacketIO#3: MFZManager::getPathToFile MFZManager=HASH(0x2336340) DMPending=HASH(0x22ff6d0)

Ditto

    9.42:MFZMgr:cdm-distrib-T2-GFB.mfz#16: MFZManager::getPathToFile MFZManager=HASH(0x2336340) DMPending=HASH(0x22ff6d0)

Ditto ditto

    9.42:MFZMgr:cdm-distrib-T2-GFB.mfz#16: ./cdmDEBUG/pending/cdm-distrib-T2-GFB.mfz MODTIME CHANGE, deleting mgr

Ahh hmmmmmm

    9.43:PacketIO#3: MFZManager::getPathToFile MFZManager=HASH(0x2336340) HASH(0x233bd08)
     at ./cdm.pl line 16, <__ANONIO__> line 1.
            main::__ANON__("Died at /home/t2/T2-12/apps/cdm/cdm/MFZManager.pm line 261, <"...) called at /home/t2/T2-12/apps/cdm/cdm/MFZManager.pm line
261

and we're dead..  So, that 'deleting mgr' now catches the eye AY WAT?

[127:

Sat Aug 29 22:12:24 2020 So that's coming from MFZManager's
onTimeout/update method, which has this

    # Start over on modtime changes
    if (defined($self->{mFileModificationTime}) && -M $filepath != $self->{mFileModificationTime}) {
        DPSTD("$filepath MODTIME CHANGE, deleting mgr");
        $self->{mDirectoryManager}->removeMFZMgr($self);
        return;
    }

which might (possibly) be a reasonable to do in DMCommon, but we can't
be doing that for DMPending (nor DMPipeline) when the modification
time is going to be changing with every data packet.[128:

Sat Aug 29 22:15:37 2020 We could maybe do that check only if
mfzState() is CnV?[129:

Sat Aug 29 22:18:46 2020 Well, trying that for now:

    # If we're CnV, we shouldn't change: Start over on modtime changes
    if ($self->mfzState() == MFZ_STATE_CCNV &&
        defined($self->{mFileModificationTime}) &&
        -M $filepath != $self->{mFileModificationTime}) {

        DPSTD("$filepath MODTIME CHANGE, deleting mgr");
        $self->{mDirectoryManager}->removeMFZMgr($self);
        return;
    }

but certainly noting that cleanup should be more thorough and
structured than that.

:129]

:128]

:127]

:126]
[130:

Sat Aug 29 22:22:00 2020 OK, so, FINALLY, traditional transfers are
starting to accumulate in pending:

      /home/t2/T2-12/apps/cdm/cdm/cdmDEBUG/pending:
      total used in directory 184 available 363368
      drwxr-xr-x 2 t2 t2  4096 Aug 29 22:20 .
      drwxr-xr-x 7 t2 t2  4096 Aug 29 22:20 ..
      -rw-r--r-- 1 t2 t2  1143 Aug 29 22:20 cdm-deleteds.mfz
      -rw-r--r-- 1 t2 t2  7603 Aug 29 22:20 cdm-distrib-T2-GFB.mfz
      -rw-r--r-- 1 t2 t2 82257 Aug 29 22:21 cdmd-MFM.mfz
      -rw-r--r-- 1 t2 t2 79969 Aug 29 22:21 cdmd-T2-12.mfz

Compared to:

      /cdm/common:
      total used in directory 16552 available 409136
      drwxr-xr-x 2 root root     4096 Aug 29 08:06 .
      drwxr-xr-x 7 root root     4096 Aug 29 08:06 ..
      -rw-r--r-- 1 root root     1143 Aug  9 05:26 cdm-deleteds.mfz
      -rw-r--r-- 1 root root     7603 Aug  3 23:00 cdm-distrib-T2-GFB.mfz
      -rw-r--r-- 1 root root 14960349 Aug  9 07:30 cdmd-MFM.mfz
      -rw-r--r-- 1 root root  1954598 Aug  6 13:31 cdmd-T2-12.mfz

on our NE neighbor.

We need to get crispy about 'file complete' and 'file obsolete'
transitions.  At least and soon.

[131:

Sat Aug 29 22:45:40 2020 Jeez looking at George Douros' 'Symbola'
font.  Jeez.

:131]

:130]
[132:

Sat Aug 29 22:48:18 2020 OK so let's take a beat, here.  What do we
THINK should happen when the last of a pending .mfz comes in?

 - FOO.mfz on disk should be checked by mfzrun VERIFY.  If
   verification fails the file should be deleted, and the MFZManager
   either deleted ("easier") or marked as "unverifiable" (just delete
   it).

 - FOO.mfz on disk should be moved from pending/ to common/.

 - If there's an existing common/FOO.mfz, it should be
   removed, and its DMCommon MFZManager should be removed as well

[133:

Sat Aug 29 23:13:18 2020 So how about naming some 'terminal actions'
for MFZManagers?

 - MFZManager::deleteContent() -- Delete file on disk, remove $self
   from DirectoryManager::mMFZManagers, mark $self dead or deleted
   somehow, and unschedule self from TQ.  Perhaps have
   TransferManager metadata records check that their mfzmgr is still
   alive when they access it.

 - MFZManager::detachFromContent() -- Do all the things of
   deleteContent except don't delete the file on disk.  The goal is to
   allow us to then manipulate the file (e.g., mv pending -> common)
   and create a new MFZManager for it.

[134:

Sat Aug 29 23:19:50 2020 Yeah this is helpful.  Go again:

 - MFZManager::destructDetach() -- Remove $self from
   DirectoryManager::mMFZManagers, mark $self dead or deleted somehow,
   and unschedule self from TQ.  Perhaps have TransferManager metadata
   records check that their mfzmgr is still alive when they access it.

 - MFZManager::destructDelete() -- Do destructDetach, then delete the
   file on disk.

[135:

Sat Aug 29 23:22:27 2020 Come on try it.  GO GO GO

:135]

:134]

:133]

:132]
[136:

Sun Aug 30 01:12:25 2020 OK, so current question is about content
names.  In cdm.pl-old, we basically trust the surface filename -- if
the file is FOO.mfz, the content name is 'FOO', and that's that.  If
we make a copy of it called FOO2.mfz, its content name is 'FOO2'.

But there is also an 'inner content name', in the MFZNAME.DAT file in
the inner zip.  And if the file was called 'FOO.mfz' when it was
signed, then 'FOO.mfz' remains the inner content name regardless of
what happens to the surface file name.

So you'd think, really for safety, one should rely on the inner
content name for purposes of triggering actions and what not.

I think in fact, in the old system, if you had some signed mfz like
cdmd-MFM.mfz, that happened to be newer than some other signed mfz
like cdmd-T2-12.mfz, you could copy cdmd-MFM.mfz on top of
cdmd-T2-12.mfz, and my best guess is the 'new' cdmd-T2-12.mfz would
get distributed, unpacked into its inner correct place (because that's
determined by the tar file), but then the wrong hardcoded install
routine would be run.[137:

Sun Aug 30 02:08:22 2020 So I think an alleged 'cdmd-T2-12.mfz' that
really contained a cdmd-MFM.tgz inside would get installed to
/home/t2/MFM, and then 'make -C /home/t2/T2-12 install' would get run,
re-installing the current T2-12 stuff.

But anyway.[138:

Sun Aug 30 02:10:03 2020 So the bottom line issue is this:

The ANNOUNCE.PKT that is being packed into new MFZ files *does*
contain the inner content name in a reasonably accessible form.  (And
in a reasonably credible form too, since it's independently signed).

If we depended on that announce packet, we'd have a reasonably
principled way to check which MFZManagers represented different takes
on the same content.

But we were still hoping for 'backward compatibility'.[139:

Sun Aug 30 03:04:53 2020 Screw it.  Let's count on the ANNOUNCE.PKT.
The existing code in the grid won't need it, so it'll go ahead and
install the cdmd-T2-12.mfz containing both the ANNOUNCE.PKT and the
code that depends on it.

So, we're going refactor the loadCnV code rather than have a separate
non-ANNOUNCE-using version.
[140:

Sun Aug 30 03:10:34 2020 Well so for now we're just calling loadCnVMFZ
on the $pmgr we're looking at..  And it's failing because it's looking
at an old .mfz in from the neighbors..  So we have to replace the
ngb's /cdm/common .mfz's with something new..

:140]
:139]

:138]

:137]

:136]
[141:

Sun Aug 30 04:11:23 2020 Well, late late and almost surely rickety,
but traditional transfer seems to be working -- so long as it's only
'new style' .mfzs containing ANNOUNCE.PKT files.

So that's something.  And the transfer between pending/ and common/ is
smooth enough that it switches right over to

    187.50:PacketIO#3: Don't need PacketCDM_F=HASH(0x2231890) MFZMgr:NEWSTAL.mfz#14

once it's released 'NEWSTAL' the new .mfz

[142:

Sun Aug 30 05:05:08 2020 Morning time.  Should implement a 'C' handler
so others can get stuff from us..

:142]

:141]
[143:

Sun Aug 30 07:14:53 2020 OK, getting to be second sleep time, but
we've made a lot of progress.  Files are traditionally transferring in
and out.  At the moment, we tend to be requesting files we already
have in common, accumulating them in pending, then discovering that we
don't need them -- at which point, at the moment, they just sit there
in pending.

In cdm.pl-old, we avoided that problem by preloading everything in
common, before we started talking to the world.  Probably should just
do that again here, for now at least.

:143]
[144:

Sun Aug 30 13:50:11 2020 Up.  Well it's time to look at TMPipeline I
guess!  Have a whole day and a bit of time left.  There are remaining
issues in TMTraditional -- for example we're missing the part about
adding sources to the metadata..

Actually, maybe we should get a three-tile cluster going here, just to
see a _little_ bit of the multi-source and multi-path issues, before
losing the current head of of TMTraditional state.[145:

Sun Aug 30 16:28:42 2020 OK, post meeting; have an hour or so before
final dinner prep.

Could we consider activating cdm-deleteds for the first time in the
history of the universe?[146:

Sun Aug 30 17:05:33 2020 OK so here's the format of the records in the
cdm-deleteds.map that lives inside cdm-deleteds.mfz:

    cdm-distrib-T2-GFB.mfz 7603 d80920a9d0f1a33c8309f9884267e372 1559576278

and I think at least for a first cut, we'd just care about the
contentname and the inner timestamp, and we'd say any file of that
name that isn't newer than the given timestamp counts as deleted.

We'll make a DMCommon::mDeletedsMap { cn -> [ cn len cksum innerts ] }
data member.  We'll make a special release trigger on cdm-deleteds.mfz
that reloads that map.[147:

Sun Aug 30 17:12:24 2020 Have to stop now, but: We'll provide a
DMCommon::isDeleted($cn,$its) method, and check that in newContent or
thereabouts.

:147]


:146]

:145]

:144]
[148:

Mon Aug 31 01:18:02 2020 Well, I've got to get some sleep here, but
yah know, it's getting to be time to commit this bad bein.  I think
it's close to the point where it's better than the original ever was
at traditional transfers, and we have new features like cdm-deleteds
is kind of working as well.

:148]
[149:

Mon Aug 31 06:04:12 2020 OK so will need more sleep after a bit but
head full of stuff so saying let's do a short run now.

TODO

[151: Mon Aug 31 10:46:36 2020 Well, took a cut at this
STARTED ANYWAY:151] - Release trigger for cdmd-T2-12.mfz

[150: Mon Aug 31 10:11:26 2020
DONE, a first cut anyway:150] - A 'CDM view' for mfmt2?

:149]
[152:

Mon Aug 31 10:46:59 2020 Hard to know how to test the T2-12 release
trigger, since it's going to nuke our git working repo even if it
succeeds.

Maybe we should move our working directory elsewhere, at least for a
while?

[153:

Mon Aug 31 10:53:28 2020 Well, putting it in /home/t2/T2-12-repo, for
now.

:153]
:152]
[154:

Mon Aug 31 11:50:01 2020 OK, committing and pushing in T2-12.  Gotta
try the install trigger..

:154]

[155:

Wed Sep  2 01:45:22 2020 OK, it was super late, but t2sup#284 finally
shipped.  I Want to Keep Up The Pace Here!

TODO

[161: Wed Sep  2 02:45:27 2020 For now, let's call that
DONE  :161] - Rough out set of actions that can be used by hook functions (and
   eventually formalized somehow)

[162: Wed Sep  2 04:15:42 2020 So slow
DONE :162] - Action for restarting CDM

[163:
DONE :163] - Action for restarting MFMT2

[164:
DONE:164] - Action for rebooting

 - Action for changing MFMT2 persistent command line arguments (or
   specifically just what physics to run)

[165: Wed Sep  2 04:56:33 2020
DONE :165] - Have some kind of map for { cn => { hook => [ action.. ] } }

[159:

[166:
DONE :166] - Add these mappings to the map

    cdmd-T2-12.mfz => { RELEASE => RESTART_CDM }
    cdmd-MFM.mfz => { RELEASE => RESTART_MFMT2 }

[160:

Wed Sep  2 02:44:14 2020 Damn, fell off for a youtube/twitter/gitter
check in.  Probably cost a half hour?

STOP MAKING TO-DO.  GO GO GO.

:160]

  :159][156:

Wed Sep  2 01:53:08 2020

 - ?Create an interposition between mfm.sh and mfmt2, so that mfm.sh
   runs the delegate, and the delegate runs the engine.

 - ?Maybe cdmake could help standardize such a delegate?  (What does
   the 'cd' in .. oh yeah, 'common data' I guess)

 - ?Maybe cdmake could check that some particular file is included in
   the packing.  Actually, we already have something like 'args.txt',
   right?  Where does that get checked/applied?  Oh yeah, it's right
   near cdmake in the mfzmake help:

       (4) args.txt  -> mfzrun adds first line to simulator arguments

   And are we going to say that mfmt2 and mfms are NECESSARILY
   supposed to accept identical command line arguments?  That seems
   superficially handy but very restrictive and potentially very
   misleading.

[157: Wed Sep  2 02:05:55 2020
   I think we should try to say that mfmt2 'does not have' (m)any
   'mfz-settable' command line args.  That as much as possible mfmt2
   should be a fixed target relative to physics creators.

:157]

:156]

:155]
[158:

Wed Sep  2 02:06:43 2020 OK don't go spinning out too far ahead on
design fantasy here.  'Return to the to-do' says the fortune teller.


:158]
[167:

Wed Sep  2 04:56:51 2020 Committing, to make a new cdmd-T2-12.mfz and
push it..

So, just over three hours since :155: above.  Not a great run, but an
okay run for sure.

:167]
[168:

Thu Sep  3 06:20:31 2020 Did a test run with cdmd-MFM.mfz going two
ways at once -- it was like five hours, gah.  I did slow the packet
handling down because cdm was really eating the machine.  CDM can do
like 7-8K in two directions taking like 35+% of the CPU.  Slowed-down
it was doing like 4.5K in two directions using <10% of the CPU (idling
right now it's like ~2-3%.)

:168]
[169:

Thu Sep  3 06:29:48 2020 So today is a bit crowded but it's about time
to think about pipelining again right?

TODO

[220: Sun Sep  6 11:22:12 2020
DONE :220] - Review current protocol exchanges for pipeline

 - Think briefly about whether we announce both traditional and
   pipeline, where possibly, and how we respond to that if so.

[252: Tue Sep  8 15:43:35 2020
DONE :252] - Start fleshing out TMPipeline following 'best practices' such as
   they emerged from TMTraditional.

 - Report back in about sticking points encountered.

:169]
[170:

Thu Sep  3 06:35:38 2020 About time for a nap.

:170]
[171:

Thu Sep  3 16:16:02 2020 Moving the flag.

:171]
[172:

Thu Sep  3 23:09:09 2020 OK let's book three hours here and get
pipelining NG *significantly advanced*!  START THE CLOCK GO GO GO

:172]
[173:

Thu Sep  3 23:10:28 2020 Current status of TMPipeline?  -> Super
empty, just new() and update()!

Let's init from TMTraditional?[174:

Thu Sep  3 23:13:02 2020 Let's not do that whole-hog.  Let's go
function by function and review as we go.[175:

Thu Sep  3 23:14:26 2020 Hey, we're going to need need CDMPACKET_*
files!  That could be a good place to warm up.[176:

Thu Sep  3 23:17:33 2020 The pipeline format uses subtypes under the
CMD P packet.  Do we want separate .pm's for each subtype?

Do we have subclassing going on in CDM packet land?  Of course we do!
So we want a stub-ish CDMPacket_P.pm, and then yes, CDMPacket_PF.pm
and so on.  Do it.[177:

Thu Sep  3 23:20:47 2020 Ah oops! :) We already have PacketCDM_P.pm!
And it's already partially parsing P packets, in to

    use fields qw(
        mPipelineCmd
        mTemporarilyUnparsedText
        );

so we should take away mTemporarilyUnparsedText, and get, say
PacketCDM_PF.pm going.

[178:

Thu Sep  3 23:30:40 2020 Yikes, I picked PF to, 'say', start with --
but that's the pipeline file announcement!  Which is the MOST SPECIAL
PACKET OF THEM ALL -- it's the one that shows up in ANNOUNCE.PKT.  The
old cdm.pl doesn't even know how to parse those packets!

Off to mfzmake, I guess?[179:

Thu Sep  3 23:33:24 2020 Yes, here in 'MakeAnnouncement' in
mfzmake.tmpl, stuff like:

    my $packetdata =
        pack(ANNOUNCE_PACK_DATA_FORMAT
             ,0x80, 0x83, "F"
             ,1
             ,$innertime
             ,length($inner)
             ,$regnum
             ,$checksum
             ,$contentname
        );

aaaand... am I given to understand.. that.. ANNOUNCE.PKT contains a
packet that claims to be a CDM "F" packet?  Which Of Course Already
Exists It's The Traditional File Announcement That Has A Completely
Different FORMAT THAN THIS FOGGEN F PACKET HERE WHAT THE HAIL?

[180:

Thu Sep  3 23:45:32 2020 GRRRR!

(Not to mention that :56: above explicitly says
  ..
    The documented CDM packet types are:
  ..
    F File announcement (traditional)
                         ^^^^^^^^^^^

DUR DUR)

:180]

:179]

:178]
:177]

:176]

:175]

:174]

:173]
[181:

Thu Sep  3 23:48:08 2020 So, OPTIONS!  PEOPLE, I NEED OPTIONS, HERE!

OPTIONS

1. Change the ANNOUNCE.PKT packet type to something else.  'S' for
   Signed?  'M' for 'M'etadata?  [187: 'S' for Summary?  :187][183:
   Pro:
    + Cleanest solution according to existing design
   Con:
    x Invalidates all existing cdmd ANNOUNCE.PKTs

:183]

2. Wrap the contents of ANNOUNCE.PKT in some whole other PF
   packet[184:
   Pro:
    + Existing ANNOUNCE.PKT format can be preserved
    + MFM tree unaffected
    + Minimal CDM redesign required
   Con:
    x Existing (nearly new) ANNOUNCE.PKT format contains misleading
      garbage -- its packet header -- that will never be used

:184]

 - [Try to distinguish the two types of F on the fly] (DESK REJECT)

3. Redo ANNOUNCE.PKT more substantially -- it doesn't really HAVE to
   contain a full-on-real packet at the time it's signed.  It just
   needs to be a payload we can recognize in a larger context.[185:

   Pro:
    + Better separation of concerns.  mfzmake no care about packets
    + Can decide appropriate packet header formats elsewhere
    + Could use the payload in other packet types without shame
   Con:
    x Invalidates all existing cdmd ANNOUNCE.PKTs
    x Why is file extension 'PKT'?
    x Requires non-neglible redesign

:185]

[182:

Thu Sep  3 23:54:49 2020 PROS AND CONS THEN.

:182]
:181]
[186:

Fri Sep  4 00:14:47 2020 Well, I'm leaning toward some version of
option 3 I guess.  With details like:

 - Change name to perhaps SUMMARY.DAT
 - Don't have a packet header inside it
 - Keep the announcement version but make it 2

[188:

Fri Sep  4 00:19:12 2020 And once I say that, I immediately start
leaning toward option 1 instead.

 - Change third byte of ANNOUNCE.PKT from 'F' to 'S'.
 - Change fourth byte from 0x01 to 0x02 (in sympathy)
 - Regenerate all existing cdmds before trusting their ANNOUNCE.PKTs

[189:

Fri Sep  4 00:21:40 2020 OK, mandatory look-away break before making
decision.  FIFTEEN MINUTES PEOPLE.  BE BACK AT TWENTY OF.[190:

Fri Sep  4 00:57:41 2020 Well forty minutes then.

Sticking with option 1?

Sticking with option 1.[191: Fri Sep  4 01:01:49 2020 DONE  :191]

GO GO GO

:190]

:189]

:188]


:186]
[192:

Fri Sep  4 01:03:53 2020 OK, for the record, the ANNOUNCE.PKT format
is (now) this:

  3   hdr                   0x80.0x83.'S'
  1   announcement version  0x02
  4   big-endian inner timestamp
  4   big-endian inner length
  2   big-endian regnum
  8   inner checksum substr
 50   content stem (filename without '.mfz')
===
 72
128   RSA sig
===
200

[193:

Fri Sep  4 01:06:07 2020 And we need a whole separate PacketCDM_S.pm
for it!

:193]

:192]
[194:

Fri Sep  4 02:15:20 2020 Urgh fell off a couple more times.

One issue in restarting low-level development here is how do we get
back to spike testing instead of watching the whole system..  At
least, we need to get cdmDEBUG going again, and a loopback, and maybe
shut down the neighbors for a while..

:194]
[195:

Fri Sep  4 02:26:47 2020 (Working back to spike access.  Currently
only using loopback.  Changed StatusReporter to only include dirs that
are NGB_STATE_OPEN.)

:195]
[196:

Fri Sep  4 03:47:47 2020 OK so we're finally parsing 'S' packets
plausibly.  How do we actually check the signature?  Is that yet
another mfzrun function we're supposed to process out for?  Do we want
to think about doing the common.pl.inc -> .pm thing and making it
available to MFM and T2-12?

:196]
[197:

Fri Sep  4 04:14:19 2020 All right, we're well over three hours from
:172: above and I've lost focus.  We've got pipelining *slightly*
advanced rather than significantly, buuuut it's a start.

Let's go for second sleep and pick up.. where?

 - common.pl.inc -> .pm

 - but, who owns it?  MFM and T2-12 both make good claims:

   = MFM: I need it for mfms workflows utterly separate from T2-12!

   = T2-12: I need it to ship the MFM source code between tiles!

[198:

Fri Sep  4 04:21:50 2020 I think MFM's claim might still be better.
T2-12's claim is a chicken-and-egg thing that's a temporary concern
only when mfmzrun (say) actually changes.  MFM's needs never go away.

We could have the cdm Makefile try to pull a copy of the mfz libs from
the MFM tree, then use it locally?  That might not be awful.

:198]

:197]
[199:

Fri Sep  4 11:58:35 2020 OK starting up.  The issue I remembered about
.pm in the MFM tree is ensuring the .pms can be found reliably under
all the various packaging and installation scenarios.[200:

Fri Sep  4 12:06:24 2020 Well, so there's like this:

    DEB_MFM_BINDIR := $(DESTDIR)/usr/bin
    DEB_MFM_RESDIR := $(DESTDIR)/usr/share/mfm/res
 ..
            mkdir -p $(DEB_MFM_RESDIR)
            cp -r res/fonts $(DEB_MFM_RESDIR)
            cp -r res/images $(DEB_MFM_RESDIR)
 ..

in MFM/config/Makedebian.mk.  We suspect we could add something like a
res/perl or res/lib or res/perllib in the [201: Fri Sep  4 12:18:38
2020 tree, yeah, in the tree.  Jeez I have to keep reminding myself
the .pms, if we make them, will NOT BE GENERATED CODE (unlike mfzmake
and mfzrun currently are).  So there won't be any issue of putting
generated code into res/ -- they will live their whole source tree
lives in res/perl, and we will edit them in res/perl, not in
src/drivers/mfzmake or whatever.  So

 - MFM/src/drivers/mfzrun/Makefile would get simpler

 - src/drivers/mfzrun/mfz*.tmpl would become mfz* and

 - we'd copy them intact to MFM/bin/ and chmod a+rx

 - they'd have some BEGIN code to ensure the 'right' path(s) are in
   %INC ?  That's the whole issue..

:201]

:200]

:199]
[202:

Fri Sep  4 13:06:08 2020 HOLY CRAB THE PERL DEBUGGER EXISTS AND WORKS
AND IS GREAT!  AND ITS EMACS INTEGRATION WORKS ON THE TILES!

:202]
[203:

Fri Sep  4 13:14:46 2020 But, tearing up the MFM tree to try
res/perllib, I guess..  Back to actual perl debugging later.

:203]
[204:

Fri Sep  4 14:55:42 2020 Urgh.  So it's not just a matter of turning
common.pl.inc into a module.  mfzrun/Makefile ALSO slugs in values for
things like '@DEBIAN_PACKAGE_NAME@' at build time.

Do we really want to be fogging with this?

[205:

Fri Sep  4 15:13:22 2020 Ugh, taking a break.  Gonna think HSA awhile.
[206:

Sat Sep  5 00:00:02 2020 First night run.

Screw it.  For now I'm going to do this:

 - Leave common.pl.inc alone

[207: Sat Sep  5 00:05:28 2020 Hey.  Why don't we go the sdl-config
route?  Call it mfm-config, and have it end up in MFM_INSTALL_DIR/bin
or whatever it's called, just like mfzmake and mfms and so on.  Have
it print out whatever varieties of configuration is needed.  Main
point is to figure out how to get the properly authoritative
information into mfm-config in all the different build scenarios.   :207]

:206]
:205]

:204]
[208:

Sat Sep  5 06:09:01 2020 Well I pretty much wasted this run, as far as
hacking goes.  I did a mfm-config thing, but on the one hand, it's not
immediately useful on the MFM tree side, while on the other hand, the
T2-12 side really doesn't need it, because it knows where all the
bodies are buried on the tile.

So, without taking a position, yet, on tearing all that out, I think
the idea here is to make MFM/res/perllib/MFZUtils.pm, but -- for the
moment at least -- only use it from the T2-12 side.  Let
mfzmake/mfzrun continue to use common.pl.inc, and thus not have to
deal with finding .pms across different installation options.

:208]
[209:

Sat Sep  5 23:48:56 2020 GO GOG O

:209]
[210:

Sun Sep  6 01:59:27 2020 OK, so good progress so far.

 - Have CryptoManager.pm, for handle and regnum services, existing and
   accessible from CDM::{mCryptoManager}

 - Have KeyManager, for signature checking and verification services,
   existing and accessible from CryptoManager

 - We have PacketCDM_S::verifySignature($cdm) which successfully
   verifies an announce packet (i.e., itself) using the whole RSA
   pubkey business -- all internally, without shelling out to mfzrun

   It also successfully detects deliberately corrupted packets (for
   ONE (1) whole instance of corruption), and successfuly detects the
   repaired package afterward.

At present we are NOT automatically verifying the signature during
initial packet parsing.  That was awkward because the Packet::validate
method had no easy way to get to the CryptoManager, but also because
we were afraid of burying the crypto that early in packet
processing.[216:

Sun Sep  6 02:37:22 2020 Yes: And Really Of Course Because: When the
packet first gets parsed off the wire, it will have the source
direction in the packet header, which would cause it to fail
verification.  But saying it aloud now, it's clear we could and
probably should work around that in verifySignature, though..  [217:
Sun Sep  6 02:42:34 2020 DONE   :217]So it's
not such a compelling argument..

:216]
The risk this way is that calling PacketCDM_S::verifySignature might
get overlooked.

We shall see.

[211:

Sun Sep  6 02:24:37 2020 Anyway, so I think perhaps we need more

TODO

[212: DONE :212] - Check for previous to-do, for clearance or action
[213: Sun Sep  6 02:25:40 2020

 - Work on to-do at :169: above doh. [215: Sun Sep  6 02:28:57 2020

[224: Mon Sep  7 01:30:54 2020
DONE :224] - Modify MFZManager::loadCnVMFZ to parse and verify the announce
   packet.  Store the S packet.  Use $spkt->{mPacketBytes} as future
   source of the data.

[251: Tue Sep  8 15:43:24 2020
DONE :251] - Create TMPipeline::handleAnnouncement, following TMTraditional

:215]

:213]


:211]

:210]
[214:

Sun Sep  6 02:26:16 2020 So, review pipeline protocol

SERVER PIPELINE ANNOUNCEMENT:
(1SA) Decide to send a pipeline announcement for a file we have in
      common/ or pipeline/.  Get its $mfzmgr.
(2SA) Pick a plausible $ngbmgr to send it to
(3SA) Get a $outboundspkt copy of the verified ANNOUNCE.PKT S packet, via
      $mfzmgr->{mVerifiedSPacket}
(4SA) Modify $outboundspkt to set the direction of $ngbmgr
(5SA) Send the packet
(6SA) Record the time or something?

CLIENT RECEIVE PIPELINE ANNOUNCEMENT
(1CA) Verify the S packet or toss it
(2CA) See if contents of common/ dominate the S packet, discard if so
      (but consider replying with an S packet of our own?)
(3CA) Check if deleted, discard if so (and consider announcing our
      cdm-deleteds to the source?)
(4CA) Check if contents of pipeline/ dominate the S packet, as in CA.
(5CA) If all seems right, initialize a file in pipeline/ and set up an
      appropriate(?) metadata record.
(6CA) Request the first chunk from the pipeline source (or anyone we know
      offering it.)

:214]
[218:

Sun Sep  6 04:12:28 2020 Second sleep.

:218]
[219:

Sun Sep  6 11:21:46 2020 On.

:219]
[221:

Sun Sep  6 13:33:28 2020 OK so we've made a lot of progress on
switching loadCnVMFZ over to MFZUtils internal routines.

Need to take a break to finally push out the overdue Computing Up.

Current status to pick back up here:

[223: Mon Sep  7 01:30:06 2020
DONE :223] - Deal with ensuring .mfz-internal pubkey matches an existing
   external pubkey before trusting the guts.

:221]
[222:

Mon Sep  7 00:38:21 2020 GO GO GO

:222]
[225:

Mon Sep  7 01:31:40 2020 On to SERVER PIPELINE ANNOUNCEMENT a la :214: above.

:225]
[226:

Mon Sep  7 02:56:40 2020 OK, well it's a bit of a pain to test -- I
faked an open NeighborManager in the debugger -- but we are now doing
(1SA) through (5SA) from :214: above in
TMPipeline::maybeMakeAnnouncement and down.

2.5 hours in.

Let's push on to receiving an S and see how far we can get.

:226]
[227:

Mon Sep  7 03:55:18 2020 OK, starting to slow down here, but have
gotten as far as TMPipeline::handleAnnouncement getting called.  Is
step (1CA) moot by the time we get there?  Maybe not.[228:

Mon Sep  7 04:10:32 2020 OK, now we're definitely up to (2CA).  We do
(I think) need to call verifySignature() as part of (1CA), and now we
are.

So I'm going to declare victory in this run and stop here, at about
3.5 hours.

Thinking ahead:

 - What does .mfz domination really mean?

 - When do we actually delete a dominated file?  Is that something we
   could do in an MFZManager::update?  How would we know then?  We
   need the place where different DirectoryManagers come together,
   like we have NeighborhoodManager to own all the NeigborManagers.

   Right now we just have the DirectoryManagers all laying
   independently in CDM:

        $self->{mCompleteAndVerifiedContent} = DMCommon->new($self);
        $self->{mPendingContent} = DMPending->new($self);
        $self->{mInPipelineContent} = DMPipeline->new($self);

   but for dominance purposes it would be 'more correct' to have some
   kind of ContentLocationsManager that owned the all
   DirectoryManagers.

   ContentLocationsManager::update could perhaps be a place to at
   least to spot checks for dominance

   Without keeping modfication times on everything, it's pretty hard
   to justify a random update method actually changing much stuff.

   We need stuff to age unless refreshed; mod times are one way to get
   at that.  Once stuff is aging with disuse, we can justify reaping
   the sufficiently old with no more reason than their age.

   Even 'immortal' stuff like the contents of common/ we could say
   that's 'used' when we reload it, so if that doesn't happen for some
   reason, we could flush common/ stuff.  [229:

Mon Sep  7 04:31:31 2020 All for now.

:229]


:228]

:227]
[230:

Mon Sep  7 11:27:57 2020 On.  ContentLocationsManager?
DirectoriesManager?  FileLocationsManager?  LocationsManager?
SuperDirectoryManager?  SuperSudsyBomb?  DirsManager?

DirectoriesManager I guess.  Start by moving stuff from CDM.pm [231:

Mon Sep  7 12:30:25 2020 OK geez that took an hour just to settle the
relocation of stuff from CDM to DirectoriesManager?  Poop that's a
third of my nominal foggen window here.

But anyway we are back to TMPipeline, handling an inbound S packet,
and domination.  Now, I guess it would be sensible to ask
DirectoriesManager 'Which DirectoryManager, if any, is currently
dominant for CONTENTNAME?'[232:

Mon Sep  7 12:49:35 2020 OK, so DirectoriesManager::getDominantDM does
what?

 - It's given a contentname.

 - It scans all its DMs for that cn.  For each hit, it captures their
   fileInnerTimestamp and computes set of DMs that are tied for
   newest.  (We'd like the hits we consider to either be CnV or
   reasonably fresh, but who knows how to do that latter reasonably.)

 - Break ties among the newest by directory.  I guess it's common/CnV
   > pipeline > pending.

 - Return the dominant newest DM if any.

:232]

:231]

:230]
[233:

Mon Sep  7 13:23:17 2020 Have a cut at
DirectoriesManager::getDominantDM but it's a bit of a pain setting up
a case where there's actually any competition..  Maybe better to push
on and (try to remember to) circle back once we create a pipeline MFZ
in response to the S.

:233]
[234:

Mon Sep  7 13:54:18 2020 So, umm, ummm: The S packet appears to
contain {mInnerLength}, but nothing like {mTotalLength}.  How are we
supposed to know when we've received the whole file?

Why, exactly, does the S packet contain mInnerLength rather than
mTotalLength?? [235:

Mon Sep  7 14:16:19 2020 Oh fog.  Now I remember.  Because the total
file length doesn't AND CAN'T exist until after the ANNOUNCE.PKT has
already been created and packed.

Now what Batman?

Now what, Mr Coder, Mr Super Genius?
[236:

Mon Sep  7 14:18:44 2020 Well, there are packets that come
afterwards.  The pipeline data chunks.  We could put the real file
length in them, if it isn't already.[237:

Mon Sep  7 14:36:08 2020 The PA packet.  Pipeline prefix
availability.  Right now in the old code it's:

    my $pipelineOperationsCode = "P";
    my $fileAnnouncementCode = "A";
    my $pkt = chr(0x80+$aliveNgb->{dir}).chr($CDM_PKT_TYPE).$pipelineOperationsCode.$fileAnnouncementCode;
    $pkt = plAddTagTo($pkt,$plinfo->{outboundTag});
    $pkt = addLenArgTo($pkt,$plinfo->{prefixLengthAvailable});

but we could add the total file length to it (so long as we're not
crossing versions 2 and 3 as far as pipelining.)

Or we could just make a separate PL packet that supplies the final
length, and just send it once.

No matter how we slice it, we'll still have to check the final inner
length against the S packet claim when we get to it.

[238:

Mon Sep  7 15:05:27 2020 Orrrrrr, we could nest the S inside a bigger
packet containing the final file length.  That way we'd get it all at
once, at the cost of packing issues and sadness over finally giving up
on our cherished if doomed Here's A Signed Packet Just Send It idea.

:238]

:237]

:236]
:235]

:234]
[239:

Mon Sep  7 15:08:49 2020 Well, it's dangerous because we're over three
hours since :230: above, but I think we're going with PL to send the
total length.  That means DMPipeline::newContentStub won't set up
mFileTotalLength and we'll do more configuration when the PL arrives.
[240:

Mon Sep  7 15:27:38 2020 Yep, I should have stopped.

It's really looking like we pretty much HAVE to embed the contents of
ANNOUNCE.PKT in a bigger packet.

REASON #1: So we can provide the mFileTotalLength at a sane time
REASON #2: So we can provide the outbound tag for the whole transfer

and we really do need to provide the fogging outbound tag for the
whole transfer.  The whole ANNOUNCE.PKT idea IS FUNDAMENTALLY BROKEN
because we absolutely need information THAT DOESN'T EXIST AT THE TIME
ANNOUNCE.PKT must be finalized.

So, I guess, we're going to embed the S packet inside the PF packet,
and watch our byte count on the latter..

:240]
:239]
[241:

Mon Sep  7 23:41:15 2020 ON.

:241]
[242:

Mon Sep  7 23:44:17 2020 I considered redoing the whole format of the
thing -- so it's not even a packet, for example --  but it would only
save like three bytes so screw it.  Let's live with it as a
packet-within-a-packet.

:242]
[243:

Mon Sep  7 23:47:51 2020 So I guess it's going to be just:

0x80, 0x83, 'P', 'F',    #   0 +   4 =   4 header bytes
 N                       #   4 +   4 =   8 outbound tag
 N                       #   8 +   4 =  12 file total length
 a200                    #  12 + 200 = 212 S packet

and we'll break down the S separately, to keep the crypto clean and
whatever.

:243]
[244:

Tue Sep  8 00:27:23 2020 Struggling back to runnability after tearing
up for embedding S inside PF.  Current issue: We ALSO have untested
new code about DirectoriesManager to integrate....[245: Tue Sep  8
00:30:16 2020 Actually I guess that was mostly outdated stub code, and
we're maybe not in such bad shape on the dirsmgr.  :245]

:244]
[246:

Tue Sep  8 02:47:34 2020 OK, we're in
MFZManager::configureFromPFPacket and wishing the PF packet had the
{mFileTotalChecksum} in it too.  If I read T2Utils::checksumWholeFile,
that would mean another 16 bytes.  Which we still can afford, although
I think PF would now be the biggest packet in CDMland.

:246]
[247:

Tue Sep  8 05:40:33 2020 Who, Ray.  I think we're actually about it to
generating the first pipeline chunk request of 'the New Era'.

(Way past three hours; fell off for a twitter/wapo/yt chunk in the
middle there.  Oh well.  The ball is still moving downfield a little.)
[248:

Tue Sep  8 05:43:32 2020 So I think that means it's time to flesh out
PacketCDM_PR.pm..[249:

Tue Sep  8 07:01:15 2020 OK well I think we just sent out first PR
pipeline request packet.  To an unconnected neighbor.  Because I
messed with the timestamps in the debugger to make it look like our
mfz was obsolete.  So That's Progress.

So really REALLY should stop now; we're at 6.5 hours on the run.

Actually, maybe we should think about committing here.  It's been a
while.  (Though we've been rsyncing ~t2/ to the laptop also.)

:249]

:248]
:247]
[250:

Tue Sep  8 15:37:26 2020 OK.  So is there a cheap way that I could run
two instances of cdm.pl on the same machine and have them communicate
through like pipes?  I guess not really, since I'm counting on
receiving a single packet in each read.  Could create some kind of
FUSE thing I suppose but that's way too much a pain from where I am.

Thing is we're getting to the end of what we can spike test easily,
and I'm afraid of debugging costs across tiles.

Screw it.  Let's go two just two tiles.  Just get going.  We can still
run the perl debugger on each tile..

:250]
[253:

Tue Sep  8 15:46:39 2020 I guess we should get a fresh cdmd-T2-12.mfz
ready to go..[254:

Tue Sep  8 16:00:53 2020 And we're going to need a fresh cdmd-MFM.mfz
too, of course, since it's got a bogus F-packet in ANNOUNCE.PKT..

:254]

:253]
[255:

Tue Sep  8 16:45:41 2020 Well, working through all kinds of random
problems.  Current issue is (once again) the chicken-and-egg between
T2-12 and MFM over the availability of MFM/res/perllib/MFZUtils.pm.
Didn't we reach a copy-on-make-T2-12 conclusion, that doesn't appear
to be implemented here?
[256:

Tue Sep  8 16:49:32 2020 Well all I see is :208: above.  And I think
I'm foggen just going to move MFZUtils.pm into the foggen T2-12 tree.

Chips Fall Where They May.

:256]
:255]
[257:

Tue Sep  8 23:19:14 2020 GO GO GO

:257]
[258:

Tue Sep  8 23:42:17 2020 OK so we're working back and forth between
two tiles, shamefully counting on having ethernet to both of them to
accelerate distributing code changes between them.

Two current issues:

 - We appear to be generating pipeline announcements even for
   destinations that we think are version 1

 - TMPipeline::handlePipelineChunkRequest doesn't yet exist.  (It
   shouldn't have been getting called, but for issue 1..)

:258]
[259:

Wed Sep  9 02:48:10 2020 OK so we're having confusion about
maintaining transfer manager metadata, particularly when moving
MFZManagers between different DirectoryManagers.

 - Where should TransferManagers be notified when a file moves?

 - Well, when a file moves where, specifically?

   = ..is newly found in DMCommon?  Then TMTraditional and TMPipeline
     should both be notified to create server metadata for it

   = ..is released from DMPending to DMCommon?  Then TMTraditional
     should flush its client metadata.  Also do the newly-found common
     steps above.

   = ..is released from DMPipeline to DMCommon?  Then TMPipeline
     should flush its client metadata, and do the common steps.

   = ..is found deleted from common (by obsolescence or whatever)?
     Notify TMs for server flush

:259]
[260:

Wed Sep  9 04:39:35 2020 So OK, we want TMPipeline transfers to
support server metadata and client metadata separately, right?  That's
the whole pipeline idea.  In particular, we want two different
outbound tags for them.  The client otag was chosen by ngb and sent to
us, and we use it to get more content from them.  The server otag was
created by us and sent out in PF packets, and others use it to request
content from us.

So, if there's only one MFZManager for a growing .mfz in pipeline/,
what goes in MFZManager::mOutboundTag ?  It would have to be our
outboundtag, I'd think you'd think, right?  Because it's only when
we're a server that the content is actually outbound.  So where does
the(ir outbound our) inbound tag go?

Only in the client metadata record, I guess.  And there really isn't
any obligation for client and server metadata records to have the same
structure beyond the first two keys.

:260]
[261:

Wed Sep  9 06:39:22 2020 Well, overdue for second sleep, and the
MFZMgr <-> TMgr <-> DirMgr metadata relationships are still confusing
and in flux.

:261]
[262:

Wed Sep  9 12:56:00 2020 Have to start long cook soon, but thinking
about goals and implementations.

 - Yes it's right for the (client) 'inbound otag' to be in the client
   metadata rec, because we want to associate multiple 'inbound otag's
   with the same mfzmgr.

 - We also want the client prefix length available to be the client
   metadata rec, because we'll have different values for that as well.

 - We can very sensibly view the 'client metadata rec' as simply being
   the neighbor's server metadata rec..

 - I guess on that view we could think about taking the
   prefixlengthavailable out of the mfzmgr itself and putting it in
   the pipeline server metadata.

 - But I really think in the spirit of squeakiness we have to ditch
   the metadata-as-anonymous-arrays and make at least one class for
   the (serverish) metadata.

[263:

Wed Sep  9 13:08:15 2020 And the name of this class is?  Well, the
low-order point of this class is?

[264:

Wed Sep  9 23:49:43 2020 TransferMetadata.pm[266: PipelineMetadata.pm?
 It's unique faster, compared to TransferM(etadata|anager).. :266]

GO GO GO

:264]

:263]

:262]
[265:

Wed Sep  9 23:52:18 2020 I'm really tempted to make it a packet
though...  NO STOP STOP STOP GO GO GO

:265]
[267:

Thu Sep 10 00:38:05 2020 So the point of the whole 'K2' thing is to be
able to access a metadata record either by 'dir9' (==dir8|DIR8_SERVER)
or by a second key 'K2'.  Which was seqno in the case of traditional
transfers, and otag in the case of pipeline transfers.

When we handle a chunk request, we look up the metadata by the K2.  When
we create a chunk request, we look up the metadata by the
contentname.  (And in fact when we look up by K2, we use a second map
to find the contentname from the K2 and then actually look up by
contentname.)

And we note that even though we're making classes for this metadata,
most of the work is still going to be done by TransferManager, since
that's were the maps of the K2Ms are located.[268:

Thu Sep 10 00:48:41 2020 So, um, I'm still hating this metadata
story.  For one thing, ATM it appears we have different metadata for
trad-server vs trad-client vs pipe-server.  Which is a mess.

Restate fundamentals.

 - We want to use a short fixed-size 'key' in data request/reply
   packets because using the full content name all the time would eat
   a signficant portion of our packet budget.

 - We want that key to be associated not just with a contentname but
   also with its innertimestamp, so that if the content associated
   with a contentname is updated, the key will change as well, and
   previously advertised key(s) for that cn will no longer work.

 - NEW keys are CREATED only when we are setting up structures to
   SERVE content.  That happens at two times: (1) When an MFZMgr is
   released to common/, and (2) When an empty file is created in
   pipeline/ as a result of a ngb pipeline announcement.

 - EXISTING keys are COPIED and STORED to enable RECEIVING content.
   That happens at two times: (1) When an empty file is created in
   pending/ in response to a ngb traditional announcement, and (2)
   When an empty file is created in pipeline/ as a result of a ngb
   pipeline announcement.

[269:

Thu Sep 10 01:28:06 2020 And it really seems like we should somehow be
able to exploit the symmetry -- that OUR existing keys are our ngbs NEW
keys -- to simplify this structure.

But what is the relationship between client metadata and server
metadata?

Use cases:

[UC1] Find a neighbor that recently claimed to serve this chunk I want.

[UC2] Find a neighbor that hasn't recently heard about what I can serve

[UC3] Change my ability to serve -- I have more chunks available

[UC4] Change my ability to serve -- this key is obsoleted

[270:

Thu Sep 10 01:51:33 2020 And let's make up lame-o-but-specific data
structures for those use cases:

[UC1] { cn -> { d8 -> [ pfxlen whenheardfrom key ] } }

      Select by cn, iterate over d8s, filter by pfxlen, weight by
      K/max(K,now-whenheardfrom), random pick.

      whenheardfrom updates on announcements and data chunks received.

      Larger K (in seconds) distributes requests more broadly; smaller
      K focuses on most recent relevant activity.

[UC2] { cn -> [ whensentto x d8 ] }

        subroutine pickD8ByAge(cn): Select by cn, iterate over d8 array,
        weight by age=now-whensento, random pick, return (d8,age)

      Iterate over cn, get (d8,age) for each, filter age by K, weight
      by age, random pick, if any.  (And announce cn to d8.)

      whensentto updates on announcements and data chunks sent.

      K sets minimum delay for announcement.  Could do it in the sub.

[UC3] (Same data structure as [UC2])

      Given cn (MFZMgr) and new pfxlen.

      Select by cn, iterate over d8s, set whensentto to 'long ago'.

      Kick whoever does the [UC2] processing

[UC4] Do the same as [UC3]?
[272:

Thu Sep 10 03:09:19 2020 So, that seems vaguely plausible as far as it
goes.  I don't really like iterating over (all cn x all d8) for the
[UC2] case.  Could just pick M random cns and weighted pick among
them.

But it's not clear how really much better all that is than just doing
fully random announcements.  Except for the UC1 'filter' step, which
we actually need.

And how does this help us settle the metadata design, exactly?

:272]
[271:

Thu Sep 10 03:08:19 2020 (Broke to do 'forensic' work in hopes of
recovering the now-extremely-long-lost robust.cs.unm.edu data grrr.)

:271]


:270]

:269]

:268]

:267]
[273:

Thu Sep 10 03:24:28 2020 I guess I want to try again with the needed
functionality, and see if we can come up with a more monolithic
approach that would cover them with a bit less total hair..

[SIT10] Receive traditional announcement
[SIT11] Receive pipeline announcement
[SIT12] Consider sending announcements
[SIT13] Send pipeline chunk request
[SIT14] Recv pipeline chunk request
[SIT15] Send traditional chunk request
[SIT16] Recv traditional chunk request
[SIT17] Send pipeline data chunk
[SIT18] Recv pipeline data chunk
[SIT19] Send trad data chunk
[SIT210] Recv trad data chunk
[SIT211] Discover new file in common
[SIT212] Discover file missing in common
[SIT213] Discover file missing in pending
[SIT214] Discover file missing in pipeline
[SIT215] Receive last of file in pending
[SIT216] Receive last of file in pipeline

[274:

Thu Sep 10 07:11:11 2020 Aieee wasted much time.

Suppose there was a single TransferManager in charge of all
information about data movement between CDMs -- trad and pipe,
outbound and inbound.  We want to see what involvement this TM would
have in all those situations.

[SIT10] Receive traditional announcement
          TM->refreshInbound(fpkt)
[SIT11] Receive pipeline announcement
          TM->refreshInbound(pfpkt)
[SIT12] Consider sending announcements
          TM->selectOutbound(\&filteredby,\&weightedby)
[SIT13] Send pipeline chunk request
          TM->refreshInbound(prpkt)
[SIT14] Recv pipeline chunk request
          TM->

:274]

:273]
[275:

Thu Sep 10 07:16:21 2020 TM methods

TM::refreshInbound($pkt)
  - handle multiple packet types appropriately
    $fpkt  - d8 has all of cn/inrts as of now
    $pfpkt - d8 has at least some of cn/inrts as of now

[276:

Thu Sep 10 07:45:00 2020 Or refreshThem vs refreshUs, instead of
inbound/outbound?

TM::refreshThemOnRecv($pkt)
  - handle multiple inbound packet types appropriately
    $fpkt  - d8 has all of cn/inrts as of now
    $pfpkt - d8 knows something about cn/inrts as of now
    $dpkt  - d8 has all of cn/inrts (as implied by sku) as of now
    $prpkt - d8 asked us for cn/inrts (by otag) as of now

TM::refreshUsOnSend($pkt)
  - handle multiple outbound packet types appropriately
    $fpkt  - we told d8 we have all of cn/inrts as of now
    $pfpkt - we told d8 we know about cn/inrts as of now
    $dpkt  - we sent d8 some data

..but this is just restating basically all of the packet semantics.
What is the consolidated state TM manages?

  [d9 cninrts k2 lastout lastin mfzgmr pfxlen]



:276]
:275]
[277:

Thu Sep 10 14:07:16 2020 Time to move the flag.  How are we going to
clean this design up?

:277]
[278:

Fri Sep 11 05:22:30 2020 So ugh.  Did other stuff yesterday and yet
magically nothing has changed here.

I guess the most inside track I can think of at the moment is to say:

How about let's ditch the traditional/pipeline distinction?  Let's
just implement a single underlying pipeline-capable MFZ+transfer
model, and use it for everything.

Storage manager:
 - Here's a believable description of some content, set up for it
 - Here's somebody who says they now have this much of that content

{ cninrts

:278]
[279:

Sat Sep 12 00:26:46 2020 Geez, another day of 'other stuff' let's say.

Nothing looks good here.

What I want to do is try a branch where we abandon backwards
compatibility and try to simply things as much as we possibly can
convince ourselves.

Example Extreme Simplifications:

 - Pipeline only.  Ditch 'traditional' one-hop transfer entirely.
   (One-hop behavior could be laid back on top of pipeline without
   much trouble if desired, if we don't need backwards compatibility.)

 - 'Content slots' rather than file names.  Have a hard limit of, say,
   250 .mfzs to be managed.  HARDCODE THEIR NAMES INTO cdm.pl, just
   like we are currently hardcoding the regnum space.

 - Go with much lower res timestamps -- like 5 minute granularity --
   and 24 bits of range.  That produces ~160 years of timestamps,
   which may sound pretty finite, in the big picture.  But then, what
   we have now is 32 bits of one second granularity, which provides
   only ~136 years of timestamps.  Ten minute granularity would push
   the range well over 300 years while, we'd think, very rarely
   crimping any reasonable development and grid deployment
   workflow.[283: Sat Sep 12 06:06:14 2020 Given how long propagation
   will still take even with smaller .MFZs  :283]

 - Use 8-bit 'content slot' + 24-bit 'coarse timestamp' as a 32 bit
   object name, a 'slotstamp' if you will, and use it directly in all
   data chunks requests and replies.

 - Then we get to ditch BOTH the traditional 'SKUs' AND the pipeline
   'otags' and just refer directly to the slotstamp whenever referring
   to a data object.

 - Then we modify 'mfzmake cdmake' to take the slotnum as well as the
   regnum, and we build out our master list of slot assignments.[284:
   Perhaps even autonaming the files cdmss-01-f00ba5.mfz, (cdmss-SLOT02x-STAMP06x)  :284]

 - While we're fantasizing here, we should also redo (at least) the
   T2-12 Makefile design to make smaller cdmds, instead of
   cdmd-T2-12.

[280:

Sat Sep 12 02:27:48 2020 For example, we could break it down one
level, and register like these four dirs separately.

      /home/t2/T2-12:
      total used in directory 76 available 318912
      drwxr-xr-x  8 t2 t2 4096 Aug 31 19:38 apps
      drwxr-xr-x  8 t2 t2 4096 Aug 31 19:38 files
      drwxr-xr-x  6 t2 t2 4096 Aug 31 19:38 lkms
      drwxr-xr-x  5 t2 t2 4096 Aug 31 19:39 pru

and we could reorg a bit to like move all the other ones into 'other'
or something, and register that.  And maybe stuff like notes/ doesn't
even end up in any slot?

Finer granularity allows both smaller .mfzs and rarer use of
destructive hook actions like reboot.

[281:

Sat Sep 12 02:34:10 2020 Starting a branch and redoing the make stuff
would be a good place to begin.

If we're really going to do this..

:281]
:280]


:279]
[282:

Sat Sep 12 05:06:47 2020 So one issue is where does the checksum map
live, or does it always have to be redistributed from sources that
have the content CnV?

If we also ditch the announcement packet being a packet, we could make
it a mini description file, and sign that instead.  Except we can't
because we're still inside the zip file.

The problem is where does the inner zip file start in the overall.

What if we just appended the map after the outer zip file?  Could we
even do that?  Why not, it's an MFZ file.  'cdmake' could even make a
v2 .mfz file, that has that map appended.  How big would the map be?
How about 4096 bytes.  What

[285:

Sat Sep 12 06:12:24 2020 Seeming like 2048 would be plenty.  Budgets
like
  6 'C' 'D' 'M' '1' '0' '\n'   #   0 +   6  ==    6
  1 block size bits            #   6 +   1  ==    7
  1 regnum                     #   7 +   1  ==    8
  1 slot                       #   8 +   1  ==    9
  3 stamp                      #   8 +   3  ==   12
  4 mapped file len            #  12 +   4  ==   16
 16 label                      #  16 +  16  ==   32
 64 mapped file full sha512    #  32 +  64  ==   96
800 100*8 byte xsum            #  96 + 800  ==  896
128 sig                        # 896 + 128  == 1024
<mapped file data starts here: 'MFZ(1.0)' etc..>

[286:

Sat Sep 12 07:24:09 2020 Well, this seems kind of do-able, from this
distance anyway.

And the beauty of it is we don't have to do (much of) anything special
to distribute the map.  We just start shipping the CDM1 file data, and
once the recipient has the first 1KB, they can check the CDM1 sig and
start redistributing that.

And then we can pick up in-progress transfers by checking the running
checksums and cutting the file back to the last one that checks.[287:

Sat Sep 12 07:36:22 2020 And if we count on/enforce/trust the filename
formatting, we can determine who dominates who just by reading the
directory entries.  We can have allegedly obsolete old version CnV
content and allegedly new version in progress files for the same slot
num in the same directory.  I guess we could even serve from the
former until the latter officially bumps it off, although it seems
wasteful.  I guess really instead of serving from the old we should
respond with a tiny 'trust me' courtesy announcement of the new
version.



:287]

:286]:285]

:282]
[288:

Sat Sep 12 12:48:09 2020 GO GO GO

:288]
[289:

Sat Sep 12 13:00:11 2020 Created branch cdm-simplex.

TODO

[293: Sun Sep 13 01:07:27 2020
DONE :293] - Redo mfzmake cdmake to generate CDM10 files

[294: DONE  :294] - Redo mfzrun to detect and handle CDM10 files

[295: Sun Sep 13 01:21:17 2020 Call it for now
DONE :295] - Resynchronize MFZUtils.pm with common.pl.inc

[301: Sun Sep 13 03:51:26 2020 Tried, undone, and
DEFERRED :301] - Reorganize T2-12 top subdirs for cdmd alignment

[290: Sat Sep 12 13:11:16 2020

 - Ditch ANNOUNCE and S packet stuff in favor of CDM10 stuff as in
   :285: above

:290]

:289]
[291:

Sat Sep 12 15:43:29 2020 Well, stop the clock, I guess.  Looks like we
kind of have 'CDM10' format mfz files 'working', in the sense that
'mfzmake cdmake' now generates them, and 'mfzrun cdmss-01-51609e.mfz
verify' (and similar commands) recognizes and skips the 1KB CDM10
prefix, and the rest of the unpacking appears to run transparently.

We do have duplication of constants (for e.g. magic numbers) between
T2-12/app/cdm/cdm/MFZUtils.pm and MFM/src/drivers/mfzrun/common.pl.inc
but other than that we're doing not terribly I think.

We don't have any code written to process the CDM10 header yet, but it
looks plausible, up to crypto schmutz, in emacs.

Committing this on the MFM side, I think.[296: Sun Sep 13 01:30:39
2020 Done :296]

:291]
[292:

Sun Sep 13 01:07:06 2020 GO GO GO.  Run til 5am COME ON.

:292]
[297:

Sun Sep 13 03:06:44 2020 Damn got sucked down a rabbit hole trying to
get arc-mfz.el to work on the tiles.  But no.  The newer version of
unzip on the tiles rejects the slightly-crappy input that my
workstation version of unzip grumpily but successfully processes.

GRRRRRRRRR.

POP POP POP

:297]
[298:

Sun Sep 13 03:16:00 2020 Trying to reconfigure the T2-12 top-level
subdirs now is a mistake.  It's going to impact stuff all the way back
to the tile-disk-image creation process and forward again.

[299:

Sun Sep 13 03:49:33 2020 OK well I bailed out of that with a

  'git reset --hard HEAD~='

and that seemed to work (surrounded by a git stash/apply for
untracked/uncommitted stuff I wanted, like these notes).
[300:

Sun Sep 13 03:50:52 2020 So, where are we really?

WE HAVE JUST ONE MORE HOUR ON THIS RUN.

[302:

Sun Sep 13 03:52:16 2020 I guess we're supposed to start tearing the
fog out of apps/cdm/cdm, with all this 'simplification' that we're
going to achieve here in no time flat.

TEAR-OUT TODO

 - Move it all to cdm/cdm-hold/ and start fresh

 - Pull in cdm.pl and start working from the front, ditching 

:302]



:300]

:299]

:298]
[303:

Sun Sep 13 03:56:54 2020 Pulling files in in
compilation-failure-inspections order.  First one to think about at
all: MFZManager.pm.

Can we do any quick work thinning out any of these:

    mContentName           => mSlotNum
    mDirectoryManager
    mState
    mVerificationStatus
    mFileModificationTime
    mFileTotalLength
    mFileTotalChecksum
    mFileInnerLength
    mFileInnerTimestamp
    mFileInnerChecksum
    mFilePipelineAnnouncePacket
    mAnnouncedContentName
    mPrefixLengthAvailable
    mXsumMap
    mXsumDigester

[304:

Sun Sep 13 03:59:17 2020 What's the big picture here?

CDM DIRECTORIES:

  /cdm/common    CnV only, and non-(completely)-dominated
  /cdm/pipeline  All other .mfzs
  /cdm/log,private_keys,public_keys
                 As before

:304]
:303]
[305:

Sun Sep 13 05:40:07 2020 OK past end of run, here, have to break.

Current status: Working from the front again using DO_DEBUG_TASK stubs

Next steps: Keep doing that.

:305]
[306:

Mon Sep 14 01:00:35 2020 OK one more solid quick run.  Let's claim the
next four hours, til 5:00:00.

TODO

[336: Mon Sep 14 12:56:38 2020 Yah man,
DONE :336] - Make MFZModel fully incremental.

[337:
DONE  :337] - Make a routine that accepts (filepos, bytes), and appends them iff
   the '-s file' currently matches the filepos.

[338:
DONE :338] - As part of doing that appending, the routine watches for three key
   categories of file lengths:
   [(0) Zero length file (or non-existent?) handled by separate routine(s)]
   (1) Reaching the first 1KB
   (2) Reaching the next block boundary
   (3) Reaching the end of the file

[339:
DONE :339] - As part of doing that appending, the routine splits chunks being
   added so that it reaches the next key length exactly, performs
   special functions, and then moves on.

 - The special functions are:
   [(0) Init RW file handle to file name derived from SS.  Use '-s
        $fh' to determine the ongoing size of the file, do not have a
        separate current length member.]

   (1) Parse and validate the CDMap headers.  If validation fails,
       unlink $fh and close it, remove self from 'content manager'.
       Otherwise, acquire target file length and block boundaries.
       Init mapped file digester.  Bump announcer.

   (2) Validate the prefix to the block boundary via the digester.  Do
       like (1) if validation fails.

   (3) Validate file against full file checksum, handle as (1) if
       fails.  Otherwise, run release hooks.

[307:

Mon Sep 14 01:48:50 2020 Should we maybe buffer blocks in memory
between boundaries, and only write stuff to the disk that we believe
in?  Seems clean-ish.  And only announce/serve to others once the disk
file is greater than 1KB, since that means it's validated.

:307]

:306]
[308:

Mon Sep 14 04:25:45 2020 OK, so our all-dancing MFZModel::addChunkAt
is working at least on non-error cases.  Now we need surrounding
infrastructure for two case:

(1) Checking and synchronizing a perhaps incomplete .mfz at startup
(2) Initiating a new .mfz in response to an announcement.  Needs to
    happen in a separate directory (i.e., pipeline/) so we won't touch
    any existing files until we've gotten and validated the CDMap.

[313:

Mon Sep 14 04:57:31 2020 So, back to (1) and (2) here.

(1) MFZModel::tryLoad($path) returns MFZModel or undef and sets $@
[314: Mon Sep 14 05:21:38 2020 Done :314]
(2) Still need to deal with announcements and who has what confirmed
    length.. 
   


:313]

For (1), let's make (update) MFZModel::newFromPath($path..[309:

Mon Sep 14 04:31:46 2020 Actually we can make what we've got better.
We shouldn't even look at the disk until we've accumulated and
validated the entire CDM10 header.  All we need to know is the
directory that we should-eventually-create the content in, if we get
that file.  Yes.  We don't even need a slotstamp in MFZModel->new()
which solves that chicken-and-egg problem..[310:

Mon Sep 14 04:33:49 2020 (Except we don't get as nice a getTag()
without an upfront SS.  Live with it.[311:

Mon Sep 14 04:37:54 2020 Well now wait though.  In both cases above,
we do have some clue what we expect the SS to be.  In (1) based on the
filename, in (2) in the announcement.  And we really would like to
check that the delivered CDMap lives up to the advertised SS.  So I
think we SHOULD require an SS and MFZModel->new() time, even though we
won't make go to the disk with a path based on the SS until the CDMap
is validated.
[312:

Mon Sep 14 04:56:35 2020 OK, so did that.  We take an SS at new()
time, and check it when the CDMap is complete.  NOTE I THINK WE ARE
NOT YET ACTUALLY DOING THE CRYPTO CHECK ON THE CDMAP DATA!

:312]
:311])

:310]

:309]

:308]
[315:

Mon Sep 14 05:21:56 2020 OK so about break time, but we're doing well
here.

TODO

[319: Mon Sep 14 08:09:55 2020 Made PacketCDM_F::makeFromMFZModel($model)
DONE :319] - MFZModel::makeAnnouncement: Return a newstal CDM_F packet
   representing what we have available from this MFZModel, or undef if
   we have nothing servable yet.

[318: Mon Sep 14 08:09:25 2020
DONE :318] - MFZModel::servableLength: Return length of disk file or 0 if none
   yet

[316:

Mon Sep 14 05:25:05 2020 We're thinking of going with just two
(mfz) directories, common/ and pipeline/.

How do we store neighbor availability?  Keep their latest F packets
somewhere, they're small.  Where?  Possibly in the MFZModel somewhere?
Seems like mission creep, but whereever we keep them they depend on an
MFZMOdel..

At first blush it's just

 { d8 -> fpacket }

but we'll eventually need some way to refresh that info.

What if we just kept the latest F packet we heard of that's got more
than we have?  Or played king of the hill as they came in?  That
forces things to refresh naturally.  And since F packets are so small
we send them with some frequency without feeling bad.

Seems in the stigmergic spirit.

We need to map from SS to MFZModel for it, and we need to map from
just a slotnum to our currently dominant SS for it.  Where's all that
happen?

Why do we need pipeline/ separate from common/, again?  If it's an
obsoleteing announcement it'll be in a different filename anyway.  If
it's the same SS we don't want to have two files for it.  We just want
to extend the one we've got until its done and good, or done and bad
and deleted.
[317:

Mon Sep 14 06:22:02 2020 Let's spike a thing that only looks at
common/, verifies everything good on startup, and nukes everything
bad, and see what that looks like.  Then feed in some stuff from orbit
as if from neighbors, and see what that looks like.

:317]
:316]

:315]
[320:

Mon Sep 14 08:10:24 2020 So trying to do directory loading
incrementally is a pain because we might end up announcing dominated
stuff until a later file is checked.

It feels easier to deal with if we did it atomically, but we're still
going to have to deal with new dominations arising as content comes
in.

Maybe we should focus on that latter: How to atomically update
dominations when some MFZModel changes state.

First, let's review/consolidate what domination means:

 - Domination applies between two MFZModels

 - If either has servableLength == 0, there is no domination either way

So both have mFileHandles and trustable mSSs.

 - If SSSlot(m1->{mSS}) != SSSlot(m2->{mSS}), there is no domination
   either way

So both refer to the same slotnum.

 - If SSStamp(m1->{mSS}) > SSStamp(m2->{mSS}), then m1 dominates m2.
 - If SSStamp(m1->{mSS}) < SSStamp(m2->{mSS}), then m2 dominates m1.

[321:

Mon Sep 14 08:23:27 2020 And now what.  Do we allow for multiple
distinct MFZModels with the same mSS?  Even temporarily?

Maybe not.  If it even comes up, maybe such situations are supposed to
be resolved on some basis other than whatever domination exactly
means.

[322:

Mon Sep 14 08:26:00 2020 What we wanted domination to mean was:

 (DOM1) We should only announce and grow undominated MFZmodels.

 (DOM2) Once a MFZModel is complete, we should forget any MFZModels it
        dominates, deleting their files.

So how do we implement just those two principles.

(DOM1) Whenever ContentManager creates an MFZModel $model, it does
       something like:

    if (defined($self->{mSSMap}->{$model->{mSS}})) {
      - $model and $self->{mSSMap}->{$model->{mSS}} fight it out.  Bigger
        servable length wins, flip a coin (?) on ties.  Assign winner
        to $model
    }
    $self->{mSSMap}->{$model->{mSS}} = $model;

[323:

Mon Sep 14 08:37:37 2020 OK and what if we have a complete older
timestamp and a zero-length newer timestamp on the same slotnum?  Who
dominates?  The older.  And if it's a 1K-length newer timestamp?  Then
it's the newer?  So how do we arrange for that dominance change to
happen?

What if we recorded { slotnum -> { ts -> model } } ?

with model->{mSS} === SSSMake(slotnum, ts)

Then

  keys %{$models->{$slotnum}}

are the things that might dominate each other.

Task0: Get the existing MFZModel for $ss if any

    my $ss = shift || die;
    my $slot = SSSlot($ss);
    my $ts = SSStamp($ss);
    my $map = $models->{$ss};
    return undef unless defined $map;
    return $map->{$ts};

Task1: Pick a random undominated MFZModel to announce or perhaps grow

    my $sn = pickOne(keys %{$models})
    my $dom;
    for my $ts (sort { decreasing } keys %{$models->{$sn}}) {
      my $mdl = $models->{$sn}->{$ts};
      next if $mdl->servableLength() == 0;
      $dom = $mdl;
      last;
    }
    return $dom;

Task2: Insert this here MFZModel $mdl in yo data structure

    my $map = $models->{SSSlot($mdl->{mSS})};
    unless (defined($map)) {
      $map = { };
      $models->{SSSlot($mdl->{mSS})} = $map;
    }
    my $omdl = $map->{SSStamp($mdl->{mSS})};
    if (defined($omdl)) {
       my $len = $mdl->servableLength();
       my $olen = $omdl->servableLength();
       return SetError("Already have a better one")
          if $olen > $len || (($len == $olen) && oneIn(2));
       DPSTD("Replacing $omdl"..);
    }
    $map->{SSStamp($mdl->{mSS})} = $mdl;
    return $mdl;

Task3: Reap any slotnum $sn MFZModels that are dominated by other
       completed slotnum models

    my $sn = shift || die;
    my $count = -1;
    for my $ts (sort { decreasing } keys %{$models->{$sn}}) {
      my $mdl = $models->{$sn}->{$ts};
      if ($count >= 0) {
        ++$count;
        $mdl->deleteFile();
        delete $models->{$sn}->{$ts};
      } elsif ($mdl->isComplete()) {
        $count = 0;
      }
    }
    return $count;

Task4: Garbage-collect $models

     for my $sn (keys %{$models}) {
       Task3($sn);
     }
     
Task5: Find or create the MFZModel for this $ss

     my $ss = shift || die;

     my $mdl = Task0($ss); # get existing
     unless (defined($mdl)) {
       $mdl = MFZModel->new($self->{mCDM},$ss,SUBDIR_COMMON);
     }
     return $mdl;

Task6: Update MFZModel availability based on this $fpkt

     my PacketCDM_F $fpkt = shift || die;
     my $d8 = $fpkt->getDir8();   # source of announcement
     my $ss = $fpkt->{mSlotStamp};
     my $mdl = Task5($ss);

     my $ngbf = $mdl->{mNeighborFPacket};
     $mdl->{mNeighborFPacket} = $fpkt
       if !defined($ngbf) ||
          ($ngbf->{mAvailableLength} < $fpkt->{mAvailableLength}) ||
          ($fpkt->{mAvailableLength} > $mdl->servableLength() && oneIn(4));

:323]

:322]

:321]
:320]
[324:

Mon Sep 14 10:01:26 2020 Well, those tasks 0..6 for ContentManager
look quite plausible sitting, but I am out of gas for now so they'll
all have to wait.

TODO

[327: Mon Sep 14 12:25:14 2020 First cuts throughout, with some testing
DONE :327] - Implement Task0

[328: DONE  :328] - Implement Task1

[329: DONE  :329] - Implement Task2

[330: DONE  :330] - Implement Task3

[331: DONE  :331] - Implement Task4

[332: DONE  :332] - Implement Task5

[333: DONE  :333] - Implement Task6

 - Spike test them

 - Start shipping F,C,D packets!

:324]
[325:

Mon Sep 14 10:11:30 2020 And I hit the fogging Off button instead of
the X button.  Genius.  Had just backed up, though so.

Sleep now.
[326:

Mon Sep 14 11:18:45 2020 Well, perhaps sleep later.  Oh well.

:326]
:325]
[334:

Mon Sep 14 12:25:59 2020 So we need more testing.  In particular, we
need a dominance situation, and a garbage collection.[335:

Mon Sep 14 12:45:52 2020 Well, faked it a little, but.. Stigmergy Is
Hard To Fake.

:335]

:334]
[340:

Mon Sep 14 12:58:43 2020 OK let's reexamine C and D packets, and then
try to move towards shipping them..

:340]
[341:

Mon Sep 14 13:03:17 2020 OK, we're putting our new ContentManager onto
a CDM data member.

:341]
[342:

Mon Sep 14 16:24:06 2020 Well, I haven't really slept yet and that has
to kick in soon, but, are we shipping F packets yet?[343:

Mon Sep 14 16:25:05 2020 I don't think so.  Let's try to do it on
timeout ContentManager.[344:

Mon Sep 14 21:31:57 2020 OK, slept.  We started shipping Fs but hadn't
demonstrated any case where that mattered, since it was all loopback.

Let's see about initiating a C.

:344]

:343]

:342]
[345:

Tue Sep 15 01:45:11 2020 OK, well, running very out of time here, but
making progress -- at dealing with some error cases even:

 - We're verifying the CDM10 map signature successfully

 - We rename files to cdmss-foo.mfz.bad if the signature check fails

 - If incremental xsum fails, we dump the current buffer and reload.
   
[346:

Tue Sep 15 01:48:23 2020 I think we have to try this guy on two tiles
like, right now.

So I guess we're committing?  On our cdm-simplex branch?[347:

Tue Sep 15 02:17:19 2020 Yeah.  Committing.

:347]

:346]

:345]
