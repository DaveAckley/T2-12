{73}  -*- text -*- 
[0:

Fri Aug  7 02:25:10 2020 OK, so having a second power zone drives home
much more clearly that we have to make cdm be able to do some kind of
pipelining of cdmd distribution, rather than going hop-to-hop at
multiple hours per hop.

Here's what I'm thinking:

Steps

 (1) During preinitCommon/checkCommonFile, have cdm compute and save
     in memory a vector of running SHA256 checksums, split on 1MB
     boundaries or to the end of the file.[1: Actually maybe split
     each file into some fixed N chunks -- N = 4, 8, 10? -- and do
     checksums for those positions.  Idea is to pick N and checksum
     fingerprint sized so that the split checksum info for a cdmd can
     fit in a single packet.  Maybe 20 chunks and 8 bytes per
     fingerprint for 160 byte main payload, plus packet header and SKU
     and packet checksum? :1]

 (2) Define a new cdm packet that carries that split checksum
     associated with a particular cdmd.

 (3) Write and somehow debug code to send and handle that split
     checksum packet, but do not actually send it in the production
     version.  We want to get the code to handle it out there to
     everybody before we start sending it to anybody.

 (4) Write a new kind of pending file announcement that's like a real
     announcement, but it includes a limit on the available bytes.


[2:

Fri Aug 7 03:44:04 2020 Actually as a step 0, let's flesh out the doc
on the current cdm packet formats.  That's currently a stub in
T2-PHF.[3:

Fri Aug  7 10:56:26 2020 OK did some of that, then did morning and
second sleep.[4:

Fri Aug  7 10:57:14 2020 So okay let's implements something
immediately.  I say let's implement a nearly-separate parallel system
of new packets, that only resolves back into the existing system once
a file is apparently complete and correct at the receiver.

[5:

Fri Aug  7 10:58:58 2020 Let's take this parallel structure as far as
a separate /cdm/pipe/ directory.

(1) During startup, 'map' the mfz's with sha256.  Divide it into 25
    pieces and capture 4 bytes of checksum per snapshot, so we can
    send the whole map in a single (big) packet.[6: Fri Aug  7
    11:21:55 2020 Or no?  Do 100 pieces and store the full SHA256
    checksum, and send it incrementally, whenever a chunk containing a
    percentage point mark is sent? :6]

(2) Have the potential receiver request a pipeline receive, in
    response to a normal file announcement.  During the transition, we
    will defeat this request to preserve original semantics.

(3) Let's draft only CDM 'P' for all pipeline commands?, so we can
    modularize their handling and enabling/disabling.

(4) State for a pipeline receive includes:
    - name+len+time+xsum (full file) that we are pipelining
    - length of file prefix we now possess
    - incremental xsum {filepos -> checksum} map confirmed so far.
      We also want to know which neighbors are advertising which
      prefixlengths, to know who we can ask for another chunk.
    - (and so min(prefixlength,max(ixsum keys)) is the max filepos we
      can currently deliver to pipeline consumers downstream)
    - time of last upstream chunk request, for timeout purposes
      [8: Fri Aug  7 12:48:19 2020
    - I guess time of last downstream pipeline announce as well?
    :8]

[7: Fri Aug  7 12:19:01 2020 So, packet flows.

 - We see a standard file announcement that we apparently want.  If
   enabled, we initialize a PipelineStatus structure (%hash) for the
   state in (4).  Set it up to timeout immediately.  It will have the
   ngb marked as advertising the whole file.

 - During state update (doBackgroundWork, I guess), we check for
   timeouts on any PipelineStatus structures we've got.  On timeout,
   request the current length we're at (0 at first) from any ngb
   marked as having that index, and set timeout.

[9:

Fri Aug  7 13:09:09 2020 Do we want to distinguish PipelineReceive and
PipelineSend structures instead of just PipelineStatus?  It seems no
but there are at least two timeouts -- failure to progress on
receiving, and time to reannounce current availability on sending.

In my gradually-emerging-semi-standard-timed-state-machine frameworks,
each machine is in a single state at any particular time, and the
timeout code is associated with that particular state.  What are the
states of the PipelineStatus machine?  Is it always just in state
RECEIVING_AND_SERVING?  That's nice and well-founded anyway.

I guess we just foggen have two timeouts, in effect, and set ourselves
to run at the earlier, but check both when we do run.

If we can have a state machine with just one main state, that does
seem like a good thing.

[10:

Fri Aug  7 13:53:03 2020 OK, how do we execute here?  Perl functions
to write:

GLOBAL METHODS

 - plReactToTraditionalAnnouncement: Init/update pl structure (also
   destroy any pls obsoleted by this announcement).

 - plInitState: Create initialized plStatus hash

 - plCheckTimeout: Call from doBackgroundWork or similar contexts, do
   all timeout processing

 - plHandlePacket: Deal with all incoming pl packets, including
   dispatching to plStatus methods
[11: Sat Aug  8 02:02:41 2020

 - plFindPLS: Lookup existing pls for name

:11]
PLSTATUS METHODS
 - plsReceiveTimeout
 - plsAnnounceTimeout
 - plsHandleChunkSupplied
 - plsHandleChunkRequested
 - plsReleaseCompleted
 - plsSendAnnouncementTo
 - ..others as needed I guess..
[12:Sat Aug  8 02:47:57 2020
 - plsScheduleTimeout

:12]
:10]

:9]

:7]    

:5]

:4]

:3]
:2]

:0]
[13:

Sat Aug  8 02:54:56 2020 OK so here's an issue: Once we have a file in
/cdm/common, and our neighbors want to pipeline it from us, do we have
to copy it (or gah link it, or something) to /cdm/pipeline?  Or do we
make the $plinfo struct be able to represent and serve files from
either directory?

I guess that?  We'll have a filePath member, and so long as
$plinfo->{prefixLengthAvailable} < $plinfo, the thing needs to be in
/pipeline, but once it's complete and verified, we move it do /common
and update the $plinfo.

Likewise, we'll create $plinfos on startup (or modtime change) for
valid /common files, that should end up looking just like the $plinfos
we get via the pipeline -- pointing into common, and used only for
serving, not reception, since they're complete.

:13]
[14:

Sat Aug  8 10:11:00 2020 OK well we need some kind of actual pipeline
packet formats to implement here.  How exactly are we naming the file
we want to be pipelining, in these packets?[15:

Sat Aug  8 11:59:08 2020 I guess it has to be SKU, which is built on
the seqno + armoring to detect possible missed remote restarts.

So we need to ensure we have a seqno store in a pls, and go from
there.

 -> Right now SKU parsing is done by checkSKUInDir, which is only
    prepared to look in /cdm/common or /cdm/pending.  So how will we
    refer to (partial) files that exist only in /cdm/pipeline?

Keep pushing out the overlay?  Separate seqno for $plinfo?  Separate
SKU for that matter?

[16:

Sat Aug  8 12:22:14 2020 Start with the pl announcement.  We don't
have that yet.

Could we do random tags instead of seqnos?  Or say one byte spinner +
three bytes random?  That would be plenty of defense against remote
restarts, I'd think.  Four bytes on the wire is better than ten for
the existing SKU.

----
WHAT: Announce pipeline file, defining tag:
  PF+tag+addlenarg(filename)+addlenarg(length)+addlenarg(innertime)+addlenarg(checksum)
SEND WHEN: After $plinfo create + random occasional
ON RECV: Create/update plinfo, add/refresh ngb/tag to $plinfo->{providers}

----
WHAT: Supply an xsum mark
  PM+tag+addlenarg(filepos)+addlenarg(xsumforfilepos)
SEND WHEN: After PD that spans filepos
ON RECV: Access plinfo and provider via tag, refresh provider, add [filepos,xsumforfilepos] to $plinfo->{xsumMap}

----
WHAT: Report prefix availability
 PA+tag+addlenarg(prefixlength)
SEND WHEN: After PF, and after prefixlength changes.
ON RECV: Access plinfo and provider via tag, refresh provider, update prefixlength in provider

----
WHAT: Request a pipeline file chunk:
  PR+tag+addlenarg(filepos)
SEND WHEN: After a PD that grew a file, or on PR timeout.
ON RECV: Access plinfo, check filepos availability, send PD, and PM if indicated.

----
WHAT: Provide a pipeline file chunk, perhaps with xsum mark
  PD+tag+addlenarg(filepos)+addlenarg(chunk)+addlenarg(xsummarkifany)
SEND WHEN: In response to PR.  If filepos+chunklen spans a mark, trim
           chunklen to end at mark and append xsummarkof resulting
           position, otherwise take default chunklen or rest
           available, and do not appends xsummark.
ON RECV: Access plinfo, check if filepos aligned with current file
         length.  If not, discard, if so, add chunk to digester and
         write to file.  If xsummark appended, compare to digest
         value.  Abort entire plinfo and underlying file if fail,
         otherwise add current position and xsummark to xsummap, and
         update prefixlenavailable (which should trigger sending PA as
         above).

         If prefixlenavailable has reached plinfo->{fileLength}, do
         pending file release operation to release the pipeline file,
         then rebuild (? reinit?) the plinfo, leading to a new tag and
         a new PF.  This may temporarily disrupt downstream providers
         but they should pick up the PF tag and continue from there.
         

[17:

Sat Aug  8 14:16:05 2020 So, more detailed plinfo struct:


plinfo = {
          'fileName' => 'cdmd-T2-12.mfz',        # name, also key in %plSTATE
          'fileChecksum' => '..',                # info about whole file
          'fileInnerTimestamp' => '1596031468',  # ditto
          'fileLength' => '1892932',             # ditto
          'filePath' => './cdmDEBUG/pipeline/cdmd-T2-12.mfz', # location
          'lastAnnounceTime' => 0,         # last time we announced this
          'lastRequestTime' => 0,          # last time anybody asked for this?
          'prefixLengthAvailable' => 0,    # max confirmed via xsumMap or fileChecksum
          'xsumMap' => [
                         [ 18930, '1f..' ],
                         [ 37860, 'tx..' ],
                         ..
                       ],
          'providers' => { dir -> [tag, prefixlengthavailable, age ],
                           .. }
        };


:17]

:16]

:15]

:14]
[18:

Sun Aug  9 01:39:35 2020 Well oops the keymaster trees got overwritten
by neighboring cdmds when I connected up a few tiles after moving the
flag.. but fortunately we'd maintained git discipline and after
cloning T2-12 and MFM from github it seems we're all caught up.

[19:

Sun Aug  9 02:21:12 2020 Although we did mess up the MFM build at
first.  Two notes:

 - Do 'T2-12$ make' before 'MFM$ make'.  T2-12 creates t2adc.h, which
   MFM includes.

 - MFM dies first time on missing 'StdElements.inc' which gets built
   out of order or something?

:19]

:18]
[20:

Sun Aug  9 02:33:40 2020 So okay, I think we're set up again.  Let's
just spike in from the top, implementing the packets from :16: above
and something like the expanded plinfo from :17: above, with glue at
the top to try them out, and quick report back here whenever we hit
some kind of hitch. 
[21:

Sun Aug  9 02:38:29 2020 Well, that's not good enough.  Let's be more
specific.  Give me some actual

TODO

[22: Sun Aug  9 04:35:11 2020 plsFindXsumInRange($plinfoCommon,$lo,$hi); 
DONE :22] - Routine to binary search xsummap for a point in a range.
   lowestAtLeast.

[23: plsInsertInXsumMap($plinfo,$filepos,$xsum);
DONE :23] - Routine to insert a new point into an xsummap via splice

[24: loose code..
DONE :24] - Test shim for prev two

[31: Sun Aug  9 11:31:04 2020 plNewTag
DONE :31] - Routine to generate a tag[32: Sun Aug  9 11:31:32 2020

Also plAddTagTo
DONE - Routine to add tag to packet

And plGetTagArgFrom
DONE - Routine to read a tag off a packet :32]

 - Come make more to-do[27:

 - Routine to init pls providers map

 - Routine to accept notification of provider (pl-related) activity

 - Routine to accept updates of provider tag-pfxlen availability

 - Routine to age/timeout the provider map

 - Routine select a provider that advertises availability of filepos

:27]

:21]
:20]
[25:

Sun Aug  9 08:46:50 2020 OK, had a second sleep.  Feeling okay about
the xsummap management.  What's specifically next?  Hard parts feel
like coordination between finfo and plinfo..  Let's go for the
packets, I guess, and try to be sensitive to our lurking confusions as
we do..
[26:

Sun Aug  9 08:49:07 2020 Actually, how about we spike toward the pls
'providers' map?  That's an area of some design uncertainty.  We'd
like to be able just to offer and query about prefixlengths available,
and have a little shim showing the provider info changing.

:26]
:25]
[28:

Sun Aug  9 08:55:37 2020 Now, we do need to know that all of the
providers in a pls map are providing precisely the same version of
precisely the file.. but I guess that all goes into the pls
selection.  How to we get from tag to pls?  Must have some master
map.  So it can't be just the 'providers' map inside the PLSs.[29:

Sun Aug  9 08:59:33 2020 In the existing SKU-based $finfo code that is
done via $seqnoMap{$seqno} when talking about our own content (from
/cdm/common), and via $hoodModel{$dir}->{contentOffered}->{$seqno} for
neighbor's content (coming into our /cdm/pending).

[30:

Sun Aug  9 09:03:32 2020 Do we want to dovetail into that?  Use SKU
and seqno?  Just seqno?  All sounds scary.  Goals for our pipeline
overlay 'tags':

 - Short but 'unique enough' in a given cdm.pl run

 - Stable for duration of a cdm.pl run

 - Fast access from tag to $plinfo and back again



:30]

:29]

:28]
[33:

Sun Aug  9 11:55:15 2020 OK so I guess now we're looking at a global
tag map?  To serve what operations?

 - plGetFilenameFromTag($tag, $dir) : get filename or undef
 - plGetFromTag($tag, $dir) : get existing $plinfo or undef

 - plPutFilenameOnTag($tag, $dir, $filename) : add/replace, delete on undef?
 - plPutOnTag($tag, $dir, $plinfo) : ditto

 - plInitTagMap() : re/init
[34:

Sun Aug  9 12:35:57 2020 So we made %plTAGMAP be tag -> {dir -> filename} 

but it's kind of weird because (1) we expect having multiple dirs
using the same tag to be vanishingly rare, and (2) we'll (generally?
invariably?) know the dir going in anyway.  Why not have it be

 dir -> {tag -> filename}

instead?

And I guess the other question is where do we store other tag-related
information, like aging or prefixavailability info?

Do we maybe ditch %plSTATE and make the tag map be

 dir -> {tag -> plinfo}

(possibly using dir==8 again to mean 'our own plinfos'?)

Or do we make the bidirectional mapping more explicit, with like

 %plFILEtoTAG   filename -> {dir -> tag}    # e.g., generate chunk request
 %plTAGtoFILE   dir -> {tag -> filename}    # e.g., handle tag recv

 %plFILEtoPLINFO filename -> plinfo

 plinfo  {
         ..
         providers -> {dir -> [tag prefix age .. ]} # ?
         ..
         }
[35:

Sun Aug  9 16:12:19 2020 Or might we prefer to ditch
plinfo->providers:

 %plFILEtoPROVIDER   filename -> {dir -> [tag prefix age ..]}    # e.g., generate chunk request
 %plPROVIDERtoFILE   dir -> {tag -> filename}                    # e.g., handle tag recv

 %plFILEtoPLINFO filename -> plinfo

 plinfo  {
         ..
         fileName -> ..   
         ..
         }

and so we're saying the plinfo contains no per-provider info at all,
just properties of the file as a whole.  There could be some
cleanliness there I'd think.[37:

Mon Aug 10 02:08:50 2020 So let's push a bit here; let's go with the
:35: maps and the 'file only plinfo' and see how far it gets us.

Need a shim that actually fakes sending and receiving pipeline chunks.

:37][36:

Sun Aug  9 16:45:07 2020 But time to cook.

:36]

:35]

:34]
:33]
[38:

Mon Aug 10 10:06:25 2020 OK, so, we had this idea that when we see a
traditional file announcement, we could create a pipeline entry for
it, and we created plReactToTraditionalAnnouncement specifically for
that purpose.

But a traditional file announcement DOES NOT INCLUDE A TAG.  There's
NO WAY we can send a plChunkRequest back to a provider that has only
sent us a traditional file announcement, because, for all we know, the
provider doesn't even support pipelined transfers.

The whole plReactToTraditionalAnnouncement is specifically broken.  We
need to undo that, and just have the shim set up a pipeline
announcement somehow, and go from there.

(We're also going to need some kind of way to NOT immediately respond
to traditional file announcements, if we want to avoid initiating a
traditional transfer as well..  It would be better if there was some
backward-compatible way to assess the version of a neighboring cdm, or
a set of supported features, or something.)

(Now, I note that the old 'A' aliveness packet, thought 'obsolete',
still does exist.  And it contains a one byte payload which we could
claim is a version?  Well except that old cdms send a random value
there, right?[39:

Mon Aug 10 10:18:03 2020 Here's the existing 'A' handling code:

        if ($bytes[2] eq "A") {
            # Handle old len3 type A packets
            DPPKT(sprintf("Rcvd 'A' from %d uniq %02x\n",$srcDir,defined($bytes[3]) ? ord($bytes[3]) : 0));
            return;
        }

and nothing above that cares about the packet length.  We could reuse
"A" as meaning something like an 'available features' list or
whatever, and just start sticking on flags and bytes and whatever
starting at byte[3], with the proviso that all code that looks at
those bytes has to silently ignore stuff they don't recognize.

And then we could, say, slap on a 'P' to mean that pipeline operations
are supported.  [40: Mon Aug 10 10:22:41 2020 And I guess we'd need to
ensure that all cdms that are taking this interpretation of "A" need
to ensure they send out their own "A" packet promptly on startup, to
minimize the race time:40]

:39])


:38]
[41:

Mon Aug 10 10:30:02 2020 Pop pop pop: But what we need now is to tear
up the 'react to traditional' thing and start generating a pipeline
file announcement instead, and then react to that.[42:

Mon Aug 10 10:32:29 2020 Can $plinfo have the OUTBOUND tag, even
though it's now supposed to have NO PER-PROVIDER data?  We're going to
use the same OUTBOUND tag no matter who we supply the file to, so it
seems like we could/should.  Kind of like the outbound tag is CONSUMER
data rather than provider..

:42]

:41]
[43:

Tue Aug 11 01:38:15 2020 OK so we're trying to handle a shim chunk
request and we're getting confused between 'inbound' and 'outbound'
tags.  The idea is we have a (almost surely) distinct inbound tag for
each provider we request data from, but all those inbound tags live in
the %plFILEtoPROVIDER map, keyed by the filename, and none of them
refer to a plinfo directly.

Instead, the %plFILEtoPLINFO map links a filename to a plinfo, so we
only have one plinfo per filename.

And, how do we represent files we have in common/? plSetupCommonFile
does that yes?[44:

Tue Aug 11 01:47:37 2020 Yes, and it ends up doing

    $plFILEtoPLINFO{$name} = $plinfo;
    $plOUTBOUNDTAGtoPLINFO{$plinfo->{outboundTag}} = $plinfo;

So that's when we have a complete verified file, and we should prefer
that whenever we can.  But we can also have in-progress pipeline
versions of files.[45:

Tue Aug 11 01:50:18 2020 Ah, wait a second.  At the moment we have
$plinfo->{prefixLengthAvailable}, but that seems to violate the 'no
per-provider in plinfo' rule from :35: above.  It seems like that
belongs somewhere in the pipeline records inside %plFILEtoPROVIDER.

Which brings back the dir==8-means-local hack.  But it's weird because
there's only two places the actual file can be -- common/ or
pipeline/, but there's seven directions plus local.  Maybe the
plinfo->{prefixLengthAvailable} is actually right -- it means the
verified length that THIS HERE FILE has, regardless of what any other
provider might say they have for the same name.  So even if the
plinfo->pfxLenAvl can change, it doesn't change in a per-provider way;
it only changes when THIS HERE FILE grows far enough to reach another
verification point.

:45]

:44]

:43]
[46:

Tue Aug 11 02:03:39 2020 So we should really get serious about having
the running sha256 digester inside the plinfo.  And we should have
shims about growing a copy of an mfz on disk, and seeing its plinfo
pfxLenAvl grow as the file passes xsummap checkpoints.

Let's go for a spike on that next.  Going for the full chunk packet
exchange is premature until we flesh out plinfo file growing
mechanics.

But urgh, not now, let's say second sleep early tonight.

:46]
[47:

Tue Aug 11 06:08:23 2020 OK plinfo grow go go go.[48:

Tue Aug 11 07:39:34 2020 OK, so we've now grown an exact duplicate of
an mfz in pipeline/.  Ooh we haven't updated the prefixlen on it as we
hit our xsum marks though..[49:

Tue Aug 11 07:43:55 2020 OK prefixLengthAvailable is growing with the
checked portion of the file, though nobody is looking at it.

Where do we go from here?  What lies between here and full chunk
packet exchange?

 - I guess we have to commit or redesign on the $dir==8 -> common
   idea, for one thing.

 - How do we search and decide who to ask for a chunk?  Given a
   filename, we iterate over the dir->prec map, and check each prec to
   see if they offer what we want, and do some selection process
   between multiple offerings.[50: Tue Aug 11 08:42:38 2020 

 - I guess the selection process is (1) $dir==8 wins if available.
   Except we shouldn't be asking for a chunk at all if we have the
   whole thing locally.  Wait.  If plinfo is pointing into common/ we
   just shouldn't have or accept any other providers, right?  If a
   newer version of filename comes along, that should knock the
   existing plinfo-to-common out and replace it with a stub in
   pipeline/.

The point being that at any given time, there is only one actual disk
file that represents the plinfo data source for this file.  It might
be complete and in common/ and it might not.[51:

Tue Aug 11 10:55:08 2020 OK so how can we proceed here?

We'd like to understand the process whereby plinfos for common/ and
pipeline/ files come to exist in our main containers:

    my %plFILEtoPLINFO;         # filename -> plinfo
    my %plOUTBOUNDTAGtoPLINFO;  # outboundTag -> plinfo
    my %plFILEtoPROVIDER; # filename -> {dir -> [tag prefix age ..] }
    my %plPROVIDERtoFILE; # dir -> {tag -> filename}

 - Well, plSetupCommonFile($finfo) builds a plinfo from a finfo, fills
   out the whole xsummap, and makes entries in %plFILEtoPLINFO and
   %plOUTBOUNDTAGtoPLINFO.  But it apparently touches nothing in
   %plFILEtoPROVIDER or %plPROVIDERtoFILE.

   So if we want to SUPPLY a chunk to a neighbor, we go by
   %plOUTBOUNDTAGtoPLINFO.  That makes sense.  But what about the
   pipeline setup?  That might have to setup an outbound tag too.

 - While on the other hand, plProcessFileAnnouncement($dir,$bytes)
   uses plSetupNewPipelineFile($name, $contentLength, $checksum,
   $timestamp) if (1) there's no plinfo for $name in %plFILEtoPLINFO,
   or (2) the existing $plinfo->{fileInnerTimestamp} is less than the
   $timestamp from the packet.

   Now, at the moment, plSetupNewPipelineFile does not modify any of
   the main containers.  Which seems kind of wrong.  What do we think
   it should do? [52: Tue Aug 11 11:52:01 2020 Well, unclear.  At the
   moment, plProcessFileAnnouncement, which calls
   plSetupNewPipelineFile, later calls plPutOnTag($tag,$dir,$plinfo)
   and that eventually modifies %plPROVIDERtoFILE.  It also calls
   plGetProviderRecordForFilenameAndDir($filename, $dir), which
   eventually modifies %plFILEtoPROVIDER.

   But as far as I can tell, plProcessFileAnnouncement never does
   anything that touches %plFILEtoPLINFO or %plOUTBOUNDTAGtoPLINFO
   which I'd think means their stuff won't get found later on, except
   by shims that have their grubby fingers on the plinfo explicitly.

   So on first principles, plProcessFileAnnouncement should play king
   of the hill with an existing plinfo on the same file.  The 'if':

    if (!$plinfo || $plinfo->{fileInnerTimestamp} < $fileinnertimestamp) {

   statement does do that, but the 'then' clause doesn't follow
   through on it.

   If there is an existing plinfo, but we're newer than it, we should
   replace it in %plFILEtoPLINFO and %plOUTBOUNDTAGtoPLINFO with
   ourselves and our outbound tag, so that all future announcements
   downstream will use the new one (regardless of how many bytes of it
   we actually have).

   Actually we should modify %plFILEtoPLINFO and
   %plOUTBOUNDTAGtoPLINFO whether there's an existing plinfo or not,
   right? 


:52]

:51]

:50]

:49]

:48]

:47]
[53:

Wed Aug 12 06:48:02 2020 OK well that was a big cook yesterday
(vindaloo for dinner + freezer) and also did some really-quite-usable
script for HSA2020 so that was good.  Now it's time to move the flag
today soon so we'll see if we do much here.

For here, we were on getting the main containers updated properly as
part of our test shims.  And the last go showed:

    XXplFILEtoPROVIDER $VAR1 = {
              'HACKcdmd-T2-12.mfz' => {
                                        '1' => [
                                                 1,
                                                 0,
                                                 0,
                                                 0
                                               ]
                                      }
            };
    XXplPROVIDERtoFILE $VAR1 = {
              '1' => {
                       '3134941762' => 'HACKcdmd-T2-12.mfz'
                     }
            };
    GOODBYE

which was progress.  So, what isn't working next?[54:

Wed Aug 12 07:51:53 2020 Well, testShimForPlinfoGrow isn't actually
making packets, but it is reading the data chunks with
plsGetChunkAt($plinfoCommon,$filepos); and writing them with
plsWriteChunk($plinfoPipeline,$chunk); -- maybe now we're ready to try
lifting that up to packet sending and handling?

Let's compare testShimForPlinfoGrow and testShimForChunkMovement and
get the latter to use what it needs of the former..[55:

Wed Aug 12 08:10:58 2020 Well it's still not clear if/how we can test
the file announcement and setup stuff, since we are talking to
ourself..  The idea was/would be to set up a real file in common, but
create a fake name for it in the announcement packet, so that we won't
think we have it on the handling side, and we'll init a pipeline
plinfo for it.  That wasn't working before; let's try it again and see
where it blows up now.[56:

Wed Aug 12 08:51:22 2020 Well it kind of seems to be working.

So what's next.  Chunks.[57:

Wed Aug 12 08:56:55 2020 OK, so it looks like we're (fake) sending and
receiving an availability packet -- and we're sending it ostensibly
using the original (common/) file, but since we hacked the
announcement packet, its outbound tag 29775360

    PLS1READY $VAR1 = {
 ..
              'fileName' => 'cdmd-T2-12.mfz',
              'filePath' => './cdmDEBUG/common/cdmd-T2-12.mfz',
              'outboundTag' => 29775360,
 ..

is now also the inbound provider tag associated with the pipeline/
file that got set up:

    PIPELINEPREFIXAVAIL(\201\203PA\306V^@^G1892908)
    GF1XX HACK2cdmd-T2-12.mfz 1 HASH(0x1a42e40)
    PADN: $VAR1 = [
              1,
              29775360,
              1892908,
              798622100
            ];

So let's send some chunks.[58:

Wed Aug 12 09:27:33 2020 OK so plProcessChunkRequest was most
half-warmed-over copypasta of plProcessPrefixAvailability.  So now we
need to get to a plsGetChunkAt call like in testShimForPlinfoGrow.

:58]

:57]

:56]

:55]


:54]

:53]
[59:

Wed Aug 12 11:05:22 2020 Moving the flag.

:59]
[60:

Wed Aug 12 12:37:29 2020 Flag moved.

:60]
[61:

Thu Aug 13 06:13:17 2020 Don't know what the deal is with this
sleeping through the night business.  Can't last.

:61]
[62:

Thu Aug 13 06:13:36 2020 So our test shims have reached the point of
simulated packets sent and received that initialize and build a
pipeline file.  I guess the main thing left is to finish receiving a
file and get it into common/, to close the big loop.

Maybe we should make a much smaller test cdmd for all this?  Like
20-30KB maybe instead of 1.8MB?

:62]
[63:

Thu Aug 13 11:59:40 2020 Well it's looking like
testShimForChunkMovement is now getting us all the way from this:

    t2@beaglebone:~/T2-12/apps/cdm$ ls -al cdmDEBUG/*
    cdmDEBUG/common:
    total 40
    drwxr-xr-x 2 t2 t2  4096 Aug 13 11:27 .
    drwxr-xr-x 7 t2 t2  4096 Aug 13 11:27 ..
    -rw-r--r-- 1 t2 t2 12412 Aug 13 06:30 cdmd-TEST.mfz

    cdmDEBUG/log:
    total 8
    drwxr-xr-x 2 t2 t2 4096 Aug  9 02:23 .
    drwxr-xr-x 7 t2 t2 4096 Aug 13 11:27 ..

    cdmDEBUG/pending:
    total 8
    drwxr-xr-x 2 t2 t2 4096 Aug 13 11:27 .
    drwxr-xr-x 7 t2 t2 4096 Aug 13 11:27 ..

    cdmDEBUG/pipeline:
    total 8
    drwxr-xr-x 2 t2 t2 4096 Aug 13 11:27 .
    drwxr-xr-x 7 t2 t2 4096 Aug 13 11:27 ..

    cdmDEBUG/public_keys:
    total 12
    drwxr-xr-x 2 t2 t2 4096 Aug  9 02:23 .
    drwxr-xr-x 7 t2 t2 4096 Aug 13 11:27 ..
    -rw-r--r-- 1 t2 t2  288 Aug  9 02:23 t2%2dkeymaster%2drelease%2d10.pub
    t2@beaglebone:~/T2-12/apps/cdm$ 

to this:

    t2@beaglebone:~/T2-12/apps/cdm$ ls -al cdmDEBUG/*
    cdmDEBUG/common:
    total 40
    drwxr-xr-x 2 t2 t2  4096 Aug 13 12:01 .
    drwxr-xr-x 7 t2 t2  4096 Aug 13 12:00 ..
    -rw-r--r-- 1 t2 t2 12412 Aug 13 06:30 cdmd-TEST.mfz
    -rw-r--r-- 1 t2 t2 12412 Aug 13 12:01 HACK2cdmd-TEST.mfz

    cdmDEBUG/log:
    total 8
    drwxr-xr-x 2 t2 t2 4096 Aug  9 02:23 .
    drwxr-xr-x 7 t2 t2 4096 Aug 13 12:00 ..

    cdmDEBUG/pending:
    total 8
    drwxr-xr-x 2 t2 t2 4096 Aug 13 12:01 .
    drwxr-xr-x 7 t2 t2 4096 Aug 13 12:00 ..

    cdmDEBUG/pipeline:
    total 8
    drwxr-xr-x 2 t2 t2 4096 Aug 13 12:01 .
    drwxr-xr-x 7 t2 t2 4096 Aug 13 12:00 ..

    cdmDEBUG/public_keys:
    total 12
    drwxr-xr-x 2 t2 t2 4096 Aug  9 02:23 .
    drwxr-xr-x 7 t2 t2 4096 Aug 13 12:00 ..
    -rw-r--r-- 1 t2 t2  288 Aug  9 02:23 t2%2dkeymaster%2drelease%2d10.pub
    t2@beaglebone:~/T2-12/apps/cdm$ 

with only 10.8K lines of debug output in between..

So.  I think maybe we should commit this as a plausible WIP, and then
start thinking about replacing cdm.pl..

:63]
[64:

Thu Aug 13 12:17:33 2020 OK, now we want a cdm.pl that has all the
pl.pl stuff, but doesn't use breathe a word of it unless
$PIPELINE_ENABLED = 1.

How actually do we get from the shims to the event loop?  Let's go
through what testShimForChunkMovement calls..

:64]
[65:

Thu Aug 13 13:00:15 2020 Well, pl.pl is running as root on a single
tile with a loopback, and with $PIPELINE_ENABLED = 0, and it seems to
be doing okay:

    SENDIT(\202\203A^T)
    cdmd-TEST.mfz^E12412^PQ\236\347\335\300\232\225\372sk_\263\235\252
    15973218101)
    cdmd-TEST.mfz^E12412^PQ\236\347\335\300\232\225\372sk_\263\235\252
    15973218101)
    GOT PACKET(\206\203A^T
    Rcvd 'A' from 6 uniq 14

    cdmd-TEST.mfz^E12412^PQ\236\347\335\300\232\225\372sk_\263\235\252
    15973218101)
    AF(fn=cdmd-TEST.mfz,dir=2,ts=1597321810,seq=1)
    CHECKING Ignore complete and matched in common

and so on..

Maybe switch it back to the real /cdm base?  So if we turn on another
tile maybe it won't start sending us everything?[66:

Thu Aug 13 13:04:43 2020 Well, that seems to be okay too.  We think
maybe we could turn on a neighbor tile now and have 'nothing' happen?  

:66]

:65]
[67:

Thu Aug 13 13:10:56 2020 Seems like a pl.pl is talking to an existing
cdm.pl without issue, and they're announcing and ignoring each other
with the best of them.
[68:

Thu Aug 13 13:22:43 2020 Let's commit and pull pl.pl to the other
  guy.[69:

Thu Aug 13 13:24:04 2020 ehhhhhhxcept the other guy is a regular tile
and just has a T2-12 directory, not a T2-12 repo..[70:

Thu Aug 13 13:33:29 2020 OK, so it seems like two pl.pls are talking
to each other OK.

:70]

:69]

:68]

:67]
[71: 

Fri Aug 14 02:14:07 2020 So, we were going to do an enabling thing,
where even if we had $PIPELINE_ENABLED == 1, we wouldn't do pipeline
stuff in a particular direction until we had seen a 'feature
announcement' packet -- reusing the 'obsolete' "A" aliveness packet --
that included some flag meaning 'pipeline capable'.

:71]
[72:

Fri Aug 14 04:30:38 2020 OK committing a bunch of stuff in pl.pl,
including 'use constant's hey, and version stuff, and don't send
announcements -- traditional or pipeline -- to dir until we've seen an
"A" packet from dir, and so on.

Getting closer to a plausible cut-over to cdm.pl; not there quite
yet. 

:72]
